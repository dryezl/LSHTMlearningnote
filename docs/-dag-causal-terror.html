<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 49 章 有向無環圖 DAG &amp; 可怕的因果 Causal Terror | 醫學統計學</title>
  <meta name="description" content="第 49 章 有向無環圖 DAG &amp; 可怕的因果 Causal Terror | 醫學統計學" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="第 49 章 有向無環圖 DAG &amp; 可怕的因果 Causal Terror | 醫學統計學" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/cover.jpg" />
  
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 49 章 有向無環圖 DAG &amp; 可怕的因果 Causal Terror | 醫學統計學" />
  
  
  <meta name="twitter:image" content="img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang" />


<meta name="date" content="2021-01-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="-many-more-variables.html"/>
<link rel="next" href="-model-selection.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block/empty-anchor.js"></script>
<script src="libs/kePrint/kePrint.js"></script>
<link href="libs/lightable/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/plotly-binding/plotly.js"></script>
<script src="libs/typedarray/typedarray.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的統計學筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path="prob-intro.html"><a href="prob-intro.html"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a><ul>
<li class="chapter" data-level="1.1" data-path="prob-intro.html"><a href="prob-intro.html#三個概率公理"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path="prob-intro.html"><a href="prob-intro.html#conditonalProb"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="prob-intro.html"><a href="prob-intro.html#獨立-independence-的定義"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path="prob-intro.html"><a href="prob-intro.html#賭博問題"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path="prob-intro.html"><a href="prob-intro.html#賭博問題的答案"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Bayes-Definition.html"><a href="Bayes-Definition.html"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path="expectation.html"><a href="expectation.html"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="expectation.html"><a href="expectation.html#方差的性質"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bernoulli.html"><a href="bernoulli.html"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path="binomial.html"><a href="binomial.html"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="binomial.html"><a href="binomial.html#二項分佈的期望和方差"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path="binomial.html"><a href="binomial.html#hyperdist"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path="binomial.html"><a href="binomial.html#樂透中獎概率問題"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a><ul>
<li class="chapter" data-level="5.3.1" data-path="binomial.html"><a href="binomial.html#如果我只想中其中的-3-個號碼概率有多大"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path="normaldistr.html"><a href="normaldistr.html"><i class="fa fa-check"></i><b>7</b> 正（常）態分佈 Normal Distribution</a><ul>
<li class="chapter" data-level="7.1" data-path="normaldistr.html"><a href="normaldistr.html#概率密度曲線-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path="normaldistr.html"><a href="normaldistr.html#正常態分佈"><i class="fa fa-check"></i><b>7.2</b> 正（常）態分佈</a></li>
<li class="chapter" data-level="7.3" data-path="normaldistr.html"><a href="normaldistr.html#standardNormal"><i class="fa fa-check"></i><b>7.3</b> 標準正（常）態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="CLT.html"><a href="CLT.html"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="CLT.html"><a href="CLT.html#covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path="CLT.html"><a href="CLT.html#correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path="CLT.html"><a href="CLT.html#中心極限定理-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="CLT.html"><a href="CLT.html#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正（常）態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path="CLT.html"><a href="CLT.html#泊松分佈的正常態分佈近似"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正（常）態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path="CLT.html"><a href="CLT.html#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正（常）態分佈模擬的校正：continuity corrections</a><ul>
<li class="chapter" data-level="8.6.1" data-path="CLT.html"><a href="CLT.html#例題"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="CLT.html"><a href="CLT.html#兩個連續隨機變量"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path="CLT.html"><a href="CLT.html#兩個連續隨機變量-例子"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path="CLT.html"><a href="CLT.html#條件分佈和邊緣分佈的概念"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path="CLT.html"><a href="CLT.html#條件分佈和邊緣分佈的例子"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a><ul>
<li class="chapter" data-level="8.10.1" data-path="CLT.html"><a href="CLT.html#例題-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path="inference-basic.html"><a href="inference-basic.html"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a><ul>
<li class="chapter" data-level="9.1" data-path="inference-basic.html"><a href="inference-basic.html#人羣與樣本-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path="inference-basic.html"><a href="inference-basic.html#樣本和統計量-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path="inference-basic.html"><a href="inference-basic.html#估計-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path="inference-basic.html"><a href="inference-basic.html#信賴區間-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a><ul>
<li class="chapter" data-level="10.1" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#估計量的特質"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a><ul>
<li class="chapter" data-level="10.2.1" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#bias"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#估計量的效能-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#均值和中位數的相對效能"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#均方差-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#samplevarbias"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path="estimation-and-precision.html"><a href="estimation-and-precision.html#samplevar"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a><ul>
<li class="chapter" data-level="11.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的期望和方差的證明"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的期望"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的方差"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a><ul>
<li class="chapter" data-level="11.3.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#下面來求-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#把上面的推導擴展"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="likelihood-definition.html"><a href="likelihood-definition.html"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a><ul>
<li class="chapter" data-level="12.1" data-path="likelihood-definition.html"><a href="likelihood-definition.html#概率-vs.-推斷-ability-vs.-inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 ability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path="likelihood-definition.html"><a href="likelihood-definition.html#似然和極大似然估計-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path="likelihood-definition.html"><a href="likelihood-definition.html#似然方程的一般化定義"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path="likelihood-definition.html"><a href="likelihood-definition.html#對數似然方程-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="likelihood-definition.html"><a href="likelihood-definition.html#極大似然估計-maximum-likelihood-estimator-mle-的性質"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path="likelihood-definition.html"><a href="likelihood-definition.html#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path="likelihood-definition.html"><a href="likelihood-definition.html#有-n-個獨立觀察時的似然方程和對數似然方程"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="llr.html"><a href="llr.html"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a><ul>
<li class="chapter" data-level="13.1" data-path="llr.html"><a href="llr.html#正態分佈數據的極大似然和對數似然比"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path="llr.html"><a href="llr.html#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path="llr.html"><a href="llr.html#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path="llr.html"><a href="llr.html#似然比信賴區間"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a><ul>
<li class="chapter" data-level="13.4.1" data-path="llr.html"><a href="llr.html#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path="llr.html"><a href="llr.html#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="llr.html"><a href="llr.html#inference-practical-05"><i class="fa fa-check"></i><b>13.5</b> Inference Practical 05</a><ul>
<li class="chapter" data-level="13.5.1" data-path="llr.html"><a href="llr.html#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path="llr.html"><a href="llr.html#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path="llr.html"><a href="llr.html#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="quadratic-llr.html"><a href="quadratic-llr.html"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a><ul>
<li class="chapter" data-level="14.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a><ul>
<li class="chapter" data-level="14.1.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#近似法估算對數似然比的信賴區間"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#以泊松分佈爲例"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#Possion-log-transform"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#以二項分佈爲例"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="quadratic-llr.html"><a href="quadratic-llr.html#inference-practical-06"><i class="fa fa-check"></i><b>14.3</b> Inference Practical 06</a><ul>
<li class="chapter" data-level="14.3.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="hypothesis-test.html"><a href="hypothesis-test.html"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a><ul>
<li class="chapter" data-level="15.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path="hypothesis-test.html"><a href="hypothesis-test.html#錯誤概率和效能方程-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a><ul>
<li class="chapter" data-level="15.2.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#以二項分佈爲例-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="hypothesis-test.html"><a href="hypothesis-test.html#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a><ul>
<li class="chapter" data-level="15.3.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#以已知方差的正態分佈爲例"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="hypothesis-test.html"><a href="hypothesis-test.html#複合假設-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a><ul>
<li class="chapter" data-level="15.4.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#單側替代假設"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path="hypothesis-test.html"><a href="hypothesis-test.html#雙側替代假設"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="hypothesis-test.html"><a href="hypothesis-test.html#爲反對零假設-h_0-的證據定量"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a><ul>
<li class="chapter" data-level="15.5.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="hypothesis-test.html"><a href="hypothesis-test.html#雙側替代假設情況下雙側-p-值的定量方法"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path="hypothesis-test.html"><a href="hypothesis-test.html#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path="hypothesis-test.html"><a href="hypothesis-test.html#inference-practical-07"><i class="fa fa-check"></i><b>15.8</b> Inference Practical 07</a><ul>
<li class="chapter" data-level="15.8.1" data-path="hypothesis-test.html"><a href="hypothesis-test.html#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a><ul>
<li class="chapter" data-level="16.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#近似和精確檢驗-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#LRT"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#練習題"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#Wald"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a><ul>
<li class="chapter" data-level="16.4.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#再以二項分佈爲例"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#Score"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a><ul>
<li class="chapter" data-level="16.5.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#再再以二項分佈爲例"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#LRTwaldScore-Compare"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#inference-practical-08"><i class="fa fa-check"></i><b>16.7</b> Inference Practical 08</a><ul>
<li class="chapter" data-level="16.7.1" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path="approximation-hypo-test.html"><a href="approximation-hypo-test.html#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="normal-error-models.html"><a href="normal-error-models.html"><i class="fa fa-check"></i><b>17</b> 正態誤差模型 Normal error models</a><ul>
<li class="chapter" data-level="17.1" data-path="normal-error-models.html"><a href="normal-error-models.html#服從正態分佈的隨機變量"><i class="fa fa-check"></i><b>17.1</b> 服從正態分佈的隨機變量</a></li>
<li class="chapter" data-level="17.2" data-path="normal-error-models.html"><a href="normal-error-models.html#Fandtdistr"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</a></li>
<li class="chapter" data-level="17.3" data-path="normal-error-models.html"><a href="normal-error-models.html#兩個參數的模型"><i class="fa fa-check"></i><b>17.3</b> 兩個參數的模型</a><ul>
<li class="chapter" data-level="17.3.1" data-path="normal-error-models.html"><a href="normal-error-models.html#一組數據兩個參數"><i class="fa fa-check"></i><b>17.3.1</b> 一組數據兩個參數</a></li>
<li class="chapter" data-level="17.3.2" data-path="normal-error-models.html"><a href="normal-error-models.html#兩組數據各一個參數"><i class="fa fa-check"></i><b>17.3.2</b> 兩組數據各一個參數</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="normal-error-models.html"><a href="normal-error-models.html#正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導"><i class="fa fa-check"></i><b>17.4</b> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</a></li>
<li class="chapter" data-level="17.5" data-path="normal-error-models.html"><a href="normal-error-models.html#比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2"><i class="fa fa-check"></i><b>17.5</b> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="17.6" data-path="normal-error-models.html"><a href="normal-error-models.html#各個統計分佈之間的關係"><i class="fa fa-check"></i><b>17.6</b> 各個統計分佈之間的關係</a></li>
<li class="chapter" data-level="17.7" data-path="normal-error-models.html"><a href="normal-error-models.html#inference-practical-09"><i class="fa fa-check"></i><b>17.7</b> Inference Practical 09</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html"><i class="fa fa-check"></i><b>18</b> 多個參數時的統計推斷 Inference with multiple parameters I</a><ul>
<li class="chapter" data-level="18.1" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#多參數-multiple-parameters---lrt"><i class="fa fa-check"></i><b>18.1</b> 多參數 multiple parameters - LRT</a><ul>
<li class="chapter" data-level="18.1.1" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#似然-likelihood"><i class="fa fa-check"></i><b>18.1.1</b> 似然 likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#對數似然比檢驗"><i class="fa fa-check"></i><b>18.1.2</b> 對數似然比檢驗</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#多參數-wald-檢驗---wald-test"><i class="fa fa-check"></i><b>18.2</b> 多參數 Wald 檢驗 - Wald test</a></li>
<li class="chapter" data-level="18.3" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#多參數-score-檢驗---score-test"><i class="fa fa-check"></i><b>18.3</b> 多參數 Score 檢驗 - Score test</a></li>
<li class="chapter" data-level="18.4" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#condilikeli"><i class="fa fa-check"></i><b>18.4</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="18.5" data-path="inference-with-multiple-para.html"><a href="inference-with-multiple-para.html#inference-practical-10"><i class="fa fa-check"></i><b>18.5</b> Inference Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html"><i class="fa fa-check"></i><b>19</b> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</a><ul>
<li class="chapter" data-level="19.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集似然法推導的過程總結"><i class="fa fa-check"></i><b>19.1</b> 子集似然法推導的過程總結</a><ul>
<li class="chapter" data-level="19.1.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然方程的分佈"><i class="fa fa-check"></i><b>19.1.1</b> 子集對數似然方程的分佈</a></li>
<li class="chapter" data-level="19.1.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#假設檢驗過程舉例"><i class="fa fa-check"></i><b>19.1.2</b> 假設檢驗過程舉例</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然比的近似"><i class="fa fa-check"></i><b>19.2</b> 子集對數似然比的近似</a><ul>
<li class="chapter" data-level="19.2.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然比近似的一般化"><i class="fa fa-check"></i><b>19.2.1</b> 子集對數似然比近似的一般化</a></li>
<li class="chapter" data-level="19.2.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#事件發生率之比的-wald-檢驗統計量"><i class="fa fa-check"></i><b>19.2.2</b> 事件發生率之比的 Wald 檢驗統計量</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#practical0"><i class="fa fa-check"></i><b>19.3</b> Inference Practical 11</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>20</b> 統計推斷總結</a><ul>
<li class="chapter" data-level="20.0.1" data-path="summary.html"><a href="summary.html#快速複習"><i class="fa fa-check"></i><b>20.0.1</b> 快速複習</a></li>
<li class="chapter" data-level="20.0.2" data-path="summary.html"><a href="summary.html#試爲下面的醫學研究問題提出合適的統計學模型"><i class="fa fa-check"></i><b>20.0.2</b> 試爲下面的醫學研究問題提出合適的統計學模型</a></li>
<li class="chapter" data-level="20.0.3" data-path="summary.html"><a href="summary.html#醫生來找統計學家問問題"><i class="fa fa-check"></i><b>20.0.3</b> 醫生來找統計學家問問題</a></li>
</ul></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="21" data-path="descriptive-stat.html"><a href="descriptive-stat.html"><i class="fa fa-check"></i><b>21</b> 探索數據和簡單描述</a><ul>
<li class="chapter" data-level="21.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據分析的流程"><i class="fa fa-check"></i><b>21.1</b> 數據分析的流程</a><ul>
<li class="chapter" data-level="21.1.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#研究設計和實施"><i class="fa fa-check"></i><b>21.1.1</b> 研究設計和實施</a></li>
<li class="chapter" data-level="21.1.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據分析"><i class="fa fa-check"></i><b>21.1.2</b> 數據分析</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據類型"><i class="fa fa-check"></i><b>21.2</b> 數據類型</a></li>
<li class="chapter" data-level="21.3" data-path="descriptive-stat.html"><a href="descriptive-stat.html#如何總結並展示數據"><i class="fa fa-check"></i><b>21.3</b> 如何總結並展示數據</a><ul>
<li class="chapter" data-level="21.3.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#離散型分類型數據的描述---頻數分佈表-frequency-table"><i class="fa fa-check"></i><b>21.3.1</b> 離散型分類型數據的描述 - 頻數分佈表 frequency table</a></li>
<li class="chapter" data-level="21.3.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#連續型變量"><i class="fa fa-check"></i><b>21.3.2</b> 連續型變量</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="descriptive-stat.html"><a href="descriptive-stat.html#數據總結方案位置分散偏度和峰度"><i class="fa fa-check"></i><b>21.4</b> 數據總結方案：位置，分散，偏度，和峰度</a><ul>
<li class="chapter" data-level="21.4.1" data-path="descriptive-stat.html"><a href="descriptive-stat.html#位置"><i class="fa fa-check"></i><b>21.4.1</b> 位置</a></li>
<li class="chapter" data-level="21.4.2" data-path="descriptive-stat.html"><a href="descriptive-stat.html#分散"><i class="fa fa-check"></i><b>21.4.2</b> 分散</a></li>
<li class="chapter" data-level="21.4.3" data-path="descriptive-stat.html"><a href="descriptive-stat.html#偏度-skewness"><i class="fa fa-check"></i><b>21.4.3</b> 偏度 skewness</a></li>
<li class="chapter" data-level="21.4.4" data-path="descriptive-stat.html"><a href="descriptive-stat.html#峯度-kurtosis"><i class="fa fa-check"></i><b>21.4.4</b> 峯度 kurtosis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>22</b> 信賴區間 confidence intervals</a><ul>
<li class="chapter" data-level="22.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#定義"><i class="fa fa-check"></i><b>22.1</b> 定義</a></li>
<li class="chapter" data-level="22.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#利用總體參數的樣本分佈求信賴區間"><i class="fa fa-check"></i><b>22.2</b> 利用總體參數的樣本分佈求信賴區間</a></li>
<li class="chapter" data-level="22.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#情況1已知方差的正態分佈數據均值的信賴區間"><i class="fa fa-check"></i><b>22.3</b> 情況1：已知方差的正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="22.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#CImean"><i class="fa fa-check"></i><b>22.4</b> 信賴區間的意義</a></li>
<li class="chapter" data-level="22.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#AT2-5"><i class="fa fa-check"></i><b>22.5</b> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="22.6" data-path="confidence-intervals.html"><a href="confidence-intervals.html#varCI"><i class="fa fa-check"></i><b>22.6</b> 情況3：服從正態分佈的隨機變量方差的信賴區間</a></li>
<li class="chapter" data-level="22.7" data-path="confidence-intervals.html"><a href="confidence-intervals.html#當樣本量足夠大時"><i class="fa fa-check"></i><b>22.7</b> 當樣本量足夠大時</a></li>
<li class="chapter" data-level="22.8" data-path="confidence-intervals.html"><a href="confidence-intervals.html#情況4求人羣百分比的信賴區間"><i class="fa fa-check"></i><b>22.8</b> 情況4：求人羣百分比的信賴區間</a><ul>
<li class="chapter" data-level="22.8.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#一般原則"><i class="fa fa-check"></i><b>22.8.1</b> 一般原則</a></li>
<li class="chapter" data-level="22.8.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#exactprop"><i class="fa fa-check"></i><b>22.8.2</b> 二項分佈的“精確法”計算信賴區間</a></li>
<li class="chapter" data-level="22.8.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#二項分佈的近似法計算信賴區間"><i class="fa fa-check"></i><b>22.8.3</b> 二項分佈的近似法計算信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="22.9" data-path="confidence-intervals.html"><a href="confidence-intervals.html#CIrate"><i class="fa fa-check"></i><b>22.9</b> 率的信賴區間</a><ul>
<li class="chapter" data-level="22.9.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#利用泊松分佈精確計算"><i class="fa fa-check"></i><b>22.9.1</b> 利用泊松分佈精確計算</a></li>
<li class="chapter" data-level="22.9.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#利用正態近似法計算"><i class="fa fa-check"></i><b>22.9.2</b> 利用正態近似法計算</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="hypo-tests.html"><a href="hypo-tests.html"><i class="fa fa-check"></i><b>23</b> 假設檢驗</a><ul>
<li class="chapter" data-level="23.1" data-path="hypo-tests.html"><a href="hypo-tests.html#拋硬幣的例子"><i class="fa fa-check"></i><b>23.1</b> 拋硬幣的例子</a><ul>
<li class="chapter" data-level="23.1.1" data-path="hypo-tests.html"><a href="hypo-tests.html#單側和雙側檢驗"><i class="fa fa-check"></i><b>23.1.1</b> 單側和雙側檢驗</a></li>
<li class="chapter" data-level="23.1.2" data-path="hypo-tests.html"><a href="hypo-tests.html#p-值的意義"><i class="fa fa-check"></i><b>23.1.2</b> <span class="math inline">\(p\)</span> 值的意義</a></li>
<li class="chapter" data-level="23.1.3" data-path="hypo-tests.html"><a href="hypo-tests.html#p-值和信賴區間的關係"><i class="fa fa-check"></i><b>23.1.3</b> <span class="math inline">\(p\)</span> 值和信賴區間的關係</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="hypo-tests.html"><a href="hypo-tests.html#二項分佈的精確假設檢驗"><i class="fa fa-check"></i><b>23.2</b> 二項分佈的精確假設檢驗</a></li>
<li class="chapter" data-level="23.3" data-path="hypo-tests.html"><a href="hypo-tests.html#當樣本量較大"><i class="fa fa-check"></i><b>23.3</b> 當樣本量較大</a></li>
<li class="chapter" data-level="23.4" data-path="hypo-tests.html"><a href="hypo-tests.html#二項分佈的正態近似法假設檢驗"><i class="fa fa-check"></i><b>23.4</b> 二項分佈的正態近似法假設檢驗</a><ul>
<li class="chapter" data-level="23.4.1" data-path="hypo-tests.html"><a href="hypo-tests.html#連續性校正-continuity-correction"><i class="fa fa-check"></i><b>23.4.1</b> 連續性校正 continuity correction</a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="hypo-tests.html"><a href="hypo-tests.html#AT3-5"><i class="fa fa-check"></i><b>23.5</b> 情況1：對均值進行假設檢驗 (方差已知)</a></li>
<li class="chapter" data-level="23.6" data-path="hypo-tests.html"><a href="hypo-tests.html#OneSampleT"><i class="fa fa-check"></i><b>23.6</b> 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test</a></li>
<li class="chapter" data-level="23.7" data-path="hypo-tests.html"><a href="hypo-tests.html#情況3對配對實驗數據的均值差進行假設檢驗-the-paired-t-test"><i class="fa fa-check"></i><b>23.7</b> 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="association.html"><a href="association.html"><i class="fa fa-check"></i><b>24</b> 相關 association</a><ul>
<li class="chapter" data-level="24.1" data-path="association.html"><a href="association.html#背景介紹"><i class="fa fa-check"></i><b>24.1</b> 背景介紹</a></li>
<li class="chapter" data-level="24.2" data-path="association.html"><a href="association.html#兩個連續型變量的相關分析"><i class="fa fa-check"></i><b>24.2</b> 兩個連續型變量的相關分析</a><ul>
<li class="chapter" data-level="24.2.1" data-path="association.html"><a href="association.html#相關係數的定義"><i class="fa fa-check"></i><b>24.2.1</b> 相關係數的定義</a></li>
<li class="chapter" data-level="24.2.2" data-path="association.html"><a href="association.html#相關係數的性質"><i class="fa fa-check"></i><b>24.2.2</b> 相關係數的性質</a></li>
<li class="chapter" data-level="24.2.3" data-path="association.html"><a href="association.html#對相關係數是否爲零進行假設檢驗"><i class="fa fa-check"></i><b>24.2.3</b> 對相關係數是否爲零進行假設檢驗</a></li>
<li class="chapter" data-level="24.2.4" data-path="association.html"><a href="association.html#相關係數的-95-信賴區間"><i class="fa fa-check"></i><b>24.2.4</b> 相關係數的 <span class="math inline">\(95\%\)</span> 信賴區間</a></li>
<li class="chapter" data-level="24.2.5" data-path="association.html"><a href="association.html#比較兩個相關係數是否相等"><i class="fa fa-check"></i><b>24.2.5</b> 比較兩個相關係數是否相等</a></li>
<li class="chapter" data-level="24.2.6" data-path="association.html"><a href="association.html#相關係數那些事兒"><i class="fa fa-check"></i><b>24.2.6</b> 相關係數那些事兒</a></li>
<li class="chapter" data-level="24.2.7" data-path="association.html"><a href="association.html#在-r-裏面計算相關係數"><i class="fa fa-check"></i><b>24.2.7</b> 在 R 裏面計算相關係數</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="association.html"><a href="association.html#二元變量之間的相關性-association-between-pairs-of-binary-variables"><i class="fa fa-check"></i><b>24.3</b> 二元變量之間的相關性 association between pairs of binary variables</a><ul>
<li class="chapter" data-level="24.3.1" data-path="association.html"><a href="association.html#or-的信賴區間"><i class="fa fa-check"></i><b>24.3.1</b> OR 的信賴區間</a></li>
<li class="chapter" data-level="24.3.2" data-path="association.html"><a href="association.html#比值比的假設檢驗"><i class="fa fa-check"></i><b>24.3.2</b> 比值比的假設檢驗</a></li>
<li class="chapter" data-level="24.3.3" data-path="association.html"><a href="association.html#chisquaretest"><i class="fa fa-check"></i><b>24.3.3</b> 兩個百分比的卡方檢驗</a></li>
<li class="chapter" data-level="24.3.4" data-path="association.html"><a href="association.html#確切檢驗法-fishers-exact-test"><i class="fa fa-check"></i><b>24.3.4</b> 確切檢驗法 Fisher’s “exact” test</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="association.html"><a href="association.html#多分類-無排序-的情況-mtimes-n-表格"><i class="fa fa-check"></i><b>24.4</b> 多分類 (無排序) 的情況 <span class="math inline">\(M\times N\)</span> 表格</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="comparisons.html"><a href="comparisons.html"><i class="fa fa-check"></i><b>25</b> 比較 Comparisons</a><ul>
<li class="chapter" data-level="25.1" data-path="comparisons.html"><a href="comparisons.html#比較兩個均值-comparing-two-population-means"><i class="fa fa-check"></i><b>25.1</b> 比較兩個均值 comparing two population means</a><ul>
<li class="chapter" data-level="25.1.1" data-path="comparisons.html"><a href="comparisons.html#當方差已知且數據服從正態分佈-z-test"><i class="fa fa-check"></i><b>25.1.1</b> 當方差已知，且數據服從正態分佈 Z-test</a></li>
<li class="chapter" data-level="25.1.2" data-path="comparisons.html"><a href="comparisons.html#當方差未知但是方差可以被認爲相等且數據服從正態分佈-two-sample-t-test"><i class="fa fa-check"></i><b>25.1.2</b> 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="25.1.3" data-path="comparisons.html"><a href="comparisons.html#練習"><i class="fa fa-check"></i><b>25.1.3</b> 練習</a></li>
<li class="chapter" data-level="25.1.4" data-path="comparisons.html"><a href="comparisons.html#當方差未知但是方差不可以被認爲相等且數據服從正態分佈"><i class="fa fa-check"></i><b>25.1.4</b> 當方差未知，但是方差<strong>不可以</strong>被認爲相等，且數據服從正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="comparisons.html"><a href="comparisons.html#兩個人羣的方差比較"><i class="fa fa-check"></i><b>25.2</b> 兩個人羣的方差比較</a><ul>
<li class="chapter" data-level="25.2.1" data-path="comparisons.html"><a href="comparisons.html#Ftest"><i class="fa fa-check"></i><b>25.2.1</b> 方差比值檢驗 variance ratio test</a></li>
<li class="chapter" data-level="25.2.2" data-path="comparisons.html"><a href="comparisons.html#信賴區間"><i class="fa fa-check"></i><b>25.2.2</b> 信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="comparisons.html"><a href="comparisons.html#比較兩個百分比"><i class="fa fa-check"></i><b>25.3</b> 比較兩個百分比</a><ul>
<li class="chapter" data-level="25.3.1" data-path="comparisons.html"><a href="comparisons.html#proportiontest"><i class="fa fa-check"></i><b>25.3.1</b> 兩個百分比差是否爲零的推斷 Risk difference</a></li>
<li class="chapter" data-level="25.3.2" data-path="comparisons.html"><a href="comparisons.html#兩個百分比商是否爲-1-的推斷-relative-riskrisk-ratio"><i class="fa fa-check"></i><b>25.3.2</b> 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>26</b> 前提和數據轉換 Assumptions and transformations</a><ul>
<li class="chapter" data-level="26.1" data-path="assumptions.html"><a href="assumptions.html#穩健性"><i class="fa fa-check"></i><b>26.1</b> 穩健性</a></li>
<li class="chapter" data-level="26.2" data-path="assumptions.html"><a href="assumptions.html#正態性"><i class="fa fa-check"></i><b>26.2</b> 正態性</a><ul>
<li class="chapter" data-level="26.2.1" data-path="assumptions.html"><a href="assumptions.html#normalplot"><i class="fa fa-check"></i><b>26.2.1</b> 正態分佈圖 normal plot</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="assumptions.html"><a href="assumptions.html#總結連續型變量不服從正態分佈時的處理方案"><i class="fa fa-check"></i><b>26.3</b> 總結連續型變量不服從正態分佈時的處理方案</a></li>
<li class="chapter" data-level="26.4" data-path="assumptions.html"><a href="assumptions.html#數學冪轉換-power-transformations"><i class="fa fa-check"></i><b>26.4</b> 數學冪轉換 power transformations</a><ul>
<li class="chapter" data-level="26.4.1" data-path="assumptions.html"><a href="assumptions.html#對數轉換-logarithmic-transformation"><i class="fa fa-check"></i><b>26.4.1</b> 對數轉換 logarithmic Transformation</a></li>
<li class="chapter" data-level="26.4.2" data-path="assumptions.html"><a href="assumptions.html#逆轉換信賴區間-back-transformation-of-cis"><i class="fa fa-check"></i><b>26.4.2</b> 逆轉換信賴區間 back-transformation of CIs</a></li>
<li class="chapter" data-level="26.4.3" data-path="assumptions.html"><a href="assumptions.html#對數正態分佈-log-normal-distribution"><i class="fa fa-check"></i><b>26.4.3</b> 對數正態分佈 log-normal distribution</a></li>
<li class="chapter" data-level="26.4.4" data-path="assumptions.html"><a href="assumptions.html#百分比的轉換"><i class="fa fa-check"></i><b>26.4.4</b> 百分比的轉換</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="27" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>27</b> 簡單線性迴歸 Simple Linear Regression</a><ul>
<li class="chapter" data-level="27.1" data-path="lm.html"><a href="lm.html#一些背景和術語"><i class="fa fa-check"></i><b>27.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="27.2" data-path="lm.html"><a href="lm.html#簡單線性迴歸模型-simple-linear-regression-model"><i class="fa fa-check"></i><b>27.2</b> 簡單線性迴歸模型 simple linear regression model</a><ul>
<li class="chapter" data-level="27.2.1" data-path="lm.html"><a href="lm.html#數據-a"><i class="fa fa-check"></i><b>27.2.1</b> 數據 A</a></li>
<li class="chapter" data-level="27.2.2" data-path="lm.html"><a href="lm.html#數據-b"><i class="fa fa-check"></i><b>27.2.2</b> 數據 B</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="lm.html"><a href="lm.html#區分因變量和預測變量"><i class="fa fa-check"></i><b>27.3</b> 區分因變量和預測變量</a><ul>
<li class="chapter" data-level="27.3.1" data-path="lm.html"><a href="lm.html#meanfunction"><i class="fa fa-check"></i><b>27.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="27.3.2" data-path="lm.html"><a href="lm.html#條件分佈和方差-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>27.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="27.3.3" data-path="lm.html"><a href="lm.html#defLM"><i class="fa fa-check"></i><b>27.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="27.3.4" data-path="lm.html"><a href="lm.html#殘差-residuals"><i class="fa fa-check"></i><b>27.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="lm.html"><a href="lm.html#參數的估計-estimation-of-parameters"><i class="fa fa-check"></i><b>27.4</b> 參數的估計 estimation of parameters</a><ul>
<li class="chapter" data-level="27.4.1" data-path="lm.html"><a href="lm.html#MLEalphabeta"><i class="fa fa-check"></i><b>27.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="lm.html"><a href="lm.html#ResidualVar"><i class="fa fa-check"></i><b>27.5</b> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></a></li>
<li class="chapter" data-level="27.6" data-path="lm.html"><a href="lm.html#growgam"><i class="fa fa-check"></i><b>27.6</b> R 演示 例 1： 圖 @ref(fig:age-wt) 數據</a></li>
<li class="chapter" data-level="27.7" data-path="lm.html"><a href="lm.html#binarylms"><i class="fa fa-check"></i><b>27.7</b> R 演示 例 2： 表@ref(tab:walk) 數據</a></li>
<li class="chapter" data-level="27.8" data-path="lm.html"><a href="lm.html#exeChol"><i class="fa fa-check"></i><b>27.8</b> LM practical 01</a><ul>
<li class="chapter" data-level="27.8.1" data-path="lm.html"><a href="lm.html#兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些"><i class="fa fa-check"></i><b>27.8.1</b> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</a></li>
<li class="chapter" data-level="27.8.2" data-path="lm.html"><a href="lm.html#計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta"><i class="fa fa-check"></i><b>27.8.2</b> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></a></li>
<li class="chapter" data-level="27.8.3" data-path="lm.html"><a href="lm.html#和迴歸模型計算的結果作比較解釋這些估計值的含義"><i class="fa fa-check"></i><b>27.8.3</b> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</a></li>
<li class="chapter" data-level="27.8.4" data-path="lm.html"><a href="lm.html#加上計算的估計值直線-即迴歸直線"><i class="fa fa-check"></i><b>27.8.4</b> 加上計算的估計值直線 (即迴歸直線)</a></li>
<li class="chapter" data-level="27.8.5" data-path="lm.html"><a href="lm.html#diagnosis"><i class="fa fa-check"></i><b>27.8.5</b> 下面的代碼用於模型的假設診斷</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="OLS.html"><a href="OLS.html"><i class="fa fa-check"></i><b>28</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a><ul>
<li class="chapter" data-level="28.1" data-path="OLS.html"><a href="OLS.html#ols-估計量的性質"><i class="fa fa-check"></i><b>28.1</b> OLS 估計量的性質</a></li>
<li class="chapter" data-level="28.2" data-path="OLS.html"><a href="OLS.html#beta"><i class="fa fa-check"></i><b>28.2</b> <span class="math inline">\(\hat\beta\)</span> 的性質</a><ul>
<li class="chapter" data-level="28.2.1" data-path="OLS.html"><a href="OLS.html#randbeta"><i class="fa fa-check"></i><b>28.2.1</b> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</a></li>
<li class="chapter" data-level="28.2.2" data-path="OLS.html"><a href="OLS.html#例-1-還是圖-reffigage-wt-數據"><i class="fa fa-check"></i><b>28.2.2</b> 例 1： 還是圖 @ref(fig:age-wt) 數據</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="OLS.html"><a href="OLS.html#截距和迴歸係數的方差協方差"><i class="fa fa-check"></i><b>28.3</b> 截距和迴歸係數的方差，協方差</a><ul>
<li class="chapter" data-level="28.3.1" data-path="OLS.html"><a href="OLS.html#centring"><i class="fa fa-check"></i><b>28.3.1</b> 中心化 centring</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="OLS.html"><a href="OLS.html#alpha-beta-的推斷"><i class="fa fa-check"></i><b>28.4</b> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</a><ul>
<li class="chapter" data-level="28.4.1" data-path="OLS.html"><a href="OLS.html#對迴歸係數進行假設檢驗"><i class="fa fa-check"></i><b>28.4.1</b> 對迴歸係數進行假設檢驗</a></li>
<li class="chapter" data-level="28.4.2" data-path="OLS.html"><a href="OLS.html#迴歸係數截距的信賴區間"><i class="fa fa-check"></i><b>28.4.2</b> 迴歸係數，截距的信賴區間</a></li>
<li class="chapter" data-level="28.4.3" data-path="OLS.html"><a href="OLS.html#預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性"><i class="fa fa-check"></i><b>28.4.3</b> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</a></li>
<li class="chapter" data-level="28.4.4" data-path="OLS.html"><a href="OLS.html#預測帶-reference-range---包含了-95-觀察值的區間"><i class="fa fa-check"></i><b>28.4.4</b> 預測帶 Reference range - 包含了 95% 觀察值的區間</a></li>
</ul></li>
<li class="chapter" data-level="28.5" data-path="OLS.html"><a href="OLS.html#rsquare"><i class="fa fa-check"></i><b>28.5</b> 線性迴歸模型和 Pearson 相關係數</a><ul>
<li class="chapter" data-level="28.5.1" data-path="OLS.html"><a href="OLS.html#r2-可以理解爲因變量平方和被模型解釋的比例"><i class="fa fa-check"></i><b>28.5.1</b> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</a></li>
</ul></li>
<li class="chapter" data-level="28.6" data-path="OLS.html"><a href="OLS.html#t-r2-F"><i class="fa fa-check"></i><b>28.6</b> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</a></li>
<li class="chapter" data-level="28.7" data-path="OLS.html"><a href="OLS.html#lm-practical-02"><i class="fa fa-check"></i><b>28.7</b> LM practical 02</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="ANOVA.html"><a href="ANOVA.html"><i class="fa fa-check"></i><b>29</b> 方差分析 Introduction to Analysis of Variance</a><ul>
<li class="chapter" data-level="29.1" data-path="ANOVA.html"><a href="ANOVA.html#背景"><i class="fa fa-check"></i><b>29.1</b> 背景</a></li>
<li class="chapter" data-level="29.2" data-path="ANOVA.html"><a href="ANOVA.html#簡單線性迴歸模型的方差分析"><i class="fa fa-check"></i><b>29.2</b> 簡單線性迴歸模型的方差分析</a><ul>
<li class="chapter" data-level="29.2.1" data-path="ANOVA.html"><a href="ANOVA.html#兩個模型的參數估計"><i class="fa fa-check"></i><b>29.2.1</b> 兩個模型的參數估計</a></li>
<li class="chapter" data-level="29.2.2" data-path="ANOVA.html"><a href="ANOVA.html#分割零假設模型的殘差平方和"><i class="fa fa-check"></i><b>29.2.2</b> 分割零假設模型的殘差平方和</a></li>
<li class="chapter" data-level="29.2.3" data-path="ANOVA.html"><a href="ANOVA.html#Rsquare"><i class="fa fa-check"></i><b>29.2.3</b> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</a></li>
<li class="chapter" data-level="29.2.4" data-path="ANOVA.html"><a href="ANOVA.html#方差分析表格-the-anova-table"><i class="fa fa-check"></i><b>29.2.4</b> 方差分析表格 the ANOVA table</a></li>
<li class="chapter" data-level="29.2.5" data-path="ANOVA.html"><a href="ANOVA.html#用-anova-進行假設檢驗"><i class="fa fa-check"></i><b>29.2.5</b> 用 ANOVA 進行假設檢驗</a></li>
<li class="chapter" data-level="29.2.6" data-path="ANOVA.html"><a href="ANOVA.html#lm-Ftest"><i class="fa fa-check"></i><b>29.2.6</b> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</a></li>
<li class="chapter" data-level="29.2.7" data-path="ANOVA.html"><a href="ANOVA.html#F-t-same"><i class="fa fa-check"></i><b>29.2.7</b> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</a></li>
</ul></li>
<li class="chapter" data-level="29.3" data-path="ANOVA.html"><a href="ANOVA.html#分類變量用作預測變量時的-anova"><i class="fa fa-check"></i><b>29.3</b> 分類變量用作預測變量時的 ANOVA</a><ul>
<li class="chapter" data-level="29.3.1" data-path="ANOVA.html"><a href="ANOVA.html#一個二分類預測變量"><i class="fa fa-check"></i><b>29.3.1</b> 一個二分類預測變量</a></li>
<li class="chapter" data-level="29.3.2" data-path="ANOVA.html"><a href="ANOVA.html#一個模型兩種表述"><i class="fa fa-check"></i><b>29.3.2</b> 一個模型，兩種表述</a></li>
<li class="chapter" data-level="29.3.3" data-path="ANOVA.html"><a href="ANOVA.html#分組變量的平方和"><i class="fa fa-check"></i><b>29.3.3</b> 分組變量的平方和</a></li>
<li class="chapter" data-level="29.3.4" data-path="ANOVA.html"><a href="ANOVA.html#簡單模型的分組變量大於兩組的情況"><i class="fa fa-check"></i><b>29.3.4</b> 簡單模型的分組變量大於兩組的情況</a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="ANOVA.html"><a href="ANOVA.html#lm-practical-03"><i class="fa fa-check"></i><b>29.4</b> LM practical 03</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="multivariable-models.html"><a href="multivariable-models.html"><i class="fa fa-check"></i><b>30</b> 多元模型分析 Multivariable Models</a><ul>
<li class="chapter" data-level="30.1" data-path="multivariable-models.html"><a href="multivariable-models.html#兩個預測變量的線性迴歸模型"><i class="fa fa-check"></i><b>30.1</b> 兩個預測變量的線性迴歸模型</a><ul>
<li class="chapter" data-level="30.1.1" data-path="multivariable-models.html"><a href="multivariable-models.html#數學標記法和解釋"><i class="fa fa-check"></i><b>30.1.1</b> 數學標記法和解釋</a></li>
<li class="chapter" data-level="30.1.2" data-path="multivariable-models.html"><a href="multivariable-models.html#最小平方和估計-least-squares-estimation"><i class="fa fa-check"></i><b>30.1.2</b> 最小平方和估計 Least Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="multivariable-models.html"><a href="multivariable-models.html#線性回歸模型中使用分組變量"><i class="fa fa-check"></i><b>30.2</b> 線性回歸模型中使用分組變量</a></li>
<li class="chapter" data-level="30.3" data-path="multivariable-models.html"><a href="multivariable-models.html#協方差分析模型-the-analysis-of-covariance-ancova-model"><i class="fa fa-check"></i><b>30.3</b> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</a></li>
<li class="chapter" data-level="30.4" data-path="multivariable-models.html"><a href="multivariable-models.html#偏回歸係數的變化"><i class="fa fa-check"></i><b>30.4</b> 偏回歸係數的變化</a><ul>
<li class="chapter" data-level="30.4.1" data-path="multivariable-models.html"><a href="multivariable-models.html#情況1-beta_1-beta_1"><i class="fa fa-check"></i><b>30.4.1</b> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></a></li>
<li class="chapter" data-level="30.4.2" data-path="multivariable-models.html"><a href="multivariable-models.html#情況2beta_1beta_1"><i class="fa fa-check"></i><b>30.4.2</b> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></a></li>
<li class="chapter" data-level="30.4.3" data-path="multivariable-models.html"><a href="multivariable-models.html#情況3-beta_1-beta_1"><i class="fa fa-check"></i><b>30.4.3</b> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="multivariable-models.html"><a href="multivariable-models.html#confounding"><i class="fa fa-check"></i><b>30.5</b> 混雜 confounding</a><ul>
<li class="chapter" data-level="30.5.1" data-path="multivariable-models.html"><a href="multivariable-models.html#作為媒介-mediation-effect"><i class="fa fa-check"></i><b>30.5.1</b> 作為媒介 mediation effect</a></li>
<li class="chapter" data-level="30.5.2" data-path="multivariable-models.html"><a href="multivariable-models.html#兩個預測變量之間的關係"><i class="fa fa-check"></i><b>30.5.2</b> 兩個預測變量之間的關係</a></li>
<li class="chapter" data-level="30.5.3" data-path="multivariable-models.html"><a href="multivariable-models.html#rct臨床實驗是個特例"><i class="fa fa-check"></i><b>30.5.3</b> RCT臨床實驗是個特例</a></li>
</ul></li>
<li class="chapter" data-level="30.6" data-path="multivariable-models.html"><a href="multivariable-models.html#lm-practical-04"><i class="fa fa-check"></i><b>30.6</b> LM practical 04</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html"><i class="fa fa-check"></i><b>31</b> 多元模型分析：矩陣標記與其意義</a><ul>
<li class="chapter" data-level="31.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#線性回歸模型的矩陣非矩陣標記法"><i class="fa fa-check"></i><b>31.1</b> 線性回歸模型的矩陣/非矩陣標記法</a><ul>
<li class="chapter" data-level="31.1.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#模型標記"><i class="fa fa-check"></i><b>31.1.1</b> 模型標記：</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#解讀參數"><i class="fa fa-check"></i><b>31.2</b> 解讀參數</a><ul>
<li class="chapter" data-level="31.2.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#最小二乘估計"><i class="fa fa-check"></i><b>31.2.1</b> 最小二乘估計</a></li>
<li class="chapter" data-level="31.2.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#因變量的期待值-mathbfhat-y"><i class="fa fa-check"></i><b>31.2.2</b> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></a></li>
<li class="chapter" data-level="31.2.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#殘差"><i class="fa fa-check"></i><b>31.2.3</b> 殘差</a></li>
</ul></li>
<li class="chapter" data-level="31.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#方差分析一般化和-f-檢驗"><i class="fa fa-check"></i><b>31.3</b> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</a><ul>
<li class="chapter" data-level="31.3.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#多元線性迴歸時的決定係數和殘差方差"><i class="fa fa-check"></i><b>31.3.1</b> 多元線性迴歸時的決定係數和殘差方差</a></li>
<li class="chapter" data-level="31.3.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#方差分析表格"><i class="fa fa-check"></i><b>31.3.2</b> 方差分析表格</a></li>
<li class="chapter" data-level="31.3.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#globalsig"><i class="fa fa-check"></i><b>31.3.3</b> 迴歸方程的顯著性檢驗</a></li>
<li class="chapter" data-level="31.3.4" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#partialF"><i class="fa fa-check"></i><b>31.3.4</b> <span class="math inline">\(\text{partial }F\)</span> 檢驗</a></li>
</ul></li>
<li class="chapter" data-level="31.4" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#添加新變量對迴歸模型的影響"><i class="fa fa-check"></i><b>31.4</b> 添加新變量對迴歸模型的影響</a><ul>
<li class="chapter" data-level="31.4.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#偏迴歸係數方差的改變"><i class="fa fa-check"></i><b>31.4.1</b> 偏迴歸係數方差的改變</a></li>
<li class="chapter" data-level="31.4.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#偏迴歸係數檢驗結果的改變"><i class="fa fa-check"></i><b>31.4.2</b> 偏迴歸係數檢驗結果的改變</a></li>
<li class="chapter" data-level="31.4.3" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#擬合值的改變"><i class="fa fa-check"></i><b>31.4.3</b> 擬合值的改變</a></li>
<li class="chapter" data-level="31.4.4" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#決定係數的改變"><i class="fa fa-check"></i><b>31.4.4</b> 決定係數的改變</a></li>
<li class="chapter" data-level="31.4.5" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#共線性-collinearity"><i class="fa fa-check"></i><b>31.4.5</b> 共線性 collinearity</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#實戰演習"><i class="fa fa-check"></i><b>31.5</b> 實戰演習</a><ul>
<li class="chapter" data-level="31.5.1" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#血清維生素-c-濃度的預測變量"><i class="fa fa-check"></i><b>31.5.1</b> 血清維生素 C 濃度的預測變量</a></li>
<li class="chapter" data-level="31.5.2" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#紅細胞容積與血紅蛋白"><i class="fa fa-check"></i><b>31.5.2</b> 紅細胞容積與血紅蛋白</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="matrix-multivariable.html"><a href="matrix-multivariable.html#lm-practical-05"><i class="fa fa-check"></i><b>31.6</b> LM practical 05</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="lm-diag.html"><a href="lm-diag.html"><i class="fa fa-check"></i><b>32</b> 線性迴歸的模型診斷</a><ul>
<li class="chapter" data-level="32.1" data-path="lm-diag.html"><a href="lm-diag.html#線性迴歸模型的前提條件"><i class="fa fa-check"></i><b>32.1</b> 線性迴歸模型的前提條件</a></li>
<li class="chapter" data-level="32.2" data-path="lm-diag.html"><a href="lm-diag.html#用圖形來視覺診斷"><i class="fa fa-check"></i><b>32.2</b> 用圖形來視覺診斷</a></li>
<li class="chapter" data-level="32.3" data-path="lm-diag.html"><a href="lm-diag.html#殘差圖"><i class="fa fa-check"></i><b>32.3</b> 殘差圖</a></li>
<li class="chapter" data-level="32.4" data-path="lm-diag.html"><a href="lm-diag.html#殘差正態圖-normal-plot-of-residuals"><i class="fa fa-check"></i><b>32.4</b> 殘差正態圖 normal plot of residuals</a><ul>
<li class="chapter" data-level="32.4.1" data-path="lm-diag.html"><a href="lm-diag.html#模型診斷實例"><i class="fa fa-check"></i><b>32.4.1</b> 模型診斷實例</a></li>
</ul></li>
<li class="chapter" data-level="32.5" data-path="lm-diag.html"><a href="lm-diag.html#前提條件的統計學檢驗"><i class="fa fa-check"></i><b>32.5</b> 前提條件的統計學檢驗</a><ul>
<li class="chapter" data-level="32.5.1" data-path="lm-diag.html"><a href="lm-diag.html#二次方程迴歸法檢驗非線性"><i class="fa fa-check"></i><b>32.5.1</b> 二次方程迴歸法檢驗非線性</a></li>
<li class="chapter" data-level="32.5.2" data-path="lm-diag.html"><a href="lm-diag.html#非線性關係模型"><i class="fa fa-check"></i><b>32.5.2</b> 非線性關係模型</a></li>
</ul></li>
<li class="chapter" data-level="32.6" data-path="lm-diag.html"><a href="lm-diag.html#異常值槓桿值和庫克距離"><i class="fa fa-check"></i><b>32.6</b> 異常值，槓桿值，和庫克距離</a><ul>
<li class="chapter" data-level="32.6.1" data-path="lm-diag.html"><a href="lm-diag.html#standardres"><i class="fa fa-check"></i><b>32.6.1</b> 異常值和標準化殘差</a></li>
<li class="chapter" data-level="32.6.2" data-path="lm-diag.html"><a href="lm-diag.html#槓桿值-leverage"><i class="fa fa-check"></i><b>32.6.2</b> 槓桿值 Leverage</a></li>
<li class="chapter" data-level="32.6.3" data-path="lm-diag.html"><a href="lm-diag.html#庫克距離-cooks-distance"><i class="fa fa-check"></i><b>32.6.3</b> 庫克距離 Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="32.7" data-path="lm-diag.html"><a href="lm-diag.html#在統計忍者包裏面對模型診斷作圖"><i class="fa fa-check"></i><b>32.7</b> 在統計忍者包裏面對模型診斷作圖</a></li>
<li class="chapter" data-level="32.8" data-path="lm-diag.html"><a href="lm-diag.html#lm-practical-06"><i class="fa fa-check"></i><b>32.8</b> LM practical 06</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>33</b> 交互作用 Interactions</a><ul>
<li class="chapter" data-level="33.1" data-path="interaction.html"><a href="interaction.html#兩個預測變量之間的線性模型交互作用"><i class="fa fa-check"></i><b>33.1</b> 兩個預測變量之間的線性模型交互作用</a><ul>
<li class="chapter" data-level="33.1.1" data-path="interaction.html"><a href="interaction.html#交互作用線性模型的一般表達式"><i class="fa fa-check"></i><b>33.1.1</b> 交互作用線性模型的一般表達式</a></li>
<li class="chapter" data-level="33.1.2" data-path="interaction.html"><a href="interaction.html#interaction-cont-bin"><i class="fa fa-check"></i><b>33.1.2</b> 連續型變量和二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="33.1.3" data-path="interaction.html"><a href="interaction.html#兩個二分類變量之間的交互作用"><i class="fa fa-check"></i><b>33.1.3</b> 兩個二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="33.1.4" data-path="interaction.html"><a href="interaction.html#兩個連續變量之間的交互作用"><i class="fa fa-check"></i><b>33.1.4</b> 兩個連續變量之間的交互作用</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="interaction.html"><a href="interaction.html#lm-practical-07"><i class="fa fa-check"></i><b>33.2</b> LM practical 07</a></li>
</ul></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="34" data-path="sample-size.html"><a href="sample-size.html"><i class="fa fa-check"></i><b>34</b> 樣本量計算問題</a><ul>
<li class="chapter" data-level="34.1" data-path="sample-size.html"><a href="sample-size.html#背景-1"><i class="fa fa-check"></i><b>34.1</b> 背景</a></li>
<li class="chapter" data-level="34.2" data-path="sample-size.html"><a href="sample-size.html#決定所需樣本量大小的統計學因素"><i class="fa fa-check"></i><b>34.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="34.3" data-path="sample-size.html"><a href="sample-size.html#第一類和第二類錯誤-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>34.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="34.4" data-path="sample-size.html"><a href="sample-size.html#比較兩組之間的百分比-percentages-or-proportions"><i class="fa fa-check"></i><b>34.4</b> 比較兩組之間的百分比 (percentages or proportions)</a><ul>
<li class="chapter" data-level="34.4.1" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式-使用顯著水平-5-和檢驗效能-90"><i class="fa fa-check"></i><b>34.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="34.4.2" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下"><i class="fa fa-check"></i><b>34.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="34.5" data-path="sample-size.html"><a href="sample-size.html#比較兩組之間的均值"><i class="fa fa-check"></i><b>34.5</b> 比較兩組之間的均值</a><ul>
<li class="chapter" data-level="34.5.1" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式"><i class="fa fa-check"></i><b>34.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="34.6" data-path="sample-size.html"><a href="sample-size.html#樣本量計算的調整"><i class="fa fa-check"></i><b>34.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="chapter" data-level="35" data-path="baseline-adjustment-using-ancova.html"><a href="baseline-adjustment-using-ancova.html"><i class="fa fa-check"></i><b>35</b> Baseline Adjustment using ANCOVA</a></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="36" data-path="robust-intro.html"><a href="robust-intro.html"><i class="fa fa-check"></i><b>36</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="37" data-path="rank-tests.html"><a href="rank-tests.html"><i class="fa fa-check"></i><b>37</b> 基於秩次的非參數檢驗</a><ul>
<li class="chapter" data-level="37.1" data-path="rank-tests.html"><a href="rank-tests.html#sign-test"><i class="fa fa-check"></i><b>37.1</b> 符號檢驗 the Sign test</a><ul>
<li class="chapter" data-level="37.1.1" data-path="rank-tests.html"><a href="rank-tests.html#符號檢驗的特點"><i class="fa fa-check"></i><b>37.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="37.2" data-path="rank-tests.html"><a href="rank-tests.html#Wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>37.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="37.3" data-path="rank-tests.html"><a href="rank-tests.html#wilcoxon-mann-whitney-wmw-檢驗"><i class="fa fa-check"></i><b>37.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="37.4" data-path="rank-tests.html"><a href="rank-tests.html#秩相關spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>37.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="37.5" data-path="rank-tests.html"><a href="rank-tests.html#基於秩次的非參數檢驗的優缺點"><i class="fa fa-check"></i><b>37.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="permutation.html"><a href="permutation.html"><i class="fa fa-check"></i><b>38</b> 排列置換法 Permutation procedures</a><ul>
<li class="chapter" data-level="38.1" data-path="permutation.html"><a href="permutation.html#背景介紹-1"><i class="fa fa-check"></i><b>38.1</b> 背景介紹</a></li>
<li class="chapter" data-level="38.2" data-path="permutation.html"><a href="permutation.html#直接上實例"><i class="fa fa-check"></i><b>38.2</b> 直接上實例</a></li>
<li class="chapter" data-level="38.3" data-path="permutation.html"><a href="permutation.html#排列置換法三板斧"><i class="fa fa-check"></i><b>38.3</b> 排列置換法三板斧</a><ul>
<li class="chapter" data-level="38.3.1" data-path="permutation.html"><a href="permutation.html#該如何選用合適的檢驗統計量-t"><i class="fa fa-check"></i><b>38.3.1</b> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</a></li>
<li class="chapter" data-level="38.3.2" data-path="permutation.html"><a href="permutation.html#可以在排列置換法中對其他變量進行統計學調整-adjustment-嗎"><i class="fa fa-check"></i><b>38.3.2</b> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</a></li>
<li class="chapter" data-level="38.3.3" data-path="permutation.html"><a href="permutation.html#排列置換法基於秩次的非參數檢驗之間的關係"><i class="fa fa-check"></i><b>38.3.3</b> 排列置換法，基於秩次的非參數檢驗之間的關係</a></li>
<li class="chapter" data-level="38.3.4" data-path="permutation.html"><a href="permutation.html#排列置換檢驗法是一種精確檢驗"><i class="fa fa-check"></i><b>38.3.4</b> 排列置換檢驗法，是一種精確檢驗</a></li>
</ul></li>
<li class="chapter" data-level="38.4" data-path="permutation.html"><a href="permutation.html#基於排序置換檢驗法計算信賴區間"><i class="fa fa-check"></i><b>38.4</b> 基於排序置換檢驗法計算信賴區間</a></li>
<li class="chapter" data-level="38.5" data-path="permutation.html"><a href="permutation.html#排序置換法的優缺點"><i class="fa fa-check"></i><b>38.5</b> 排序置換法的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i><b>39</b> 自助重抽法 The bootstrap</a><ul>
<li class="chapter" data-level="39.1" data-path="bootstrap.html"><a href="bootstrap.html#定義-1"><i class="fa fa-check"></i><b>39.1</b> 定義</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="the-sandwich-estimator.html"><a href="the-sandwich-estimator.html"><i class="fa fa-check"></i><b>40</b> The sandwich estimator</a></li>
<li class="part"><span><b>VII 貝葉斯統計 Introduction to Bayesian Statistics</b></span></li>
<li class="chapter" data-level="41" data-path="intro-Bayes.html"><a href="intro-Bayes.html"><i class="fa fa-check"></i><b>41</b> 貝葉斯統計入門</a><ul>
<li class="chapter" data-level="41.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#概率論推斷的複習"><i class="fa fa-check"></i><b>41.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="41.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#貝葉斯概率推理逆概率-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>41.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a><ul>
<li class="chapter" data-level="41.2.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#演繹推理-deductive-reasoning-和-三段論-weak-syllogisms"><i class="fa fa-check"></i><b>41.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="41.2.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#如何給可能性定量-quantifying-plausibility"><i class="fa fa-check"></i><b>41.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="intro-Bayes.html"><a href="intro-Bayes.html#貝葉斯推理的統計學實現"><i class="fa fa-check"></i><b>41.3</b> 貝葉斯推理的統計學實現</a><ul>
<li class="chapter" data-level="41.3.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#醫學診斷測試-diagnostic-testing"><i class="fa fa-check"></i><b>41.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="41.3.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#hiv-檢查時的應用"><i class="fa fa-check"></i><b>41.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="41.3.3" data-path="intro-Bayes.html"><a href="intro-Bayes.html#離散概率分佈實例遺傳學分析"><i class="fa fa-check"></i><b>41.3.3</b> 離散概率分佈實例：遺傳學分析</a></li>
<li class="chapter" data-level="41.3.4" data-path="intro-Bayes.html"><a href="intro-Bayes.html#說點小歷史"><i class="fa fa-check"></i><b>41.3.4</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="41.4" data-path="intro-Bayes.html"><a href="intro-Bayes.html#practical-intro-to-bayes-01"><i class="fa fa-check"></i><b>41.4</b> Practical Intro-to-Bayes 01</a></li>
</ul></li>
<li class="chapter" data-level="42" data-path="single-para-model.html"><a href="single-para-model.html"><i class="fa fa-check"></i><b>42</b> 貝葉斯定理的應用：單一參數模型 Single-parameter models</a><ul>
<li class="chapter" data-level="42.1" data-path="single-para-model.html"><a href="single-para-model.html#從二進制數據中估計概率-estimating-a-probability-from-binomial-data"><i class="fa fa-check"></i><b>42.1</b> 從二進制數據中估計概率 Estimating a probability from binomial data</a><ul>
<li class="chapter" data-level="42.1.1" data-path="single-para-model.html"><a href="single-para-model.html#事後概率分佈是數據和先驗概率分佈之間的妥協"><i class="fa fa-check"></i><b>42.1.1</b> 事後概率分佈是數據和先驗概率分佈之間的妥協</a></li>
<li class="chapter" data-level="42.1.2" data-path="single-para-model.html"><a href="single-para-model.html#不同先驗概率分佈對事後概率分佈估計的影響"><i class="fa fa-check"></i><b>42.1.2</b> 不同先驗概率分佈對事後概率分佈估計的影響</a></li>
<li class="chapter" data-level="42.1.3" data-path="single-para-model.html"><a href="single-para-model.html#從已知的事後概率分佈中採樣對採集的事後樣本數據轉換"><i class="fa fa-check"></i><b>42.1.3</b> 從已知的事後概率分佈中採樣，對採集的事後樣本數據轉換</a></li>
<li class="chapter" data-level="42.1.4" data-path="single-para-model.html"><a href="single-para-model.html#使用非共軛先驗概率計算事後概率分佈"><i class="fa fa-check"></i><b>42.1.4</b> 使用非共軛先驗概率計算事後概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="single-para-model.html"><a href="single-para-model.html#貝葉斯理論下的事後二項分佈概率密度方程-notation-for-probability-density-functions-in-binomial-data"><i class="fa fa-check"></i><b>42.2</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions in binomial data</a></li>
<li class="chapter" data-level="42.3" data-path="single-para-model.html"><a href="single-para-model.html#theta-的先驗概率"><i class="fa fa-check"></i><b>42.3</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a><ul>
<li class="chapter" data-level="42.3.1" data-path="single-para-model.html"><a href="single-para-model.html#beta-distribution-intro"><i class="fa fa-check"></i><b>42.3.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="42.3.2" data-path="single-para-model.html"><a href="single-para-model.html#conjugate"><i class="fa fa-check"></i><b>42.3.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="42.4" data-path="single-para-model.html"><a href="single-para-model.html#附贈加量不加價"><i class="fa fa-check"></i><b>42.4</b> 附贈–加量不加價</a></li>
<li class="chapter" data-level="42.5" data-path="single-para-model.html"><a href="single-para-model.html#practical-intro-to-bayes-02"><i class="fa fa-check"></i><b>42.5</b> Practical Intro-to-Bayes 02</a><ul>
<li class="chapter" data-level="42.5.1" data-path="single-para-model.html"><a href="single-para-model.html#q1-4"><i class="fa fa-check"></i><b>42.5.1</b> Q1</a></li>
<li class="chapter" data-level="42.5.2" data-path="single-para-model.html"><a href="single-para-model.html#q2-3"><i class="fa fa-check"></i><b>42.5.2</b> Q2</a></li>
<li class="chapter" data-level="42.5.3" data-path="single-para-model.html"><a href="single-para-model.html#q3-2"><i class="fa fa-check"></i><b>42.5.3</b> Q3</a></li>
<li class="chapter" data-level="42.5.4" data-path="single-para-model.html"><a href="single-para-model.html#q4"><i class="fa fa-check"></i><b>42.5.4</b> Q4</a></li>
<li class="chapter" data-level="42.5.5" data-path="single-para-model.html"><a href="single-para-model.html#q5"><i class="fa fa-check"></i><b>42.5.5</b> Q5</a></li>
<li class="chapter" data-level="42.5.6" data-path="single-para-model.html"><a href="single-para-model.html#q6"><i class="fa fa-check"></i><b>42.5.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="43" data-path="normal-distr.html"><a href="normal-distr.html"><i class="fa fa-check"></i><b>43</b> 貝葉斯理論在正態分布數據中的應用 Normal distribution applying Bayes’ Theorem</a><ul>
<li class="chapter" data-level="43.1" data-path="normal-distr.html"><a href="normal-distr.html#事後概率的總結方法"><i class="fa fa-check"></i><b>43.1</b> 事後概率的總結方法</a></li>
<li class="chapter" data-level="43.2" data-path="normal-distr.html"><a href="normal-distr.html#貝葉斯統計推斷中的正態分布"><i class="fa fa-check"></i><b>43.2</b> 貝葉斯統計推斷中的正態分布</a><ul>
<li class="chapter" data-level="43.2.1" data-path="normal-distr.html"><a href="normal-distr.html#n-independent-identically-distributed-observations"><i class="fa fa-check"></i><b>43.2.1</b> <span class="math inline">\(n\)</span> independent identically distributed observations</a></li>
</ul></li>
<li class="chapter" data-level="43.3" data-path="normal-distr.html"><a href="normal-distr.html#事後預測分佈-posterior-predictive-distribution"><i class="fa fa-check"></i><b>43.3</b> 事後預測分佈 Posterior predictive distribution</a></li>
</ul></li>
<li class="chapter" data-level="44" data-path="-other-standard-single-parameter-models.html"><a href="-other-standard-single-parameter-models.html"><i class="fa fa-check"></i><b>44</b> 其他典型的單一參數模型 Other standard single-parameter models</a><ul>
<li class="chapter" data-level="44.1" data-path="-other-standard-single-parameter-models.html"><a href="-other-standard-single-parameter-models.html#unknownvarBayes"><i class="fa fa-check"></i><b>44.1</b> 正（常）態分佈僅均值已知（方差未知） Normal distribution with known mean but unknown variance</a></li>
<li class="chapter" data-level="44.2" data-path="-other-standard-single-parameter-models.html"><a href="-other-standard-single-parameter-models.html#泊松分佈模型的貝葉斯思路-poisson-distribution-model-under-bayesian-framework"><i class="fa fa-check"></i><b>44.2</b> 泊松分佈模型的貝葉斯思路 Poisson distribution model under Bayesian framework</a></li>
<li class="chapter" data-level="44.3" data-path="-other-standard-single-parameter-models.html"><a href="-other-standard-single-parameter-models.html#泊松模型的其他表達形式-poisson-model-parameterized-in-terms-of-rate-and-exposure"><i class="fa fa-check"></i><b>44.3</b> 泊松模型的其他表達形式 poisson model parameterized in terms of rate and exposure</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="-introduction-to-multiparameter-models.html"><a href="-introduction-to-multiparameter-models.html"><i class="fa fa-check"></i><b>45</b> 多參數模型 Introduction to multiparameter models</a><ul>
<li class="chapter" data-level="45.1" data-path="-introduction-to-multiparameter-models.html"><a href="-introduction-to-multiparameter-models.html#把不需要的噪音參數平均出去-averaging-over-nuisance-parameters"><i class="fa fa-check"></i><b>45.1</b> 把不需要的噪音參數平均出去 Averaging over ‘nuisance parameters’</a></li>
<li class="chapter" data-level="45.2" data-path="-introduction-to-multiparameter-models.html"><a href="-introduction-to-multiparameter-models.html#未知均值也未知方差的正常態分佈數據-normal-data-with-unknown-mean-and-variance"><i class="fa fa-check"></i><b>45.2</b> 未知均值也未知方差的正（常）態分佈數據 normal data with unknown mean and variance</a><ul>
<li class="chapter" data-level="45.2.1" data-path="-introduction-to-multiparameter-models.html"><a href="-introduction-to-multiparameter-models.html#無信息先驗概率分佈-noninformative-prior-distribution"><i class="fa fa-check"></i><b>45.2.1</b> 無信息先驗概率分佈 noninformative prior distribution</a></li>
<li class="chapter" data-level="45.2.2" data-path="-introduction-to-multiparameter-models.html"><a href="-introduction-to-multiparameter-models.html#均值的事後邊際概率分佈-marginal-posterior-distribution-of-mu"><i class="fa fa-check"></i><b>45.2.2</b> 均值的事後邊際概率分佈 marginal posterior distribution of <span class="math inline">\(\mu\)</span></a></li>
</ul></li>
<li class="chapter" data-level="45.3" data-path="-introduction-to-multiparameter-models.html"><a href="-introduction-to-multiparameter-models.html#r-演示-正常態數據但均值方差均未知"><i class="fa fa-check"></i><b>45.3</b> R 演示 正常態數據但均值方差均未知</a><ul>
<li class="chapter" data-level="45.3.1" data-path="-introduction-to-multiparameter-models.html"><a href="-introduction-to-multiparameter-models.html#繪製聯合事後密度分佈及均值和方差各自的邊際分佈-visualise-the-joint-and-marginal-densities"><i class="fa fa-check"></i><b>45.3.1</b> 繪製聯合事後密度分佈及均值和方差各自的邊際分佈 visualise the joint and marginal densities</a></li>
<li class="chapter" data-level="45.3.2" data-path="-introduction-to-multiparameter-models.html"><a href="-introduction-to-multiparameter-models.html#單獨繪製邊際分佈的每一個部分"><i class="fa fa-check"></i><b>45.3.2</b> 單獨繪製邊際分佈的每一個部分</a></li>
<li class="chapter" data-level="45.3.3" data-path="-introduction-to-multiparameter-models.html"><a href="-introduction-to-multiparameter-models.html#繪製事後均值的概率密度分佈"><i class="fa fa-check"></i><b>45.3.3</b> 繪製事後均值的概率密度分佈</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path="-introduction-to-multiparameter-models.html"><a href="-introduction-to-multiparameter-models.html#r-演示-分析二進制數據-bda3-p.74"><i class="fa fa-check"></i><b>45.4</b> R 演示 分析二進制數據 (BDA3 P.74)</a></li>
</ul></li>
<li class="chapter" data-level="46" data-path="-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><i class="fa fa-check"></i><b>46</b> 簡單線型回歸模型 - 地心說模型 Linear regression is the geocentric model of applied statistics</a><ul>
<li class="chapter" data-level="46.1" data-path="-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="-linear-regression-is-the-geocentric-model-of-applied-statistics.html#為什麼正常態分佈是正常的-why-normal-distribution-is-normal"><i class="fa fa-check"></i><b>46.1</b> 為什麼正（常）態分佈是正常的 why normal distribution is normal?</a></li>
<li class="chapter" data-level="46.2" data-path="-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="-linear-regression-is-the-geocentric-model-of-applied-statistics.html#身高的高斯模型-gaussian-model-of-height"><i class="fa fa-check"></i><b>46.2</b> 身高的高斯模型 Gaussian model of height</a><ul>
<li class="chapter" data-level="46.2.1" data-path="-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="-linear-regression-is-the-geocentric-model-of-applied-statistics.html#小方格估計法近似事後概率分佈"><i class="fa fa-check"></i><b>46.2.1</b> 小方格估計法近似事後概率分佈</a></li>
<li class="chapter" data-level="46.2.2" data-path="-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="-linear-regression-is-the-geocentric-model-of-applied-statistics.html#從計算獲得的事後概率分佈中採樣"><i class="fa fa-check"></i><b>46.2.2</b> 從計算獲得的事後概率分佈中採樣</a></li>
<li class="chapter" data-level="46.2.3" data-path="-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="-linear-regression-is-the-geocentric-model-of-applied-statistics.html#使用二次方程近似法"><i class="fa fa-check"></i><b>46.2.3</b> 使用二次方程近似法</a></li>
<li class="chapter" data-level="46.2.4" data-path="-linear-regression-is-the-geocentric-model-of-applied-statistics.html"><a href="-linear-regression-is-the-geocentric-model-of-applied-statistics.html#關於-beta-的先驗概率-priors"><i class="fa fa-check"></i><b>46.2.4</b> 關於 <span class="math inline">\(\beta\)</span> 的先驗概率 Priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path="-curves-and-lines.html"><a href="-curves-and-lines.html"><i class="fa fa-check"></i><b>47</b> 直線和曲線 curves and lines</a><ul>
<li class="chapter" data-level="47.1" data-path="-curves-and-lines.html"><a href="-curves-and-lines.html#多項式回歸模型"><i class="fa fa-check"></i><b>47.1</b> 多項式回歸模型</a></li>
<li class="chapter" data-level="47.2" data-path="-curves-and-lines.html"><a href="-curves-and-lines.html#平滑曲線-splines"><i class="fa fa-check"></i><b>47.2</b> 平滑曲線 Splines</a></li>
</ul></li>
<li class="chapter" data-level="48" data-path="-many-more-variables.html"><a href="-many-more-variables.html"><i class="fa fa-check"></i><b>48</b> 多重線性回歸模型 many more variables</a><ul>
<li class="chapter" data-level="48.1" data-path="-many-more-variables.html"><a href="-many-more-variables.html#waffle"><i class="fa fa-check"></i><b>48.1</b> 虛假的相關性</a></li>
<li class="chapter" data-level="48.2" data-path="-many-more-variables.html"><a href="-many-more-variables.html#繪製輔助我們理解的有向無環圖"><i class="fa fa-check"></i><b>48.2</b> 繪製輔助我們理解的有向無環圖</a></li>
<li class="chapter" data-level="48.3" data-path="-many-more-variables.html"><a href="-many-more-variables.html#多重線性回歸模型的表達"><i class="fa fa-check"></i><b>48.3</b> 多重線性回歸模型的表達</a><ul>
<li class="chapter" data-level="48.3.1" data-path="-many-more-variables.html"><a href="-many-more-variables.html#預測變量殘差圖-predictor-residual-plots"><i class="fa fa-check"></i><b>48.3.1</b> 預測變量殘差圖 predictor residual plots</a></li>
<li class="chapter" data-level="48.3.2" data-path="-many-more-variables.html"><a href="-many-more-variables.html#事後分佈預測圖-posterior-prediction-plots"><i class="fa fa-check"></i><b>48.3.2</b> 事後分佈預測圖 posterior prediction plots</a></li>
<li class="chapter" data-level="48.3.3" data-path="-many-more-variables.html"><a href="-many-more-variables.html#反現實圖-counterfactual-plots"><i class="fa fa-check"></i><b>48.3.3</b> 反現實圖 counterfactual plots</a></li>
</ul></li>
<li class="chapter" data-level="48.4" data-path="-many-more-variables.html"><a href="-many-more-variables.html#被掩蓋起來的關係"><i class="fa fa-check"></i><b>48.4</b> 被掩蓋起來的關係</a></li>
<li class="chapter" data-level="48.5" data-path="-many-more-variables.html"><a href="-many-more-variables.html#分類型變量-categorical-variables"><i class="fa fa-check"></i><b>48.5</b> 分類型變量 categorical variables</a><ul>
<li class="chapter" data-level="48.5.1" data-path="-many-more-variables.html"><a href="-many-more-variables.html#二進制型變量"><i class="fa fa-check"></i><b>48.5.1</b> 二進制型變量</a></li>
<li class="chapter" data-level="48.5.2" data-path="-many-more-variables.html"><a href="-many-more-variables.html#多於兩個分類的分類變量"><i class="fa fa-check"></i><b>48.5.2</b> 多於兩個分類的分類變量</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html"><i class="fa fa-check"></i><b>49</b> 有向無環圖 DAG &amp; 可怕的因果 Causal Terror</a><ul>
<li class="chapter" data-level="49.1" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html#multicollinearity"><i class="fa fa-check"></i><b>49.1</b> 多重共線性問題 multicollinearity</a><ul>
<li class="chapter" data-level="49.1.1" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html#哺乳動物奶質量數據中的共線性"><i class="fa fa-check"></i><b>49.1.1</b> 哺乳動物奶質量數據中的共線性</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html#posttreatbias"><i class="fa fa-check"></i><b>49.2</b> 治療後偏倚 post-treatment bias</a><ul>
<li class="chapter" data-level="49.2.1" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html#設定模型"><i class="fa fa-check"></i><b>49.2.1</b> 設定模型</a></li>
</ul></li>
<li class="chapter" data-level="49.3" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html#對撞因子偏倚-collider-bias"><i class="fa fa-check"></i><b>49.3</b> 對撞因子偏倚 collider bias</a><ul>
<li class="chapter" data-level="49.3.1" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html#虛假的傷心對撞因子-collider-of-false-sorrow"><i class="fa fa-check"></i><b>49.3.1</b> 虛假的傷心對撞因子 collider of false sorrow</a></li>
<li class="chapter" data-level="49.3.2" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html#對撞因子偏倚另一實例未測量變量造成的碰撞偏倚"><i class="fa fa-check"></i><b>49.3.2</b> 對撞因子偏倚另一實例（未測量變量造成的碰撞偏倚）</a></li>
</ul></li>
<li class="chapter" data-level="49.4" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html#直面混雜效應"><i class="fa fa-check"></i><b>49.4</b> 直面混雜效應</a><ul>
<li class="chapter" data-level="49.4.1" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html#兩條通路"><i class="fa fa-check"></i><b>49.4.1</b> 兩條通路</a></li>
<li class="chapter" data-level="49.4.2" data-path="-dag-causal-terror.html"><a href="-dag-causal-terror.html#華夫餅的後門"><i class="fa fa-check"></i><b>49.4.2</b> 華夫餅的後門</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="50" data-path="-model-selection.html"><a href="-model-selection.html"><i class="fa fa-check"></i><b>50</b> 模型選擇 model selection</a><ul>
<li class="chapter" data-level="50.1" data-path="-model-selection.html"><a href="-model-selection.html#預測變量越多越好嗎"><i class="fa fa-check"></i><b>50.1</b> 預測變量越多越好嗎</a><ul>
<li class="chapter" data-level="50.1.1" data-path="-model-selection.html"><a href="-model-selection.html#變量越多總是會提高模型的擬合程度"><i class="fa fa-check"></i><b>50.1.1</b> 變量越多總是會提高模型的擬合程度</a></li>
<li class="chapter" data-level="50.1.2" data-path="-model-selection.html"><a href="-model-selection.html#也不是預測變量越少越好"><i class="fa fa-check"></i><b>50.1.2</b> 也不是預測變量越少越好</a></li>
</ul></li>
<li class="chapter" data-level="50.2" data-path="-model-selection.html"><a href="-model-selection.html#信息熵-information-entropy"><i class="fa fa-check"></i><b>50.2</b> 信息熵 information entropy</a><ul>
<li class="chapter" data-level="50.2.1" data-path="-model-selection.html"><a href="-model-selection.html#從信息熵到精確度-from-entropy-to-accuracy"><i class="fa fa-check"></i><b>50.2.1</b> 從信息熵到精確度 From entropy to accuracy</a></li>
</ul></li>
<li class="chapter" data-level="50.3" data-path="-model-selection.html"><a href="-model-selection.html#模型之間的比較"><i class="fa fa-check"></i><b>50.3</b> 模型之間的比較</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="-its-all-about-interaction.html"><a href="-its-all-about-interaction.html"><i class="fa fa-check"></i><b>51</b> 交互作用 it’s all about interaction</a><ul>
<li class="chapter" data-level="51.1" data-path="-its-all-about-interaction.html"><a href="-its-all-about-interaction.html#設計一個交互作用模型"><i class="fa fa-check"></i><b>51.1</b> 設計一個交互作用模型</a><ul>
<li class="chapter" data-level="51.1.1" data-path="-its-all-about-interaction.html"><a href="-its-all-about-interaction.html#設計非洲大陸地形的模型"><i class="fa fa-check"></i><b>51.1.1</b> 設計非洲大陸地形的模型</a></li>
<li class="chapter" data-level="51.1.2" data-path="-its-all-about-interaction.html"><a href="-its-all-about-interaction.html#加一個指示變量並不是一個好選擇"><i class="fa fa-check"></i><b>51.1.2</b> 加一個指示變量並不是一個好選擇</a></li>
<li class="chapter" data-level="51.1.3" data-path="-its-all-about-interaction.html"><a href="-its-all-about-interaction.html#增加交互作用項是有幫助的"><i class="fa fa-check"></i><b>51.1.3</b> 增加交互作用項是有幫助的</a></li>
<li class="chapter" data-level="51.1.4" data-path="-its-all-about-interaction.html"><a href="-its-all-about-interaction.html#繪製交叉作用"><i class="fa fa-check"></i><b>51.1.4</b> 繪製交叉作用</a></li>
</ul></li>
<li class="chapter" data-level="51.2" data-path="-its-all-about-interaction.html"><a href="-its-all-about-interaction.html#連續型變量之間的交互作用"><i class="fa fa-check"></i><b>51.2</b> 連續型變量之間的交互作用</a><ul>
<li class="chapter" data-level="51.2.1" data-path="-its-all-about-interaction.html"><a href="-its-all-about-interaction.html#winter-flower-冬天的花"><i class="fa fa-check"></i><b>51.2.1</b> Winter flower 冬天的花</a></li>
<li class="chapter" data-level="51.2.2" data-path="-its-all-about-interaction.html"><a href="-its-all-about-interaction.html#繪製事後預測圖"><i class="fa fa-check"></i><b>51.2.2</b> 繪製事後預測圖</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="52" data-path="-mcmc.html"><a href="-mcmc.html"><i class="fa fa-check"></i><b>52</b> 馬可夫鏈蒙地卡羅 MCMC</a><ul>
<li class="chapter" data-level="52.1" data-path="-mcmc.html"><a href="-mcmc.html#國王訪問個各島嶼問題"><i class="fa fa-check"></i><b>52.1</b> 國王訪問個各島嶼問題</a></li>
<li class="chapter" data-level="52.2" data-path="-mcmc.html"><a href="-mcmc.html#metropolis-演算法"><i class="fa fa-check"></i><b>52.2</b> Metropolis 演算法</a></li>
<li class="chapter" data-level="52.3" data-path="-mcmc.html"><a href="-mcmc.html#簡單的-hmc-hamitonian-monte-carlo-ulam"><i class="fa fa-check"></i><b>52.3</b> 簡單的 HMC (Hamitonian Monte Carlo) <code>ulam</code></a></li>
<li class="chapter" data-level="52.4" data-path="-mcmc.html"><a href="-mcmc.html#調教你的模型"><i class="fa fa-check"></i><b>52.4</b> 調教你的模型</a><ul>
<li class="chapter" data-level="52.4.1" data-path="-mcmc.html"><a href="-mcmc.html#無法被確認的參數-non-identifiable-parameters"><i class="fa fa-check"></i><b>52.4.1</b> 無法被確認的參數 non-identifiable parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="53" data-path="-bayesian-glm.html"><a href="-bayesian-glm.html"><i class="fa fa-check"></i><b>53</b> 貝葉斯廣義線性回歸 Bayesian GLM</a><ul>
<li class="chapter" data-level="53.1" data-path="-bayesian-glm.html"><a href="-bayesian-glm.html#二項式回歸模型-binomial-regression"><i class="fa fa-check"></i><b>53.1</b> 二項式回歸模型 binomial regression</a><ul>
<li class="chapter" data-level="53.1.1" data-path="-bayesian-glm.html"><a href="-bayesian-glm.html#chimpanzees"><i class="fa fa-check"></i><b>53.1.1</b> 邏輯回歸模型數據實例：prosocial chimpanzees</a></li>
<li class="chapter" data-level="53.1.2" data-path="-bayesian-glm.html"><a href="-bayesian-glm.html#相對還是絕對"><i class="fa fa-check"></i><b>53.1.2</b> 相對還是絕對？</a></li>
<li class="chapter" data-level="53.1.3" data-path="-bayesian-glm.html"><a href="-bayesian-glm.html#歸納後的二進制數據繼續使用黑猩猩數據"><i class="fa fa-check"></i><b>53.1.3</b> 歸納後的二進制數據：繼續使用黑猩猩數據</a></li>
<li class="chapter" data-level="53.1.4" data-path="-bayesian-glm.html"><a href="-bayesian-glm.html#彙總型二進制數據大學錄取數據"><i class="fa fa-check"></i><b>53.1.4</b> 彙總型二進制數據：大學錄取數據</a></li>
</ul></li>
<li class="chapter" data-level="53.2" data-path="-bayesian-glm.html"><a href="-bayesian-glm.html#泊松回歸模型-poisson-regression"><i class="fa fa-check"></i><b>53.2</b> 泊松回歸模型 Poisson regression</a><ul>
<li class="chapter" data-level="53.2.1" data-path="-bayesian-glm.html"><a href="-bayesian-glm.html#泊松回歸實例太平洋島國居民使用的工具"><i class="fa fa-check"></i><b>53.2.1</b> 泊松回歸實例：太平洋島國居民使用的工具</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="-continuous-mixture-models.html"><a href="-continuous-mixture-models.html"><i class="fa fa-check"></i><b>54</b> 貝葉斯廣義線性回歸模型的擴展 continuous mixture models</a><ul>
<li class="chapter" data-level="54.1" data-path="-continuous-mixture-models.html"><a href="-continuous-mixture-models.html#beta-二項分佈模型-beta-binomial-model"><i class="fa fa-check"></i><b>54.1</b> Beta 二項分佈模型 beta-binomial model</a></li>
<li class="chapter" data-level="54.2" data-path="-continuous-mixture-models.html"><a href="-continuous-mixture-models.html#負二項分佈模型伽馬泊松回歸模型-negative-binomialgamma-poisson"><i class="fa fa-check"></i><b>54.2</b> 負二項分佈模型，伽馬泊松回歸模型 Negative-binomial/gamma-Poisson</a></li>
<li class="chapter" data-level="54.3" data-path="-continuous-mixture-models.html"><a href="-continuous-mixture-models.html#零膨脹模型-zero-inflated-models"><i class="fa fa-check"></i><b>54.3</b> 零膨脹模型 zero-inflated models</a><ul>
<li class="chapter" data-level="54.3.1" data-path="-continuous-mixture-models.html"><a href="-continuous-mixture-models.html#零膨脹泊松回歸模型-zero-inflated-poisson"><i class="fa fa-check"></i><b>54.3.1</b> 零膨脹泊松回歸模型 zero-inflated Poisson</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path="-continuous-mixture-models.html"><a href="-continuous-mixture-models.html#帶順序含義的多類別結果變量-ordered-categorical-outcomes"><i class="fa fa-check"></i><b>54.4</b> 帶順序含義的多類別結果變量 ordered categorical outcomes</a><ul>
<li class="chapter" data-level="54.4.1" data-path="-continuous-mixture-models.html"><a href="-continuous-mixture-models.html#用不同的截距來描述一個有順序的分佈-describing-an-ordered-distribution-with-intercepts"><i class="fa fa-check"></i><b>54.4.1</b> 用不同的截距來描述一個有順序的分佈 describing an ordered distribution with intercepts</a></li>
<li class="chapter" data-level="54.4.2" data-path="-continuous-mixture-models.html"><a href="-continuous-mixture-models.html#增加預測變量"><i class="fa fa-check"></i><b>54.4.2</b> 增加預測變量</a></li>
</ul></li>
<li class="chapter" data-level="54.5" data-path="-continuous-mixture-models.html"><a href="-continuous-mixture-models.html#帶順序含義的多類別預測型變量-ordered-categorical-predictors"><i class="fa fa-check"></i><b>54.5</b> 帶順序含義的多類別預測型變量 ordered categorical predictors</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="-multilevel-models.html"><a href="-multilevel-models.html"><i class="fa fa-check"></i><b>55</b> 貝葉斯多層回歸模型 multilevel models</a><ul>
<li class="chapter" data-level="55.1" data-path="-multilevel-models.html"><a href="-multilevel-models.html#多層數據實例蝌蚪和青蛙數據-multilevel-tadpoles"><i class="fa fa-check"></i><b>55.1</b> 多層數據實例：蝌蚪和青蛙數據 multilevel tadpoles</a></li>
<li class="chapter" data-level="55.2" data-path="-multilevel-models.html"><a href="-multilevel-models.html#多層回歸的變化的效應和過度擬合過低擬合之間的交易-varing-effects-and-the-underfittingoverfitting-trade-off"><i class="fa fa-check"></i><b>55.2</b> 多層回歸的變化的效應和過度擬合/過低擬合之間的交易 varing effects and the underfitting/overfitting trade-off</a><ul>
<li class="chapter" data-level="55.2.1" data-path="-multilevel-models.html"><a href="-multilevel-models.html#用於產生模擬數據的模型-the-model"><i class="fa fa-check"></i><b>55.2.1</b> 用於產生模擬數據的模型 the model</a></li>
<li class="chapter" data-level="55.2.2" data-path="-multilevel-models.html"><a href="-multilevel-models.html#模擬存活概率結果-simulate-survivors"><i class="fa fa-check"></i><b>55.2.2</b> 模擬存活概率結果 simulate survivors</a></li>
<li class="chapter" data-level="55.2.3" data-path="-multilevel-models.html"><a href="-multilevel-models.html#計算完全不合併策略-no-pooling-estimates"><i class="fa fa-check"></i><b>55.2.3</b> 計算完全不合併策略 no-pooling estimates</a></li>
<li class="chapter" data-level="55.2.4" data-path="-multilevel-models.html"><a href="-multilevel-models.html#計算部分合併策略的結果-partial-pooling-estimates"><i class="fa fa-check"></i><b>55.2.4</b> 計算部分合併策略的結果 partial-pooling estimates</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path="-multilevel-models.html"><a href="-multilevel-models.html#使用多於一個類別作爲多層回歸的隨機變量-more-than-one-type-of-cluster"><i class="fa fa-check"></i><b>55.3</b> 使用多於一個類別作爲多層回歸的隨機變量 more than one type of cluster</a><ul>
<li class="chapter" data-level="55.3.1" data-path="-multilevel-models.html"><a href="-multilevel-models.html#黑猩猩數據的多層回歸模型-multilevel-chimpanzees"><i class="fa fa-check"></i><b>55.3.1</b> 黑猩猩數據的多層回歸模型 multilevel chimpanzees</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VIII 廣義線性迴歸模型 Generalised Linear Regression</b></span></li>
<li class="chapter" data-level="56" data-path="revision.html"><a href="revision.html"><i class="fa fa-check"></i><b>56</b> 重要概念複習</a><ul>
<li class="chapter" data-level="56.1" data-path="revision.html"><a href="revision.html#概率論學派統計推斷要點複習"><i class="fa fa-check"></i><b>56.1</b> 概率論學派統計推斷要點複習</a></li>
<li class="chapter" data-level="56.2" data-path="revision.html"><a href="revision.html#似然"><i class="fa fa-check"></i><b>56.2</b> 似然</a></li>
<li class="chapter" data-level="56.3" data-path="revision.html"><a href="revision.html#極大似然估計"><i class="fa fa-check"></i><b>56.3</b> 極大似然估計</a></li>
<li class="chapter" data-level="56.4" data-path="revision.html"><a href="revision.html#關於假設檢驗的複習"><i class="fa fa-check"></i><b>56.4</b> 關於假設檢驗的複習</a><ul>
<li class="chapter" data-level="56.4.1" data-path="revision.html"><a href="revision.html#子集似然函數"><i class="fa fa-check"></i><b>56.4.1</b> 子集似然函數</a></li>
</ul></li>
<li class="chapter" data-level="56.5" data-path="revision.html"><a href="revision.html#線性迴歸複習"><i class="fa fa-check"></i><b>56.5</b> 線性迴歸複習</a><ul>
<li class="chapter" data-level="56.5.1" data-path="revision.html"><a href="revision.html#簡單線性迴歸"><i class="fa fa-check"></i><b>56.5.1</b> 簡單線性迴歸</a></li>
<li class="chapter" data-level="56.5.2" data-path="revision.html"><a href="revision.html#多元線性迴歸"><i class="fa fa-check"></i><b>56.5.2</b> 多元線性迴歸</a></li>
<li class="chapter" data-level="56.5.3" data-path="revision.html"><a href="revision.html#score-equations"><i class="fa fa-check"></i><b>56.5.3</b> 簡單線性迴歸的統計推斷</a></li>
</ul></li>
<li class="chapter" data-level="56.6" data-path="revision.html"><a href="revision.html#glm-practical-01"><i class="fa fa-check"></i><b>56.6</b> GLM-Practical 01</a><ul>
<li class="chapter" data-level="56.6.1" data-path="revision.html"><a href="revision.html#建立似然方程"><i class="fa fa-check"></i><b>56.6.1</b> 建立似然方程</a></li>
<li class="chapter" data-level="56.6.2" data-path="revision.html"><a href="revision.html#建立對數似然方程"><i class="fa fa-check"></i><b>56.6.2</b> 建立對數似然方程</a></li>
<li class="chapter" data-level="56.6.3" data-path="revision.html"><a href="revision.html#線性回歸模型"><i class="fa fa-check"></i><b>56.6.3</b> 線性回歸模型</a></li>
<li class="chapter" data-level="56.6.4" data-path="revision.html"><a href="revision.html#似然比檢驗wald-檢驗score-檢驗"><i class="fa fa-check"></i><b>56.6.4</b> 似然比檢驗，Wald 檢驗，Score 檢驗</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="57" data-path="intro-GLM.html"><a href="intro-GLM.html"><i class="fa fa-check"></i><b>57</b> 廣義線性迴歸入門</a><ul>
<li class="chapter" data-level="57.1" data-path="intro-GLM.html"><a href="intro-GLM.html#指數分佈家族"><i class="fa fa-check"></i><b>57.1</b> 指數分佈家族</a><ul>
<li class="chapter" data-level="57.1.1" data-path="intro-GLM.html"><a href="intro-GLM.html#泊松分佈和二項分佈的指數分佈家族屬性"><i class="fa fa-check"></i><b>57.1.1</b> 泊松分佈和二項分佈的指數分佈家族屬性</a></li>
<li class="chapter" data-level="57.1.2" data-path="intro-GLM.html"><a href="intro-GLM.html#exercise.-exponential-distribution"><i class="fa fa-check"></i><b>57.1.2</b> Exercise. Exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="57.2" data-path="intro-GLM.html"><a href="intro-GLM.html#defineaGLM"><i class="fa fa-check"></i><b>57.2</b> 廣義線性迴歸模型之定義</a></li>
<li class="chapter" data-level="57.3" data-path="intro-GLM.html"><a href="intro-GLM.html#注意"><i class="fa fa-check"></i><b>57.3</b> 注意</a></li>
<li class="chapter" data-level="57.4" data-path="intro-GLM.html"><a href="intro-GLM.html#如何在-r-裏擬合-glm"><i class="fa fa-check"></i><b>57.4</b> 如何在 R 裏擬合 “GLM”</a><ul>
<li class="chapter" data-level="57.4.1" data-path="intro-GLM.html"><a href="intro-GLM.html#margins-命令"><i class="fa fa-check"></i><b>57.4.1</b> <code>margins</code> 命令</a></li>
<li class="chapter" data-level="57.4.2" data-path="intro-GLM.html"><a href="intro-GLM.html#ggplot2geom_smoothmethod-loess-命令"><i class="fa fa-check"></i><b>57.4.2</b> <code>ggplot2::geom_smooth(method = "loess")</code> 命令</a></li>
</ul></li>
<li class="chapter" data-level="57.5" data-path="intro-GLM.html"><a href="intro-GLM.html#glm-practical-02"><i class="fa fa-check"></i><b>57.5</b> GLM-Practical 02</a><ul>
<li class="chapter" data-level="57.5.1" data-path="intro-GLM.html"><a href="intro-GLM.html#思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證"><i class="fa fa-check"></i><b>57.5.1</b> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</a></li>
<li class="chapter" data-level="57.5.2" data-path="intro-GLM.html"><a href="intro-GLM.html#r-練習"><i class="fa fa-check"></i><b>57.5.2</b> R 練習</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="58" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>58</b> 二項分佈數據的廣義線性迴歸模型 logistic regression model</a><ul>
<li class="chapter" data-level="58.1" data-path="logistic.html"><a href="logistic.html#彙總後個人-grouped-individual-的二項分佈數據"><i class="fa fa-check"></i><b>58.1</b> 彙總後/個人 (grouped / individual) 的二項分佈數據</a></li>
<li class="chapter" data-level="58.2" data-path="logistic.html"><a href="logistic.html#二項分佈數據的廣義線性迴歸模型"><i class="fa fa-check"></i><b>58.2</b> 二項分佈數據的廣義線性迴歸模型</a></li>
<li class="chapter" data-level="58.3" data-path="logistic.html"><a href="logistic.html#logit-or-log"><i class="fa fa-check"></i><b>58.3</b> 注</a><ul>
<li class="chapter" data-level="58.3.1" data-path="logistic.html"><a href="logistic.html#exercise.-link-functions."><i class="fa fa-check"></i><b>58.3.1</b> Exercise. Link functions.</a></li>
</ul></li>
<li class="chapter" data-level="58.4" data-path="logistic.html"><a href="logistic.html#邏輯迴歸模型迴歸係數的實際意義"><i class="fa fa-check"></i><b>58.4</b> 邏輯迴歸模型迴歸係數的實際意義</a></li>
<li class="chapter" data-level="58.5" data-path="logistic.html"><a href="logistic.html#BSEinfection"><i class="fa fa-check"></i><b>58.5</b> 邏輯迴歸實際案例</a><ul>
<li class="chapter" data-level="58.5.1" data-path="logistic.html"><a href="logistic.html#分析目的"><i class="fa fa-check"></i><b>58.5.1</b> 分析目的</a></li>
<li class="chapter" data-level="58.5.2" data-path="logistic.html"><a href="logistic.html#模型-1-飼料-羣"><i class="fa fa-check"></i><b>58.5.2</b> 模型 1 飼料 + 羣</a></li>
<li class="chapter" data-level="58.5.3" data-path="logistic.html"><a href="logistic.html#模型-2-增加交互作用項-飼料-times-羣"><i class="fa fa-check"></i><b>58.5.3</b> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</a></li>
</ul></li>
<li class="chapter" data-level="58.6" data-path="logistic.html"><a href="logistic.html#glm-practical-03"><i class="fa fa-check"></i><b>58.6</b> GLM-Practical 03</a><ul>
<li class="chapter" data-level="58.6.1" data-path="logistic.html"><a href="logistic.html#昆蟲的死亡率"><i class="fa fa-check"></i><b>58.6.1</b> 昆蟲的死亡率</a></li>
<li class="chapter" data-level="58.6.2" data-path="logistic.html"><a href="logistic.html#哮喘門診數據"><i class="fa fa-check"></i><b>58.6.2</b> 哮喘門診數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="59" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>59</b> 模型比較和擬合優度</a><ul>
<li class="chapter" data-level="59.1" data-path="model-comparison.html"><a href="model-comparison.html#嵌套式模型的比較-nested-models"><i class="fa fa-check"></i><b>59.1</b> 嵌套式模型的比較 nested models</a></li>
<li class="chapter" data-level="59.2" data-path="model-comparison.html"><a href="model-comparison.html#嵌套式模型比較實例"><i class="fa fa-check"></i><b>59.2</b> 嵌套式模型比較實例</a></li>
<li class="chapter" data-level="59.3" data-path="model-comparison.html"><a href="model-comparison.html#飽和模型模型的偏差擬合優度"><i class="fa fa-check"></i><b>59.3</b> 飽和模型，模型的偏差，擬合優度</a><ul>
<li class="chapter" data-level="59.3.1" data-path="model-comparison.html"><a href="model-comparison.html#飽和模型-saturated-model"><i class="fa fa-check"></i><b>59.3.1</b> 飽和模型 saturated model</a></li>
<li class="chapter" data-level="59.3.2" data-path="model-comparison.html"><a href="model-comparison.html#deviance"><i class="fa fa-check"></i><b>59.3.2</b> 模型偏差 deviance</a></li>
<li class="chapter" data-level="59.3.3" data-path="model-comparison.html"><a href="model-comparison.html#彙總型二項分佈數據-aggregatedgrouped-binary-data"><i class="fa fa-check"></i><b>59.3.3</b> 彙總型二項分佈數據 aggregated/grouped binary data</a></li>
</ul></li>
<li class="chapter" data-level="59.4" data-path="model-comparison.html"><a href="model-comparison.html#gof"><i class="fa fa-check"></i><b>59.4</b> 個人數據擬合模型的優度檢驗</a></li>
<li class="chapter" data-level="59.5" data-path="model-comparison.html"><a href="model-comparison.html#glm-practical-04"><i class="fa fa-check"></i><b>59.5</b> GLM Practical 04</a><ul>
<li class="chapter" data-level="59.5.1" data-path="model-comparison.html"><a href="model-comparison.html#回到之前的昆蟲數據嘗試評價該模型的擬合優度"><i class="fa fa-check"></i><b>59.5.1</b> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</a></li>
<li class="chapter" data-level="59.5.2" data-path="model-comparison.html"><a href="model-comparison.html#低出生體重數據"><i class="fa fa-check"></i><b>59.5.2</b> 低出生體重數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="60" data-path="count-outcomes.html"><a href="count-outcomes.html"><i class="fa fa-check"></i><b>60</b> 計數型因變量 Count outcomes</a><ul>
<li class="chapter" data-level="60.1" data-path="count-outcomes.html"><a href="count-outcomes.html#泊松-glm"><i class="fa fa-check"></i><b>60.1</b> 泊松 GLM</a></li>
<li class="chapter" data-level="60.2" data-path="count-outcomes.html"><a href="count-outcomes.html#泊松迴歸實例"><i class="fa fa-check"></i><b>60.2</b> 泊松迴歸實例</a></li>
<li class="chapter" data-level="60.3" data-path="count-outcomes.html"><a href="count-outcomes.html#過度離散-overdispersion"><i class="fa fa-check"></i><b>60.3</b> 過度離散 overdispersion</a><ul>
<li class="chapter" data-level="60.3.1" data-path="count-outcomes.html"><a href="count-outcomes.html#過度離散怎麼查"><i class="fa fa-check"></i><b>60.3.1</b> 過度離散怎麼查？</a></li>
<li class="chapter" data-level="60.3.2" data-path="count-outcomes.html"><a href="count-outcomes.html#負二項式分佈模型-negative-binomial-model"><i class="fa fa-check"></i><b>60.3.2</b> 負二項式分佈模型 negative binomial model</a></li>
</ul></li>
<li class="chapter" data-level="60.4" data-path="count-outcomes.html"><a href="count-outcomes.html#glm-practical-05"><i class="fa fa-check"></i><b>60.4</b> GLM Practical 05</a></li>
</ul></li>
<li class="chapter" data-level="61" data-path="GLM-rates.html"><a href="GLM-rates.html"><i class="fa fa-check"></i><b>61</b> 率的廣義線性迴歸 Poisson GLM for rates</a><ul>
<li class="chapter" data-level="61.1" data-path="GLM-rates.html"><a href="GLM-rates.html#醫學中的率"><i class="fa fa-check"></i><b>61.1</b> 醫學中的率</a></li>
<li class="chapter" data-level="61.2" data-path="GLM-rates.html"><a href="GLM-rates.html#泊松過程"><i class="fa fa-check"></i><b>61.2</b> 泊松過程</a></li>
<li class="chapter" data-level="61.3" data-path="GLM-rates.html"><a href="GLM-rates.html#率的模型"><i class="fa fa-check"></i><b>61.3</b> 率的模型</a></li>
<li class="chapter" data-level="61.4" data-path="GLM-rates.html"><a href="GLM-rates.html#率的-glm"><i class="fa fa-check"></i><b>61.4</b> 率的 GLM</a></li>
<li class="chapter" data-level="61.5" data-path="GLM-rates.html"><a href="GLM-rates.html#分析實例-example-british-doctors-study"><i class="fa fa-check"></i><b>61.5</b> 分析實例 Example: British doctors study</a><ul>
<li class="chapter" data-level="61.5.1" data-path="GLM-rates.html"><a href="GLM-rates.html#模型-1-吸菸"><i class="fa fa-check"></i><b>61.5.1</b> 模型 1: 吸菸</a></li>
<li class="chapter" data-level="61.5.2" data-path="GLM-rates.html"><a href="GLM-rates.html#模型-2-吸菸-年齡"><i class="fa fa-check"></i><b>61.5.2</b> 模型 2: 吸菸 + 年齡</a></li>
<li class="chapter" data-level="61.5.3" data-path="GLM-rates.html"><a href="GLM-rates.html#模型-3-吸菸-年齡-吸菸與年齡的交互作用項"><i class="fa fa-check"></i><b>61.5.3</b> 模型 3: 吸菸 + 年齡 + 吸菸與年齡的交互作用項</a></li>
</ul></li>
<li class="chapter" data-level="61.6" data-path="GLM-rates.html"><a href="GLM-rates.html#glm-practical-06"><i class="fa fa-check"></i><b>61.6</b> GLM Practical 06</a><ul>
<li class="chapter" data-level="61.6.1" data-path="GLM-rates.html"><a href="GLM-rates.html#將數據導入-r-環境中初步計算每個工廠不同年齡組工人的死亡人數和追蹤人年數據"><i class="fa fa-check"></i><b>61.6.1</b> 將數據導入 R 環境中，初步計算每個工廠不同年齡組工人的死亡人數，和追蹤人年數據。</a></li>
<li class="chapter" data-level="61.6.2" data-path="GLM-rates.html"><a href="GLM-rates.html#計算死亡率的對數值繪製其與年齡組的點圖"><i class="fa fa-check"></i><b>61.6.2</b> 計算死亡率的對數值，繪製其與年齡組的點圖。</a></li>
<li class="chapter" data-level="61.6.3" data-path="GLM-rates.html"><a href="GLM-rates.html#請用數學語言描述死亡率和年齡組之間關係的模型"><i class="fa fa-check"></i><b>61.6.3</b> 請用數學語言描述死亡率和年齡組之間關係的模型。</a></li>
<li class="chapter" data-level="61.6.4" data-path="GLM-rates.html"><a href="GLM-rates.html#接下來的模型中在前面的基礎上加入工廠編號你認爲是否有證據證明工廠之間的工人的死亡率在調整了年齡之後依然有差異計算年齡調整過後的兩工廠之間死亡率之比和95ci"><i class="fa fa-check"></i><b>61.6.4</b> 接下來的模型中在前面的基礎上加入工廠編號，你認爲是否有證據證明工廠之間的工人的死亡率在調整了年齡之後依然有差異？計算年齡調整過後的兩工廠之間死亡率之比和95%CI。</a></li>
<li class="chapter" data-level="61.6.5" data-path="GLM-rates.html"><a href="GLM-rates.html#現在在前一步加了工廠變量的基礎上重新擬合模型加入工廠和年齡之間的交互作用項"><i class="fa fa-check"></i><b>61.6.5</b> 現在在前一步加了工廠變量的基礎上，重新擬合模型，加入工廠和年齡之間的交互作用項</a></li>
<li class="chapter" data-level="61.6.6" data-path="GLM-rates.html"><a href="GLM-rates.html#現在把年齡當作連續型變量來考慮擬合下列模型"><i class="fa fa-check"></i><b>61.6.6</b> 現在把年齡當作連續型變量來考慮。擬合下列模型</a></li>
<li class="chapter" data-level="61.6.7" data-path="GLM-rates.html"><a href="GLM-rates.html#計算只有年齡連續型和工廠兩個變量模型時的模型偏差-deviance該模型和第一部分中飽和模型之間相比相差幾個參數parameters你有怎樣的推論"><i class="fa fa-check"></i><b>61.6.7</b> 計算只有年齡(連續型)和工廠兩個變量模型時的模型偏差 (deviance)，該模型和第一部分中飽和模型之間相比相差幾個參數(parameters)？你有怎樣的推論？</a></li>
<li class="chapter" data-level="61.6.8" data-path="GLM-rates.html"><a href="GLM-rates.html#對這個數據進行了這一系列的分析之後你從流行病學的角度來說有怎樣的結論"><i class="fa fa-check"></i><b>61.6.8</b> 對這個數據進行了這一系列的分析之後，你從流行病學的角度來說，有怎樣的結論？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="62" data-path="confounding-interaction.html"><a href="confounding-interaction.html"><i class="fa fa-check"></i><b>62</b> 混雜的調整，交互作用，和模型的可壓縮性</a><ul>
<li class="chapter" data-level="62.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#混雜因素的調整"><i class="fa fa-check"></i><b>62.1</b> 混雜因素的調整</a><ul>
<li class="chapter" data-level="62.1.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#woolf-法估算合併比值比"><i class="fa fa-check"></i><b>62.1.1</b> Woolf 法估算合併比值比</a></li>
</ul></li>
<li class="chapter" data-level="62.2" data-path="confounding-interaction.html"><a href="confounding-interaction.html#交互作用"><i class="fa fa-check"></i><b>62.2</b> 交互作用</a></li>
<li class="chapter" data-level="62.3" data-path="confounding-interaction.html"><a href="confounding-interaction.html#可壓縮性-collapsibility"><i class="fa fa-check"></i><b>62.3</b> 可壓縮性 collapsibility</a><ul>
<li class="chapter" data-level="62.3.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#線性迴歸的可壓縮性"><i class="fa fa-check"></i><b>62.3.1</b> 線性迴歸的可壓縮性</a></li>
<li class="chapter" data-level="62.3.2" data-path="confounding-interaction.html"><a href="confounding-interaction.html#collapsibility"><i class="fa fa-check"></i><b>62.3.2</b> 邏輯鏈接方程時的不可壓縮性</a></li>
</ul></li>
<li class="chapter" data-level="62.4" data-path="confounding-interaction.html"><a href="confounding-interaction.html#interaction-depend-scale"><i class="fa fa-check"></i><b>62.4</b> 交互作用對尺度的依賴性</a></li>
<li class="chapter" data-level="62.5" data-path="confounding-interaction.html"><a href="confounding-interaction.html#glm-practical-07"><i class="fa fa-check"></i><b>62.5</b> GLM Practical 07</a><ul>
<li class="chapter" data-level="62.5.1" data-path="confounding-interaction.html"><a href="confounding-interaction.html#使用你熟悉的統計學軟件擬合一個由-fupcontrol-作爲結果變量treat-作爲唯一預測變量的廣義線性回歸模型-根據報告的結果寫一段適用於醫學流行病學文獻雜誌的報告"><i class="fa fa-check"></i><b>62.5.1</b> 使用你熟悉的統計學軟件擬合一個由 <code>fupcontrol</code> 作爲結果變量，<code>treat</code> 作爲唯一預測變量的廣義線性回歸模型。 根據報告的結果，寫一段適用於醫學/流行病學文獻雜誌的報告。</a></li>
<li class="chapter" data-level="62.5.2" data-path="confounding-interaction.html"><a href="confounding-interaction.html#分析-treat-和-basecontrol-之間的關係結果是否如你的預期那樣"><i class="fa fa-check"></i><b>62.5.2</b> 分析 <code>treat</code> 和 <code>basecontrol</code> 之間的關係，結果是否如你的預期那樣？</a></li>
<li class="chapter" data-level="62.5.3" data-path="confounding-interaction.html"><a href="confounding-interaction.html#已知模型中如果增加調整基線變量可能對-fupcontrol-有一定的預測效果-在你的模型中增加基線血壓控制情況的變量與-m0-的結果-治療效果-treatment-effect參數標準誤-standard-error和-p-值重新修改之前用於發表在醫學雜誌上關於這個分析結果的報告描述"><i class="fa fa-check"></i><b>62.5.3</b> 已知模型中如果增加調整基線變量可能對 <code>fupcontrol</code> 有一定的預測效果。 在你的模型中增加基線血壓控制情況的變量。與 <code>m0</code> 的結果 (治療效果 treatment effect；參數標準誤 standard error；和 p 值)。重新修改之前用於發表在醫學雜誌上關於這個分析結果的報告描述。</a></li>
<li class="chapter" data-level="62.5.4" data-path="confounding-interaction.html"><a href="confounding-interaction.html#你更推薦使用哪個模型作爲最終主要結果的彙報"><i class="fa fa-check"></i><b>62.5.4</b> 你更推薦使用哪個模型作爲最終主要結果的彙報？</a></li>
<li class="chapter" data-level="62.5.5" data-path="confounding-interaction.html"><a href="confounding-interaction.html#實驗研究者更想知道新的治療方案是否由於基線時患者的血壓控制情況而有不同爲了回答這個問題請擬合對應的廣義線性回歸模型根據結果回答這個問題"><i class="fa fa-check"></i><b>62.5.5</b> 實驗研究者更想知道新的治療方案是否由於基線時患者的血壓控制情況而有不同。爲了回答這個問題，請擬合對應的廣義線性回歸模型。根據結果回答這個問題。</a></li>
<li class="chapter" data-level="62.5.6" data-path="confounding-interaction.html"><a href="confounding-interaction.html#換一個模型先不考慮-basecontrol使用危險度比-risk-ratio-來評價不同治療方案之間的療效"><i class="fa fa-check"></i><b>62.5.6</b> 換一個模型，先不考慮 <code>basecontrol</code>，使用危險度比 (risk ratio) 來評價不同治療方案之間的療效。</a></li>
<li class="chapter" data-level="62.5.7" data-path="confounding-interaction.html"><a href="confounding-interaction.html#在前一模型m4中加入-basecontrol與未加入該變量時模型的輸出結果相比有什麼不同"><i class="fa fa-check"></i><b>62.5.7</b> 在前一模型<code>m4</code>中加入 <code>basecontrol</code>，與未加入該變量時模型的輸出結果相比，有什麼不同？</a></li>
<li class="chapter" data-level="62.5.8" data-path="confounding-interaction.html"><a href="confounding-interaction.html#給上述模型增加交互作用項對於危險度比作爲指標時的交互作用分析結果和使用比值比時相比你有怎樣的思考和結論"><i class="fa fa-check"></i><b>62.5.8</b> 給上述模型增加交互作用項。對於危險度比作爲指標時的交互作用分析結果，和使用比值比時相比，你有怎樣的思考和結論？</a></li>
<li class="chapter" data-level="62.5.9" data-path="confounding-interaction.html"><a href="confounding-interaction.html#如果說不考慮一個rct的統計分析不能在收集完數據之後修改這一事實你認爲危險度比模型和比值比模型更應該使用哪一個來總結本數據的結果呢"><i class="fa fa-check"></i><b>62.5.9</b> 如果說不考慮一個RCT的統計分析不能在收集完數據之後修改這一事實，你認爲危險度比模型和比值比模型更應該使用哪一個來總結本數據的結果呢？</a></li>
<li class="chapter" data-level="62.5.10" data-path="confounding-interaction.html"><a href="confounding-interaction.html#證明危險度比模型是可以壓縮的prove-that-the-log-link-models-are-collapsible."><i class="fa fa-check"></i><b>62.5.10</b> 證明危險度比模型是可以壓縮的。Prove that the log-link models are collapsible.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="63" data-path="epi-logistic.html"><a href="epi-logistic.html"><i class="fa fa-check"></i><b>63</b> 流行病學中的邏輯迴歸</a><ul>
<li class="chapter" data-level="63.1" data-path="epi-logistic.html"><a href="epi-logistic.html#流行病學研究最常用的實驗設計"><i class="fa fa-check"></i><b>63.1</b> 流行病學研究最常用的實驗設計</a></li>
<li class="chapter" data-level="63.2" data-path="epi-logistic.html"><a href="epi-logistic.html#GLM8-3"><i class="fa fa-check"></i><b>63.2</b> 以簡單二進制暴露變量爲例</a><ul>
<li class="chapter" data-level="63.2.1" data-path="epi-logistic.html"><a href="epi-logistic.html#先決條件"><i class="fa fa-check"></i><b>63.2.1</b> 先決條件</a></li>
<li class="chapter" data-level="63.2.2" data-path="epi-logistic.html"><a href="epi-logistic.html#比值比-odds-ratios"><i class="fa fa-check"></i><b>63.2.2</b> 比值比 Odds ratios</a></li>
<li class="chapter" data-level="63.2.3" data-path="epi-logistic.html"><a href="epi-logistic.html#GLM8-3-4"><i class="fa fa-check"></i><b>63.2.3</b> 邏輯迴歸應用於病例對照研究的合理性</a></li>
</ul></li>
<li class="chapter" data-level="63.3" data-path="epi-logistic.html"><a href="epi-logistic.html#拓展到多個暴露變量的邏輯迴歸模型"><i class="fa fa-check"></i><b>63.3</b> 拓展到多個暴露變量的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="63.3.1" data-path="epi-logistic.html"><a href="epi-logistic.html#mantel-haenszel-法"><i class="fa fa-check"></i><b>63.3.1</b> Mantel Haenszel 法</a></li>
<li class="chapter" data-level="63.3.2" data-path="epi-logistic.html"><a href="epi-logistic.html#隊列研究和病例對照研究的似然"><i class="fa fa-check"></i><b>63.3.2</b> 隊列研究和病例對照研究的似然</a></li>
<li class="chapter" data-level="63.3.3" data-path="epi-logistic.html"><a href="epi-logistic.html#病例對照研究中的邏輯迴歸"><i class="fa fa-check"></i><b>63.3.3</b> 病例對照研究中的邏輯迴歸</a></li>
</ul></li>
<li class="chapter" data-level="63.4" data-path="epi-logistic.html"><a href="epi-logistic.html#流行病學研究中變量的調整策略"><i class="fa fa-check"></i><b>63.4</b> 流行病學研究中變量的調整策略</a></li>
<li class="chapter" data-level="63.5" data-path="epi-logistic.html"><a href="epi-logistic.html#glm-practical-08"><i class="fa fa-check"></i><b>63.5</b> GLM Practical 08</a><ul>
<li class="chapter" data-level="63.5.1" data-path="epi-logistic.html"><a href="epi-logistic.html#part-1"><i class="fa fa-check"></i><b>63.5.1</b> Part 1</a></li>
<li class="chapter" data-level="63.5.2" data-path="epi-logistic.html"><a href="epi-logistic.html#part-2"><i class="fa fa-check"></i><b>63.5.2</b> Part 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="64" data-path="GLM-strategy.html"><a href="GLM-strategy.html"><i class="fa fa-check"></i><b>64</b> 分析策略</a><ul>
<li class="chapter" data-level="64.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#明確分析目的"><i class="fa fa-check"></i><b>64.1</b> 明確分析目的</a></li>
<li class="chapter" data-level="64.2" data-path="GLM-strategy.html"><a href="GLM-strategy.html#分析目的-1.1-估計-rct-中治療效果-treatment-effect"><i class="fa fa-check"></i><b>64.2</b> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</a><ul>
<li class="chapter" data-level="64.2.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#rct-數據分析的一些不成熟的小建議"><i class="fa fa-check"></i><b>64.2.1</b> RCT 數據分析的一些不成熟的小建議</a></li>
</ul></li>
<li class="chapter" data-level="64.3" data-path="GLM-strategy.html"><a href="GLM-strategy.html#分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect"><i class="fa fa-check"></i><b>64.3</b> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</a><ul>
<li class="chapter" data-level="64.3.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#不成熟的小策略"><i class="fa fa-check"></i><b>64.3.1</b> 不成熟的小策略</a></li>
<li class="chapter" data-level="64.3.2" data-path="GLM-strategy.html"><a href="GLM-strategy.html#補充"><i class="fa fa-check"></i><b>64.3.2</b> 補充</a></li>
</ul></li>
<li class="chapter" data-level="64.4" data-path="GLM-strategy.html"><a href="GLM-strategy.html#分析目的-2-和-3-建立預測模型-predictive-models"><i class="fa fa-check"></i><b>64.4</b> 分析目的 2 和 3 – 建立預測模型 (predictive models)</a></li>
<li class="chapter" data-level="64.5" data-path="GLM-strategy.html"><a href="GLM-strategy.html#glm-practical-09"><i class="fa fa-check"></i><b>64.5</b> GLM practical 09</a><ul>
<li class="chapter" data-level="64.5.1" data-path="GLM-strategy.html"><a href="GLM-strategy.html#part-1-1"><i class="fa fa-check"></i><b>64.5.1</b> Part 1</a></li>
<li class="chapter" data-level="64.5.2" data-path="GLM-strategy.html"><a href="GLM-strategy.html#part-2-1"><i class="fa fa-check"></i><b>64.5.2</b> Part 2</a></li>
<li class="chapter" data-level="64.5.3" data-path="GLM-strategy.html"><a href="GLM-strategy.html#part-3"><i class="fa fa-check"></i><b>64.5.3</b> Part 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="65" data-path="checkingGLM.html"><a href="checkingGLM.html"><i class="fa fa-check"></i><b>65</b> 檢查你的模型 Model Checking - GLM</a><ul>
<li class="chapter" data-level="65.1" data-path="checkingGLM.html"><a href="checkingGLM.html#線性預測方程的定義"><i class="fa fa-check"></i><b>65.1</b> 線性預測方程的定義</a><ul>
<li class="chapter" data-level="65.1.1" data-path="checkingGLM.html"><a href="checkingGLM.html#殘差-1"><i class="fa fa-check"></i><b>65.1.1</b> 殘差</a></li>
<li class="chapter" data-level="65.1.2" data-path="checkingGLM.html"><a href="checkingGLM.html#glm-在-r-裏獲取殘差"><i class="fa fa-check"></i><b>65.1.2</b> GLM 在 R 裏獲取殘差</a></li>
<li class="chapter" data-level="65.1.3" data-path="checkingGLM.html"><a href="checkingGLM.html#如何利用獲得的殘差"><i class="fa fa-check"></i><b>65.1.3</b> 如何利用獲得的殘差</a></li>
</ul></li>
<li class="chapter" data-level="65.2" data-path="checkingGLM.html"><a href="checkingGLM.html#共變量模式殘差-covariate-pattern-residuals"><i class="fa fa-check"></i><b>65.2</b> 共變量模式殘差 covariate pattern residuals</a></li>
<li class="chapter" data-level="65.3" data-path="checkingGLM.html"><a href="checkingGLM.html#鏈接方程"><i class="fa fa-check"></i><b>65.3</b> 鏈接方程</a></li>
<li class="chapter" data-level="65.4" data-path="checkingGLM.html"><a href="checkingGLM.html#NHANESdrinker"><i class="fa fa-check"></i><b>65.4</b> NHANES 飲酒量數據實例</a></li>
<li class="chapter" data-level="65.5" data-path="checkingGLM.html"><a href="checkingGLM.html#practical-10"><i class="fa fa-check"></i><b>65.5</b> Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="66" data-path="assess-perf.html"><a href="assess-perf.html"><i class="fa fa-check"></i><b>66</b> 評價模型的表現 Assessing model performance</a><ul>
<li class="chapter" data-level="66.1" data-path="assess-perf.html"><a href="assess-perf.html#calibration"><i class="fa fa-check"></i><b>66.1</b> 精準度 calibration</a></li>
<li class="chapter" data-level="66.2" data-path="assess-perf.html"><a href="assess-perf.html#可解釋因變量的變異度及-r2-決定係數"><i class="fa fa-check"></i><b>66.2</b> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</a></li>
<li class="chapter" data-level="66.3" data-path="assess-perf.html"><a href="assess-perf.html#分辨能力-descrimination"><i class="fa fa-check"></i><b>66.3</b> 分辨能力 descrimination</a><ul>
<li class="chapter" data-level="66.3.1" data-path="assess-perf.html"><a href="assess-perf.html#敏感度和特異度"><i class="fa fa-check"></i><b>66.3.1</b> 敏感度和特異度</a></li>
</ul></li>
<li class="chapter" data-level="66.4" data-path="assess-perf.html"><a href="assess-perf.html#practical-11"><i class="fa fa-check"></i><b>66.4</b> Practical 11</a></li>
</ul></li>
<li class="chapter" data-level="67" data-path="paired-ana.html"><a href="paired-ana.html"><i class="fa fa-check"></i><b>67</b> 配對實驗數據的分析法</a><ul>
<li class="chapter" data-level="67.1" data-path="paired-ana.html"><a href="paired-ana.html#配對的原理"><i class="fa fa-check"></i><b>67.1</b> 配對的原理</a><ul>
<li class="chapter" data-level="67.1.1" data-path="paired-ana.html"><a href="paired-ana.html#爲了提升估計的精確度"><i class="fa fa-check"></i><b>67.1.1</b> 爲了提升估計的精確度</a></li>
<li class="chapter" data-level="67.1.2" data-path="paired-ana.html"><a href="paired-ana.html#控制混雜因素"><i class="fa fa-check"></i><b>67.1.2</b> 控制混雜因素</a></li>
</ul></li>
<li class="chapter" data-level="67.2" data-path="paired-ana.html"><a href="paired-ana.html#結果變量爲連續型變量的配對實驗"><i class="fa fa-check"></i><b>67.2</b> 結果變量爲連續型變量的配對實驗</a><ul>
<li class="chapter" data-level="67.2.1" data-path="paired-ana.html"><a href="paired-ana.html#一般檢驗方法"><i class="fa fa-check"></i><b>67.2.1</b> 一般檢驗方法</a></li>
<li class="chapter" data-level="67.2.2" data-path="paired-ana.html"><a href="paired-ana.html#用迴歸法分析"><i class="fa fa-check"></i><b>67.2.2</b> 用迴歸法分析</a></li>
</ul></li>
<li class="chapter" data-level="67.3" data-path="paired-ana.html"><a href="paired-ana.html#結果變量是二進制變量的配對實驗"><i class="fa fa-check"></i><b>67.3</b> 結果變量是二進制變量的配對實驗</a><ul>
<li class="chapter" data-level="67.3.1" data-path="paired-ana.html"><a href="paired-ana.html#第一步-對數據作表格"><i class="fa fa-check"></i><b>67.3.1</b> 第一步 對數據作表格</a></li>
<li class="chapter" data-level="67.3.2" data-path="paired-ana.html"><a href="paired-ana.html#mcnemars-test"><i class="fa fa-check"></i><b>67.3.2</b> McNemar’s test</a></li>
<li class="chapter" data-level="67.3.3" data-path="paired-ana.html"><a href="paired-ana.html#二進制型結果變量配對實驗的比值比"><i class="fa fa-check"></i><b>67.3.3</b> 二進制型結果變量配對實驗的比值比</a></li>
<li class="chapter" data-level="67.3.4" data-path="paired-ana.html"><a href="paired-ana.html#配對實驗比值比的信賴區間"><i class="fa fa-check"></i><b>67.3.4</b> 配對實驗比值比的信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="67.4" data-path="paired-ana.html"><a href="paired-ana.html#條件-conditional-比值比和邊際-marginal-比值比"><i class="fa fa-check"></i><b>67.4</b> 條件 (conditional) 比值比和邊際 (marginal) 比值比</a></li>
</ul></li>
<li class="chapter" data-level="68" data-path="conditional-logistic.html"><a href="conditional-logistic.html"><i class="fa fa-check"></i><b>68</b> 條件邏輯迴歸 Conditional logistic regression</a><ul>
<li class="chapter" data-level="68.1" data-path="conditional-logistic.html"><a href="conditional-logistic.html#配對實驗的邏輯迴歸模型"><i class="fa fa-check"></i><b>68.1</b> 配對實驗的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="68.1.1" data-path="conditional-logistic.html"><a href="conditional-logistic.html#配對病例對照研究"><i class="fa fa-check"></i><b>68.1.1</b> 配對病例對照研究</a></li>
<li class="chapter" data-level="68.1.2" data-path="conditional-logistic.html"><a href="conditional-logistic.html#配對隊列研究"><i class="fa fa-check"></i><b>68.1.2</b> 配對隊列研究</a></li>
</ul></li>
<li class="chapter" data-level="68.2" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件邏輯回歸-二進制暴露變量"><i class="fa fa-check"></i><b>68.2</b> 條件邏輯回歸 – 二進制暴露變量</a><ul>
<li class="chapter" data-level="68.2.1" data-path="conditional-logistic.html"><a href="conditional-logistic.html#充分統計量-sufficient-statistics"><i class="fa fa-check"></i><b>68.2.1</b> 充分統計量 sufficient statistics</a></li>
<li class="chapter" data-level="68.2.2" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件邏輯回歸的推導"><i class="fa fa-check"></i><b>68.2.2</b> 條件邏輯回歸的推導</a></li>
<li class="chapter" data-level="68.2.3" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件似然-conditional-likelihood"><i class="fa fa-check"></i><b>68.2.3</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="68.2.4" data-path="conditional-logistic.html"><a href="conditional-logistic.html#進一步擴展"><i class="fa fa-check"></i><b>68.2.4</b> 進一步擴展</a></li>
</ul></li>
<li class="chapter" data-level="68.3" data-path="conditional-logistic.html"><a href="conditional-logistic.html#條件邏輯回歸模型的一般化"><i class="fa fa-check"></i><b>68.3</b> 條件邏輯回歸模型的一般化</a></li>
</ul></li>
<li class="chapter" data-level="69" data-path="multinomial-logistic.html"><a href="multinomial-logistic.html"><i class="fa fa-check"></i><b>69</b> 多項邏輯回歸 Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="70" data-path="ordinal-logistic.html"><a href="ordinal-logistic.html"><i class="fa fa-check"></i><b>70</b> 順序邏輯回歸 Ordinal Logistic Regression</a></li>
<li class="part"><span><b>IX 等級線性迴歸模型 analysis of hierarchical and other dependent data</b></span></li>
<li class="chapter" data-level="71" data-path="Hierarchical.html"><a href="Hierarchical.html"><i class="fa fa-check"></i><b>71</b> 相互依賴數據及簡單的應對方案</a><ul>
<li class="chapter" data-level="71.1" data-path="Hierarchical.html"><a href="Hierarchical.html#相互依賴的數據"><i class="fa fa-check"></i><b>71.1</b> 相互依賴的數據</a></li>
<li class="chapter" data-level="71.2" data-path="Hierarchical.html"><a href="Hierarchical.html#依賴性的來源在哪裏"><i class="fa fa-check"></i><b>71.2</b> 依賴性的來源在哪裏</a></li>
<li class="chapter" data-level="71.3" data-path="Hierarchical.html"><a href="Hierarchical.html#數據有依賴性導致的結果"><i class="fa fa-check"></i><b>71.3</b> 數據有依賴性導致的結果</a></li>
<li class="chapter" data-level="71.4" data-path="Hierarchical.html"><a href="Hierarchical.html#邊際模型和條件模型-marginal-and-conditional-models"><i class="fa fa-check"></i><b>71.4</b> 邊際模型和條件模型 marginal and conditional models</a><ul>
<li class="chapter" data-level="71.4.1" data-path="Hierarchical.html"><a href="Hierarchical.html#標記法-notation"><i class="fa fa-check"></i><b>71.4.1</b> 標記法 notation</a></li>
<li class="chapter" data-level="71.4.2" data-path="Hierarchical.html"><a href="Hierarchical.html#合並每個階層"><i class="fa fa-check"></i><b>71.4.2</b> 合並每個階層</a></li>
<li class="chapter" data-level="71.4.3" data-path="Hierarchical.html"><a href="Hierarchical.html#生物學悖論-ecological-fallacy"><i class="fa fa-check"></i><b>71.4.3</b> 生物學悖論 ecological fallacy</a></li>
<li class="chapter" data-level="71.4.4" data-path="Hierarchical.html"><a href="Hierarchical.html#分解層級數據"><i class="fa fa-check"></i><b>71.4.4</b> 分解層級數據</a></li>
<li class="chapter" data-level="71.4.5" data-path="Hierarchical.html"><a href="Hierarchical.html#固定效應模型-fixed-effect-model"><i class="fa fa-check"></i><b>71.4.5</b> 固定效應模型 fixed effect model</a></li>
</ul></li>
<li class="chapter" data-level="71.5" data-path="Hierarchical.html"><a href="Hierarchical.html#簡單線性迴歸複習"><i class="fa fa-check"></i><b>71.5</b> 簡單線性迴歸複習</a></li>
<li class="chapter" data-level="71.6" data-path="Hierarchical.html"><a href="Hierarchical.html#practical-hierarchical-01"><i class="fa fa-check"></i><b>71.6</b> Practical Hierarchical 01</a><ul>
<li class="chapter" data-level="71.6.1" data-path="Hierarchical.html"><a href="Hierarchical.html#數據"><i class="fa fa-check"></i><b>71.6.1</b> 數據</a></li>
<li class="chapter" data-level="71.6.2" data-path="Hierarchical.html"><a href="Hierarchical.html#問題"><i class="fa fa-check"></i><b>71.6.2</b> 問題</a></li>
<li class="chapter" data-level="71.6.3" data-path="Hierarchical.html"><a href="Hierarchical.html#將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵"><i class="fa fa-check"></i><b>71.6.3</b> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</a></li>
<li class="chapter" data-level="71.6.4" data-path="Hierarchical.html"><a href="Hierarchical.html#爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值"><i class="fa fa-check"></i><b>71.6.4</b> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</a></li>
<li class="chapter" data-level="71.6.5" data-path="Hierarchical.html"><a href="Hierarchical.html#先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中"><i class="fa fa-check"></i><b>71.6.5</b> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</a></li>
<li class="chapter" data-level="71.6.6" data-path="Hierarchical.html"><a href="Hierarchical.html#用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model"><i class="fa fa-check"></i><b>71.6.6</b> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</a></li>
<li class="chapter" data-level="71.6.7" data-path="Hierarchical.html"><a href="Hierarchical.html#分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型"><i class="fa fa-check"></i><b>71.6.7</b> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</a></li>
<li class="chapter" data-level="71.6.8" data-path="Hierarchical.html"><a href="Hierarchical.html#比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同"><i class="fa fa-check"></i><b>71.6.8</b> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</a></li>
<li class="chapter" data-level="71.6.9" data-path="Hierarchical.html"><a href="Hierarchical.html#把三種模型的數學成績擬合值散點圖繪製在同一張圖內"><i class="fa fa-check"></i><b>71.6.9</b> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</a></li>
<li class="chapter" data-level="71.6.10" data-path="Hierarchical.html"><a href="Hierarchical.html#用這-5-個學校的數據擬合一個固定效應線性迴歸模型"><i class="fa fa-check"></i><b>71.6.10</b> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</a></li>
<li class="chapter" data-level="71.6.11" data-path="Hierarchical.html"><a href="Hierarchical.html#讀入-pefr-數據"><i class="fa fa-check"></i><b>71.6.11</b> 讀入 PEFR 數據。</a></li>
<li class="chapter" data-level="71.6.12" data-path="Hierarchical.html"><a href="Hierarchical.html#求每個患者的-wp-兩次測量平均值"><i class="fa fa-check"></i><b>71.6.12</b> 求每個患者的 <code>wp</code> 兩次測量平均值</a></li>
<li class="chapter" data-level="71.6.13" data-path="Hierarchical.html"><a href="Hierarchical.html#在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數"><i class="fa fa-check"></i><b>71.6.13</b> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</a></li>
<li class="chapter" data-level="71.6.14" data-path="Hierarchical.html"><a href="Hierarchical.html#擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型"><i class="fa fa-check"></i><b>71.6.14</b> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</a></li>
<li class="chapter" data-level="71.6.15" data-path="Hierarchical.html"><a href="Hierarchical.html#將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式"><i class="fa fa-check"></i><b>71.6.15</b> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</a></li>
<li class="chapter" data-level="71.6.16" data-path="Hierarchical.html"><a href="Hierarchical.html#計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差"><i class="fa fa-check"></i><b>71.6.16</b> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="72" data-path="random-intercept.html"><a href="random-intercept.html"><i class="fa fa-check"></i><b>72</b> 隨機截距模型 random intercept model</a><ul>
<li class="chapter" data-level="72.1" data-path="random-intercept.html"><a href="random-intercept.html#隨機截距模型的定義"><i class="fa fa-check"></i><b>72.1</b> 隨機截距模型的定義</a></li>
<li class="chapter" data-level="72.2" data-path="random-intercept.html"><a href="random-intercept.html#隨機截距模型的參數估計"><i class="fa fa-check"></i><b>72.2</b> 隨機截距模型的參數估計</a></li>
<li class="chapter" data-level="72.3" data-path="random-intercept.html"><a href="random-intercept.html#如何在-r-中進行隨機截距模型的擬合"><i class="fa fa-check"></i><b>72.3</b> 如何在 R 中進行隨機截距模型的擬合</a></li>
<li class="chapter" data-level="72.4" data-path="random-intercept.html"><a href="random-intercept.html#隨機截距模型中的統計推斷"><i class="fa fa-check"></i><b>72.4</b> 隨機截距模型中的統計推斷</a><ul>
<li class="chapter" data-level="72.4.1" data-path="random-intercept.html"><a href="random-intercept.html#fixed-inference"><i class="fa fa-check"></i><b>72.4.1</b> 固定效應部分的推斷</a></li>
<li class="chapter" data-level="72.4.2" data-path="random-intercept.html"><a href="random-intercept.html#隨機效應部分的推斷"><i class="fa fa-check"></i><b>72.4.2</b> 隨機效應部分的推斷</a></li>
</ul></li>
<li class="chapter" data-level="72.5" data-path="random-intercept.html"><a href="random-intercept.html#practical-hierarchical-02"><i class="fa fa-check"></i><b>72.5</b> Practical Hierarchical 02</a><ul>
<li class="chapter" data-level="72.5.1" data-path="random-intercept.html"><a href="random-intercept.html#數據-1"><i class="fa fa-check"></i><b>72.5.1</b> 數據</a></li>
<li class="chapter" data-level="72.5.2" data-path="random-intercept.html"><a href="random-intercept.html#讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分"><i class="fa fa-check"></i><b>72.5.2</b> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</a></li>
<li class="chapter" data-level="72.5.3" data-path="random-intercept.html"><a href="random-intercept.html#把數據從寬-wide-改變成長-long-的形式"><i class="fa fa-check"></i><b>72.5.3</b> 把數據從寬 (wide) 改變成長 (long) 的形式</a></li>
<li class="chapter" data-level="72.5.4" data-path="random-intercept.html"><a href="random-intercept.html#對數據按照-id-分層進行-anova"><i class="fa fa-check"></i><b>72.5.4</b> 對數據按照 <code>id</code> 分層進行 ANOVA</a></li>
<li class="chapter" data-level="72.5.5" data-path="random-intercept.html"><a href="random-intercept.html#用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果"><i class="fa fa-check"></i><b>72.5.5</b> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</a></li>
<li class="chapter" data-level="72.5.6" data-path="random-intercept.html"><a href="random-intercept.html#用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同"><i class="fa fa-check"></i><b>72.5.6</b> 用極大似然法 (maximum likelihood, ML) <code>method = "ML"</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</a></li>
<li class="chapter" data-level="72.5.7" data-path="random-intercept.html"><a href="random-intercept.html#用簡單線性迴歸擬合一個固定效應模型"><i class="fa fa-check"></i><b>72.5.7</b> 用簡單線性迴歸擬合一個固定效應模型</a></li>
<li class="chapter" data-level="72.5.8" data-path="random-intercept.html"><a href="random-intercept.html#計算這些隨機截距的均值和標準差"><i class="fa fa-check"></i><b>72.5.8</b> 計算這些隨機截距的均值和標準差</a></li>
<li class="chapter" data-level="72.5.9" data-path="random-intercept.html"><a href="random-intercept.html#忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸"><i class="fa fa-check"></i><b>72.5.9</b> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</a></li>
<li class="chapter" data-level="72.5.10" data-path="random-intercept.html"><a href="random-intercept.html#用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較"><i class="fa fa-check"></i><b>72.5.10</b> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</a></li>
<li class="chapter" data-level="72.5.11" data-path="random-intercept.html"><a href="random-intercept.html#讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量"><i class="fa fa-check"></i><b>72.5.11</b> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="73" data-path="random-inter-cov.html"><a href="random-inter-cov.html"><i class="fa fa-check"></i><b>73</b> 隨機截距模型中加入共變量 random intercept model with covariates</a><ul>
<li class="chapter" data-level="73.1" data-path="random-inter-cov.html"><a href="random-inter-cov.html#多元線性回歸模型的延伸"><i class="fa fa-check"></i><b>73.1</b> 多元線性回歸模型的延伸</a></li>
<li class="chapter" data-level="73.2" data-path="random-inter-cov.html"><a href="random-inter-cov.html#siblings-數據中新生兒體重的實例"><i class="fa fa-check"></i><b>73.2</b> <code>siblings</code> 數據中新生兒體重的實例</a></li>
<li class="chapter" data-level="73.3" data-path="random-inter-cov.html"><a href="random-inter-cov.html#賦值予隨機效應成分"><i class="fa fa-check"></i><b>73.3</b> 賦值予隨機效應成分</a><ul>
<li class="chapter" data-level="73.3.1" data-path="random-inter-cov.html"><a href="random-inter-cov.html#簡單預測-simple-prediction"><i class="fa fa-check"></i><b>73.3.1</b> 簡單預測 simple prediction</a></li>
<li class="chapter" data-level="73.3.2" data-path="random-inter-cov.html"><a href="random-inter-cov.html#eb-預測值"><i class="fa fa-check"></i><b>73.3.2</b> EB 預測值</a></li>
</ul></li>
<li class="chapter" data-level="73.4" data-path="random-inter-cov.html"><a href="random-inter-cov.html#混合效應模型的診斷"><i class="fa fa-check"></i><b>73.4</b> 混合效應模型的診斷</a></li>
<li class="chapter" data-level="73.5" data-path="random-inter-cov.html"><a href="random-inter-cov.html#第二層級-cluster-levellevel-2-的協方差"><i class="fa fa-check"></i><b>73.5</b> 第二層級 (cluster level/level 2) 的協方差</a></li>
<li class="chapter" data-level="73.6" data-path="random-inter-cov.html"><a href="random-inter-cov.html#層內層間效應估計"><i class="fa fa-check"></i><b>73.6</b> 層內層間效應估計</a></li>
<li class="chapter" data-level="73.7" data-path="random-inter-cov.html"><a href="random-inter-cov.html#到底選擇固定還是混合模型"><i class="fa fa-check"></i><b>73.7</b> 到底選擇固定還是混合模型？</a></li>
<li class="chapter" data-level="73.8" data-path="random-inter-cov.html"><a href="random-inter-cov.html#practical-hierarchical-03"><i class="fa fa-check"></i><b>73.8</b> Practical Hierarchical 03</a><ul>
<li class="chapter" data-level="73.8.1" data-path="random-inter-cov.html"><a href="random-inter-cov.html#把-high-school-and-beyond-數據讀入-r-中"><i class="fa fa-check"></i><b>73.8.1</b> 把 High-school-and-Beyond 數據讀入 R 中。</a></li>
<li class="chapter" data-level="73.8.2" data-path="random-inter-cov.html"><a href="random-inter-cov.html#擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同"><i class="fa fa-check"></i><b>73.8.2</b> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</a></li>
<li class="chapter" data-level="73.8.3" data-path="random-inter-cov.html"><a href="random-inter-cov.html#觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎"><i class="fa fa-check"></i><b>73.8.3</b> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</a></li>
<li class="chapter" data-level="73.8.4" data-path="random-inter-cov.html"><a href="random-inter-cov.html#現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化"><i class="fa fa-check"></i><b>73.8.4</b> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</a></li>
<li class="chapter" data-level="73.8.5" data-path="random-inter-cov.html"><a href="random-inter-cov.html#在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據"><i class="fa fa-check"></i><b>73.8.5</b> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</a></li>
<li class="chapter" data-level="73.8.6" data-path="random-inter-cov.html"><a href="random-inter-cov.html#把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎"><i class="fa fa-check"></i><b>73.8.6</b> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</a></li>
<li class="chapter" data-level="73.8.7" data-path="random-inter-cov.html"><a href="random-inter-cov.html#在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化"><i class="fa fa-check"></i><b>73.8.7</b> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</a></li>
<li class="chapter" data-level="73.8.8" data-path="random-inter-cov.html"><a href="random-inter-cov.html#檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e"><i class="fa fa-check"></i><b>73.8.8</b> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></a></li>
<li class="chapter" data-level="73.8.9" data-path="random-inter-cov.html"><a href="random-inter-cov.html#對上面最後一個模型進行殘差分析和模型的診斷"><i class="fa fa-check"></i><b>73.8.9</b> 對上面最後一個模型進行殘差分析和模型的診斷。</a></li>
<li class="chapter" data-level="73.8.10" data-path="random-inter-cov.html"><a href="random-inter-cov.html#通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值"><i class="fa fa-check"></i><b>73.8.10</b> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</a></li>
<li class="chapter" data-level="73.8.11" data-path="random-inter-cov.html"><a href="random-inter-cov.html#計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差"><i class="fa fa-check"></i><b>73.8.11</b> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="74" data-path="random-coefficient.html"><a href="random-coefficient.html"><i class="fa fa-check"></i><b>74</b> 隨機回歸系數模型 random coefficient model</a><ul>
<li class="chapter" data-level="74.1" data-path="random-coefficient.html"><a href="random-coefficient.html#gcse-scores-實例"><i class="fa fa-check"></i><b>74.1</b> GCSE scores 實例</a></li>
<li class="chapter" data-level="74.2" data-path="random-coefficient.html"><a href="random-coefficient.html#隨機回歸系數的實質"><i class="fa fa-check"></i><b>74.2</b> 隨機回歸系數的實質</a></li>
<li class="chapter" data-level="74.3" data-path="random-coefficient.html"><a href="random-coefficient.html#繼續-gcse-scores-實例"><i class="fa fa-check"></i><b>74.3</b> 繼續 GCSE scores 實例</a></li>
<li class="chapter" data-level="74.4" data-path="random-coefficient.html"><a href="random-coefficient.html#使用模型結果推斷"><i class="fa fa-check"></i><b>74.4</b> 使用模型結果推斷</a></li>
<li class="chapter" data-level="74.5" data-path="random-coefficient.html"><a href="random-coefficient.html#random-var"><i class="fa fa-check"></i><b>74.5</b> 隨機效應的方差</a></li>
<li class="chapter" data-level="74.6" data-path="random-coefficient.html"><a href="random-coefficient.html#模型效果評估"><i class="fa fa-check"></i><b>74.6</b> 模型效果評估</a></li>
<li class="chapter" data-level="74.7" data-path="random-coefficient.html"><a href="random-coefficient.html#practical-hierarchical-04"><i class="fa fa-check"></i><b>74.7</b> Practical Hierarchical 04</a><ul>
<li class="chapter" data-level="74.7.1" data-path="random-coefficient.html"><a href="random-coefficient.html#先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校"><i class="fa fa-check"></i><b>74.7.1</b> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</a></li>
<li class="chapter" data-level="74.7.2" data-path="random-coefficient.html"><a href="random-coefficient.html#僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化"><i class="fa fa-check"></i><b>74.7.2</b> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</a></li>
<li class="chapter" data-level="74.7.3" data-path="random-coefficient.html"><a href="random-coefficient.html#使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義"><i class="fa fa-check"></i><b>74.7.3</b> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</a></li>
<li class="chapter" data-level="74.7.4" data-path="random-coefficient.html"><a href="random-coefficient.html#在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然"><i class="fa fa-check"></i><b>74.7.4</b> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</a></li>
<li class="chapter" data-level="74.7.5" data-path="random-coefficient.html"><a href="random-coefficient.html#擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分"><i class="fa fa-check"></i><b>74.7.5</b> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</a></li>
<li class="chapter" data-level="74.7.6" data-path="random-coefficient.html"><a href="random-coefficient.html#通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義"><i class="fa fa-check"></i><b>74.7.6</b> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</a></li>
<li class="chapter" data-level="74.7.7" data-path="random-coefficient.html"><a href="random-coefficient.html#模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢"><i class="fa fa-check"></i><b>74.7.7</b> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</a></li>
<li class="chapter" data-level="74.7.8" data-path="random-coefficient.html"><a href="random-coefficient.html#現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt"><i class="fa fa-check"></i><b>74.7.8</b> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</a></li>
<li class="chapter" data-level="74.7.9" data-path="random-coefficient.html"><a href="random-coefficient.html#這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎"><i class="fa fa-check"></i><b>74.7.9</b> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</a></li>
<li class="chapter" data-level="74.7.10" data-path="random-coefficient.html"><a href="random-coefficient.html#計算這個模型的第二階級level-2-school-level的殘差"><i class="fa fa-check"></i><b>74.7.10</b> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</a></li>
<li class="chapter" data-level="74.7.11" data-path="random-coefficient.html"><a href="random-coefficient.html#計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何"><i class="fa fa-check"></i><b>74.7.11</b> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="75" data-path="longitudinal1.html"><a href="longitudinal1.html"><i class="fa fa-check"></i><b>75</b> 縱向研究數據 longitudinal data 1</a><ul>
<li class="chapter" data-level="75.1" data-path="longitudinal1.html"><a href="longitudinal1.html#固定測量時刻-fixed-occasions"><i class="fa fa-check"></i><b>75.1</b> 固定測量時刻 fixed occasions</a><ul>
<li class="chapter" data-level="75.1.1" data-path="longitudinal1.html"><a href="longitudinal1.html#缺失值-missing-data"><i class="fa fa-check"></i><b>75.1.1</b> 缺失值 Missing data</a></li>
</ul></li>
<li class="chapter" data-level="75.2" data-path="longitudinal1.html"><a href="longitudinal1.html#不固定測量時刻-variable-occasions"><i class="fa fa-check"></i><b>75.2</b> 不固定測量時刻 variable occasions</a></li>
<li class="chapter" data-level="75.3" data-path="longitudinal1.html"><a href="longitudinal1.html#預測軌跡-predicting-trajectories"><i class="fa fa-check"></i><b>75.3</b> 預測軌跡 predicting trajectories</a></li>
<li class="chapter" data-level="75.4" data-path="longitudinal1.html"><a href="longitudinal1.html#practical-05-hier"><i class="fa fa-check"></i><b>75.4</b> Practical 05-Hier</a></li>
</ul></li>
<li class="chapter" data-level="76" data-path="longitudinal2.html"><a href="longitudinal2.html"><i class="fa fa-check"></i><b>76</b> 縱向研究數據 longitudinal data 2</a><ul>
<li class="chapter" data-level="76.1" data-path="longitudinal2.html"><a href="longitudinal2.html#邊際結構-marginal-structures"><i class="fa fa-check"></i><b>76.1</b> 邊際結構 marginal structures</a><ul>
<li class="chapter" data-level="76.1.1" data-path="longitudinal2.html"><a href="longitudinal2.html#隨機截距模型"><i class="fa fa-check"></i><b>76.1.1</b> 隨機截距模型</a></li>
<li class="chapter" data-level="76.1.2" data-path="longitudinal2.html"><a href="longitudinal2.html#隨機系數模型"><i class="fa fa-check"></i><b>76.1.2</b> 隨機系數模型</a></li>
</ul></li>
<li class="chapter" data-level="76.2" data-path="longitudinal2.html"><a href="longitudinal2.html#矩陣記法"><i class="fa fa-check"></i><b>76.2</b> 矩陣記法</a></li>
<li class="chapter" data-level="76.3" data-path="longitudinal2.html"><a href="longitudinal2.html#混合效應模型的一般化公式"><i class="fa fa-check"></i><b>76.3</b> 混合效應模型的一般化公式</a></li>
<li class="chapter" data-level="76.4" data-path="longitudinal2.html"><a href="longitudinal2.html#其他可選擇的方差協方差矩陣特徵"><i class="fa fa-check"></i><b>76.4</b> 其他可選擇的方差協方差矩陣特徵</a></li>
<li class="chapter" data-level="76.5" data-path="longitudinal2.html"><a href="longitudinal2.html#其他要點評論"><i class="fa fa-check"></i><b>76.5</b> 其他要點評論</a></li>
<li class="chapter" data-level="76.6" data-path="longitudinal2.html"><a href="longitudinal2.html#不平衡數據"><i class="fa fa-check"></i><b>76.6</b> 不平衡數據</a></li>
<li class="chapter" data-level="76.7" data-path="longitudinal2.html"><a href="longitudinal2.html#practical-06-hier"><i class="fa fa-check"></i><b>76.7</b> Practical 06-Hier</a></li>
</ul></li>
<li class="chapter" data-level="77" data-path="longitudinal3.html"><a href="longitudinal3.html"><i class="fa fa-check"></i><b>77</b> 縱向研究數據 longitudinal data 3</a><ul>
<li class="chapter" data-level="77.1" data-path="longitudinal3.html"><a href="longitudinal3.html#第一層級的異質性-level-1-heterogeneity"><i class="fa fa-check"></i><b>77.1</b> 第一層級的異質性 level 1 heterogeneity</a></li>
<li class="chapter" data-level="77.2" data-path="longitudinal3.html"><a href="longitudinal3.html#第二層級異質性-level-2-heterogeneity"><i class="fa fa-check"></i><b>77.2</b> 第二層級異質性 level 2 heterogeneity</a></li>
<li class="chapter" data-level="77.3" data-path="longitudinal3.html"><a href="longitudinal3.html#分析策略"><i class="fa fa-check"></i><b>77.3</b> 分析策略</a><ul>
<li class="chapter" data-level="77.3.1" data-path="longitudinal3.html"><a href="longitudinal3.html#模型選擇和建模步驟"><i class="fa fa-check"></i><b>77.3.1</b> 模型選擇和建模步驟</a></li>
</ul></li>
<li class="chapter" data-level="77.4" data-path="longitudinal3.html"><a href="longitudinal3.html#practical-07-hier"><i class="fa fa-check"></i><b>77.4</b> Practical 07-Hier</a></li>
</ul></li>
<li class="chapter" data-level="78" data-path="-generalized-estimating-equation.html"><a href="-generalized-estimating-equation.html"><i class="fa fa-check"></i><b>78</b> 廣義估計方程式 Generalized Estimating Equation</a><ul>
<li class="chapter" data-level="78.1" data-path="-generalized-estimating-equation.html"><a href="-generalized-estimating-equation.html#practical-08-hier"><i class="fa fa-check"></i><b>78.1</b> Practical 08-Hier</a></li>
</ul></li>
<li class="chapter" data-level="79" data-path="cluster-ana.html"><a href="cluster-ana.html"><i class="fa fa-check"></i><b>79</b> 聚類分析 Cluster analysis/unsupervised learning</a><ul>
<li class="chapter" data-level="79.1" data-path="cluster-ana.html"><a href="cluster-ana.html#聚類分析過程"><i class="fa fa-check"></i><b>79.1</b> 聚類分析過程</a><ul>
<li class="chapter" data-level="79.1.1" data-path="cluster-ana.html"><a href="cluster-ana.html#連續型變量-continuous-variables-in-cluster-analysis"><i class="fa fa-check"></i><b>79.1.1</b> 連續型變量 continuous variables in cluster analysis</a></li>
<li class="chapter" data-level="79.1.2" data-path="cluster-ana.html"><a href="cluster-ana.html#二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables"><i class="fa fa-check"></i><b>79.1.2</b> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</a></li>
<li class="chapter" data-level="79.1.3" data-path="cluster-ana.html"><a href="cluster-ana.html#定義分類方法"><i class="fa fa-check"></i><b>79.1.3</b> 定義分類方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="80" data-path="PCA.html"><a href="PCA.html"><i class="fa fa-check"></i><b>80</b> 主成分分析 Principal Component Analysis</a><ul>
<li class="chapter" data-level="80.1" data-path="PCA.html"><a href="PCA.html#數據有相關性時產生的問題"><i class="fa fa-check"></i><b>80.1</b> 數據有相關性時產生的問題</a></li>
<li class="chapter" data-level="80.2" data-path="PCA.html"><a href="PCA.html#最大化方差等價於最大化數據點到新座標軸投影projection的長度"><i class="fa fa-check"></i><b>80.2</b> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</a></li>
<li class="chapter" data-level="80.3" data-path="PCA.html"><a href="PCA.html#數學推導"><i class="fa fa-check"></i><b>80.3</b> 數學推導</a><ul>
<li class="chapter" data-level="80.3.1" data-path="PCA.html"><a href="PCA.html#超越對稱矩陣奇異值分解-singular-value-decomposition-svd"><i class="fa fa-check"></i><b>80.3.1</b> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</a></li>
</ul></li>
<li class="chapter" data-level="80.4" data-path="PCA.html"><a href="PCA.html#主成分分析數據實例"><i class="fa fa-check"></i><b>80.4</b> 主成分分析數據實例</a></li>
<li class="chapter" data-level="80.5" data-path="PCA.html"><a href="PCA.html#在pca圖形中加入補充變量和補充個體-supplementary-elements"><i class="fa fa-check"></i><b>80.5</b> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</a><ul>
<li class="chapter" data-level="80.5.1" data-path="PCA.html"><a href="PCA.html#展示分類輔助性變量和個體的關係"><i class="fa fa-check"></i><b>80.5.1</b> 展示分類輔助性變量和個體的關係</a></li>
</ul></li>
<li class="chapter" data-level="80.6" data-path="PCA.html"><a href="PCA.html#cluster-analysispca-practical"><i class="fa fa-check"></i><b>80.6</b> Cluster analysis/PCA practical</a><ul>
<li class="chapter" data-level="80.6.1" data-path="PCA.html"><a href="PCA.html#使用的數據和簡單背景知識"><i class="fa fa-check"></i><b>80.6.1</b> 使用的數據和簡單背景知識</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="81" data-path="-missing-data-1.html"><a href="-missing-data-1.html"><i class="fa fa-check"></i><b>81</b> 缺失數據 Missing data 1</a><ul>
<li class="chapter" data-level="81.1" data-path="-missing-data-1.html"><a href="-missing-data-1.html#處理原則建議recommended-principles"><i class="fa fa-check"></i><b>81.1</b> 處理原則（建議）recommended principles</a></li>
<li class="chapter" data-level="81.2" data-path="-missing-data-1.html"><a href="-missing-data-1.html#缺失數據機制-missingness-mechanisms"><i class="fa fa-check"></i><b>81.2</b> 缺失數據機制 missingness mechanisms</a></li>
<li class="chapter" data-level="81.3" data-path="-missing-data-1.html"><a href="-missing-data-1.html#臨時解決方案-ad-hoc-approaches"><i class="fa fa-check"></i><b>81.3</b> 臨時解決方案 ad-hoc approaches</a></li>
<li class="chapter" data-level="81.4" data-path="-missing-data-1.html"><a href="-missing-data-1.html#單一變量的參數多重插補法-parametric-multiple-imputation-of-one-variable"><i class="fa fa-check"></i><b>81.4</b> 單一變量的參數多重插補法 parametric multiple imputation of one variable</a></li>
<li class="chapter" data-level="81.5" data-path="-missing-data-1.html"><a href="-missing-data-1.html#變量選擇插補次數模型檢查"><i class="fa fa-check"></i><b>81.5</b> 變量選擇，插補次數，模型檢查</a></li>
<li class="chapter" data-level="81.6" data-path="-missing-data-1.html"><a href="-missing-data-1.html#總結"><i class="fa fa-check"></i><b>81.6</b> 總結</a></li>
<li class="chapter" data-level="81.7" data-path="-missing-data-1.html"><a href="-missing-data-1.html#practical-10-hier"><i class="fa fa-check"></i><b>81.7</b> Practical 10-Hier</a><ul>
<li class="chapter" data-level="81.7.1" data-path="-missing-data-1.html"><a href="-missing-data-1.html#數據缺失產生的影響缺失機制和多重插補法"><i class="fa fa-check"></i><b>81.7.1</b> 數據缺失產生的影響，缺失機制，和多重插補法</a></li>
<li class="chapter" data-level="81.7.2" data-path="-missing-data-1.html"><a href="-missing-data-1.html#二進制變量的缺失-class-size-study"><i class="fa fa-check"></i><b>81.7.2</b> 二進制變量的缺失 “class size study”</a></li>
<li class="chapter" data-level="81.7.3" data-path="-missing-data-1.html"><a href="-missing-data-1.html#完整數據分析結果"><i class="fa fa-check"></i><b>81.7.3</b> 完整數據分析結果</a></li>
<li class="chapter" data-level="81.7.4" data-path="-missing-data-1.html"><a href="-missing-data-1.html#去除了缺失值的分析結果-complete-case-analysis"><i class="fa fa-check"></i><b>81.7.4</b> 去除了缺失值的分析結果 complete case analysis</a></li>
<li class="chapter" data-level="81.7.5" data-path="-missing-data-1.html"><a href="-missing-data-1.html#分析-sen_m-的缺失值機制"><i class="fa fa-check"></i><b>81.7.5</b> 分析 <code>sen_m</code> 的缺失值機制</a></li>
<li class="chapter" data-level="81.7.6" data-path="-missing-data-1.html"><a href="-missing-data-1.html#多重插補-multiple-imputation"><i class="fa fa-check"></i><b>81.7.6</b> 多重插補 multiple imputation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="82" data-path="-missing-data-2.html"><a href="-missing-data-2.html"><i class="fa fa-check"></i><b>82</b> 缺失數據 Missing data 2</a></li>
<li class="chapter" data-level="83" data-path="further-issues.html"><a href="further-issues.html"><i class="fa fa-check"></i><b>83</b> Further issues</a></li>
<li class="part"><span><b>X 生存分析 Survival Analysis</b></span></li>
<li class="chapter" data-level="84" data-path="surv-intro.html"><a href="surv-intro.html"><i class="fa fa-check"></i><b>84</b> 生存分析入門</a><ul>
<li class="chapter" data-level="84.1" data-path="surv-intro.html"><a href="surv-intro.html#本章概要"><i class="fa fa-check"></i><b>84.1</b> 本章概要</a></li>
<li class="chapter" data-level="84.2" data-path="surv-intro.html"><a href="surv-intro.html#什麼是生存分析-what-is-survival-analysis"><i class="fa fa-check"></i><b>84.2</b> 什麼是生存分析 What is survival analysis?</a></li>
<li class="chapter" data-level="84.3" data-path="surv-intro.html"><a href="surv-intro.html#生存數據在哪裏"><i class="fa fa-check"></i><b>84.3</b> 生存數據在哪裏</a></li>
<li class="chapter" data-level="84.4" data-path="surv-intro.html"><a href="surv-intro.html#生存數據分析之前要理清楚的問題"><i class="fa fa-check"></i><b>84.4</b> 生存數據分析之前要理清楚的問題</a></li>
<li class="chapter" data-level="84.5" data-path="surv-intro.html"><a href="surv-intro.html#生存數據的左右截尾"><i class="fa fa-check"></i><b>84.5</b> 生存數據的左右截尾</a><ul>
<li class="chapter" data-level="84.5.1" data-path="surv-intro.html"><a href="surv-intro.html#左側截尾數據-left-truncation"><i class="fa fa-check"></i><b>84.5.1</b> 左側截尾數據 left-truncation</a></li>
</ul></li>
<li class="chapter" data-level="84.6" data-path="surv-intro.html"><a href="surv-intro.html#初步分析生存數據"><i class="fa fa-check"></i><b>84.6</b> 初步分析生存數據</a></li>
<li class="chapter" data-level="84.7" data-path="surv-intro.html"><a href="surv-intro.html#初步描述生存數據"><i class="fa fa-check"></i><b>84.7</b> 初步描述生存數據</a><ul>
<li class="chapter" data-level="84.7.1" data-path="surv-intro.html"><a href="surv-intro.html#生存方程"><i class="fa fa-check"></i><b>84.7.1</b> 生存方程</a></li>
<li class="chapter" data-level="84.7.2" data-path="surv-intro.html"><a href="surv-intro.html#風險度方程"><i class="fa fa-check"></i><b>84.7.2</b> 風險度方程</a></li>
<li class="chapter" data-level="84.7.3" data-path="surv-intro.html"><a href="surv-intro.html#概率密度方程"><i class="fa fa-check"></i><b>84.7.3</b> 概率密度方程</a></li>
<li class="chapter" data-level="84.7.4" data-path="surv-intro.html"><a href="surv-intro.html#各方程之間的關系"><i class="fa fa-check"></i><b>84.7.4</b> 各方程之間的關系</a></li>
</ul></li>
<li class="chapter" data-level="84.8" data-path="surv-intro.html"><a href="surv-intro.html#生存時間的參數分布"><i class="fa fa-check"></i><b>84.8</b> 生存時間的參數分布</a><ul>
<li class="chapter" data-level="84.8.1" data-path="surv-intro.html"><a href="surv-intro.html#exponentialdist"><i class="fa fa-check"></i><b>84.8.1</b> 指數分布</a></li>
<li class="chapter" data-level="84.8.2" data-path="surv-intro.html"><a href="surv-intro.html#weibulldist"><i class="fa fa-check"></i><b>84.8.2</b> Weibull 分布</a></li>
</ul></li>
<li class="chapter" data-level="84.9" data-path="surv-intro.html"><a href="surv-intro.html#極大似然法估計"><i class="fa fa-check"></i><b>84.9</b> 極大似然法估計</a></li>
<li class="chapter" data-level="84.10" data-path="surv-intro.html"><a href="surv-intro.html#practical-survival-01"><i class="fa fa-check"></i><b>84.10</b> Practical Survival 01</a><ul>
<li class="chapter" data-level="84.10.1" data-path="surv-intro.html"><a href="surv-intro.html#生存分析的時間尺度"><i class="fa fa-check"></i><b>84.10.1</b> 生存分析的時間尺度</a></li>
<li class="chapter" data-level="84.10.2" data-path="surv-intro.html"><a href="surv-intro.html#擬合最簡單的指數分布生存數據"><i class="fa fa-check"></i><b>84.10.2</b> 擬合最簡單的指數分布生存數據</a></li>
<li class="chapter" data-level="84.10.3" data-path="surv-intro.html"><a href="surv-intro.html#探索服從-weibull-分布時風險度方程的曲線"><i class="fa fa-check"></i><b>84.10.3</b> 探索服從 Weibull 分布時風險度方程的曲線</a></li>
<li class="chapter" data-level="84.10.4" data-path="surv-intro.html"><a href="surv-intro.html#探索-對數邏輯-log-logistic-分布時風險度方程曲線會有哪些特性"><i class="fa fa-check"></i><b>84.10.4</b> 探索 對數邏輯 (log-logistic) 分布時，風險度方程曲線會有哪些特性？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="85" data-path="nonparametric.html"><a href="nonparametric.html"><i class="fa fa-check"></i><b>85</b> 非參數法分析生存數據</a><ul>
<li class="chapter" data-level="85.1" data-path="nonparametric.html"><a href="nonparametric.html#本章概要-1"><i class="fa fa-check"></i><b>85.1</b> 本章概要</a></li>
<li class="chapter" data-level="85.2" data-path="nonparametric.html"><a href="nonparametric.html#生存分析中的非參數分析法"><i class="fa fa-check"></i><b>85.2</b> 生存分析中的非參數分析法</a></li>
<li class="chapter" data-level="85.3" data-path="nonparametric.html"><a href="nonparametric.html#kaplan-meier-法分析生存方程"><i class="fa fa-check"></i><b>85.3</b> Kaplan-Meier 法分析生存方程</a><ul>
<li class="chapter" data-level="85.3.1" data-path="nonparametric.html"><a href="nonparametric.html#當數據中沒有刪失值"><i class="fa fa-check"></i><b>85.3.1</b> 當數據中沒有刪失值</a></li>
<li class="chapter" data-level="85.3.2" data-path="nonparametric.html"><a href="nonparametric.html#當數據中有刪失值"><i class="fa fa-check"></i><b>85.3.2</b> 當數據中有刪失值</a></li>
</ul></li>
<li class="chapter" data-level="85.4" data-path="nonparametric.html"><a href="nonparametric.html#kaplan-meier-數據的信賴區間的估計"><i class="fa fa-check"></i><b>85.4</b> Kaplan-Meier 數據的信賴區間的估計</a></li>
<li class="chapter" data-level="85.5" data-path="nonparametric.html"><a href="nonparametric.html#另一種非參數法分析-生命表格估計"><i class="fa fa-check"></i><b>85.5</b> 另一種非參數法分析 – 生命表格估計</a></li>
<li class="chapter" data-level="85.6" data-path="nonparametric.html"><a href="nonparametric.html#兩組之間生存概率的比較"><i class="fa fa-check"></i><b>85.6</b> 兩組之間生存概率的比較</a><ul>
<li class="chapter" data-level="85.6.1" data-path="nonparametric.html"><a href="nonparametric.html#the-log-rank-test"><i class="fa fa-check"></i><b>85.6.1</b> The log rank test</a></li>
</ul></li>
<li class="chapter" data-level="85.7" data-path="nonparametric.html"><a href="nonparametric.html#計算累積風險度-cumulative-hazard"><i class="fa fa-check"></i><b>85.7</b> 計算累積風險度 cumulative hazard</a></li>
<li class="chapter" data-level="85.8" data-path="nonparametric.html"><a href="nonparametric.html#關於非參數分析法的一些延伸"><i class="fa fa-check"></i><b>85.8</b> 關於非參數分析法的一些延伸</a></li>
<li class="chapter" data-level="85.9" data-path="nonparametric.html"><a href="nonparametric.html#practical-survival-02"><i class="fa fa-check"></i><b>85.9</b> Practical Survival 02</a><ul>
<li class="chapter" data-level="85.9.1" data-path="nonparametric.html"><a href="nonparametric.html#part-1-pbc-數據"><i class="fa fa-check"></i><b>85.9.1</b> Part 1: PBC 數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="86" data-path="surv-reg.html"><a href="surv-reg.html"><i class="fa fa-check"></i><b>86</b> 生存數據中的回歸模型</a><ul>
<li class="chapter" data-level="86.1" data-path="surv-reg.html"><a href="surv-reg.html#本章概要-2"><i class="fa fa-check"></i><b>86.1</b> 本章概要</a></li>
<li class="chapter" data-level="86.2" data-path="surv-reg.html"><a href="surv-reg.html#使用參數模型分析生存數據的目的"><i class="fa fa-check"></i><b>86.2</b> 使用參數模型分析生存數據的目的</a></li>
<li class="chapter" data-level="86.3" data-path="surv-reg.html"><a href="surv-reg.html#生存數據的似然方程"><i class="fa fa-check"></i><b>86.3</b> 生存數據的似然方程</a></li>
<li class="chapter" data-level="86.4" data-path="surv-reg.html"><a href="surv-reg.html#如何加入解釋變量"><i class="fa fa-check"></i><b>86.4</b> 如何加入解釋變量</a></li>
<li class="chapter" data-level="86.5" data-path="surv-reg.html"><a href="surv-reg.html#指數模型-exponential-model"><i class="fa fa-check"></i><b>86.5</b> 指數模型 exponential model</a></li>
<li class="chapter" data-level="86.6" data-path="surv-reg.html"><a href="surv-reg.html#weibull-分布"><i class="fa fa-check"></i><b>86.6</b> Weibull 分布</a></li>
<li class="chapter" data-level="86.7" data-path="surv-reg.html"><a href="surv-reg.html#weibull-和-指數模型的比較"><i class="fa fa-check"></i><b>86.7</b> Weibull 和 指數模型的比較</a><ul>
<li class="chapter" data-level="86.7.1" data-path="surv-reg.html"><a href="surv-reg.html#繪圖法"><i class="fa fa-check"></i><b>86.7.1</b> 繪圖法</a></li>
<li class="chapter" data-level="86.7.2" data-path="surv-reg.html"><a href="surv-reg.html#統計檢驗法"><i class="fa fa-check"></i><b>86.7.2</b> 統計檢驗法</a></li>
</ul></li>
<li class="chapter" data-level="86.8" data-path="surv-reg.html"><a href="surv-reg.html#拓展解釋變量類型與個數的參數模型"><i class="fa fa-check"></i><b>86.8</b> 拓展解釋變量（類型與個數）的參數模型</a><ul>
<li class="chapter" data-level="86.8.1" data-path="surv-reg.html"><a href="surv-reg.html#當變量是連續型時"><i class="fa fa-check"></i><b>86.8.1</b> 當變量是連續型時</a></li>
<li class="chapter" data-level="86.8.2" data-path="surv-reg.html"><a href="surv-reg.html#多於兩種類型的分類型變量"><i class="fa fa-check"></i><b>86.8.2</b> （多於兩種類型的）分類型變量</a></li>
<li class="chapter" data-level="86.8.3" data-path="surv-reg.html"><a href="surv-reg.html#當你加入了多個解釋變量時"><i class="fa fa-check"></i><b>86.8.3</b> 當你加入了多個解釋變量時</a></li>
</ul></li>
<li class="chapter" data-level="86.9" data-path="surv-reg.html"><a href="surv-reg.html#practical-survival-03"><i class="fa fa-check"></i><b>86.9</b> Practical Survival 03</a></li>
</ul></li>
<li class="chapter" data-level="87" data-path="cox.html"><a href="cox.html"><i class="fa fa-check"></i><b>87</b> Cox 比例風險模型</a><ul>
<li class="chapter" data-level="87.1" data-path="cox.html"><a href="cox.html#本章概要-3"><i class="fa fa-check"></i><b>87.1</b> 本章概要</a></li>
<li class="chapter" data-level="87.2" data-path="cox.html"><a href="cox.html#初步介紹-cox-比例風險模型"><i class="fa fa-check"></i><b>87.2</b> 初步介紹 Cox 比例風險模型</a></li>
<li class="chapter" data-level="87.3" data-path="cox.html"><a href="cox.html#偏似然法-partial-likelihood"><i class="fa fa-check"></i><b>87.3</b> 偏似然法 (partial likelihood)</a><ul>
<li class="chapter" data-level="87.3.1" data-path="cox.html"><a href="cox.html#爲什麼使用-cox-回歸模型"><i class="fa fa-check"></i><b>87.3.1</b> 爲什麼使用 Cox 回歸模型？</a></li>
</ul></li>
<li class="chapter" data-level="87.4" data-path="cox.html"><a href="cox.html#處理相等的生存時間-handling-tied-survival-times"><i class="fa fa-check"></i><b>87.4</b> 處理相等的生存時間 handling tied survival times</a></li>
<li class="chapter" data-level="87.5" data-path="cox.html"><a href="cox.html#估計生存曲線"><i class="fa fa-check"></i><b>87.5</b> 估計生存曲線</a></li>
<li class="chapter" data-level="87.6" data-path="cox.html"><a href="cox.html#cox回歸模型中包涵的假設"><i class="fa fa-check"></i><b>87.6</b> Cox回歸模型中包涵的假設：</a></li>
<li class="chapter" data-level="87.7" data-path="cox.html"><a href="cox.html#評估比例風險假設-assessing-the-proportional-hazard-assumption"><i class="fa fa-check"></i><b>87.7</b> 評估比例風險假設 assessing the proportional hazard assumption</a></li>
<li class="chapter" data-level="87.8" data-path="cox.html"><a href="cox.html#該用半參數模型還是用全參數模型"><i class="fa fa-check"></i><b>87.8</b> 該用半參數模型還是用全參數模型</a></li>
<li class="chapter" data-level="87.9" data-path="cox.html"><a href="cox.html#practical-survival-04"><i class="fa fa-check"></i><b>87.9</b> Practical Survival 04</a></li>
</ul></li>
<li class="chapter" data-level="88" data-path="surv-check.html"><a href="surv-check.html"><i class="fa fa-check"></i><b>88</b> 分析策略和模型檢查 Model checking-survival analysis</a><ul>
<li class="chapter" data-level="88.1" data-path="surv-check.html"><a href="surv-check.html#本章概要-4"><i class="fa fa-check"></i><b>88.1</b> 本章概要</a></li>
<li class="chapter" data-level="88.2" data-path="surv-check.html"><a href="surv-check.html#生存分析策略"><i class="fa fa-check"></i><b>88.2</b> 生存分析策略</a><ul>
<li class="chapter" data-level="88.2.1" data-path="surv-check.html"><a href="surv-check.html#關於似然比檢驗-a-note-on-likelihood-ratio-tests"><i class="fa fa-check"></i><b>88.2.1</b> 關於似然比檢驗 A note on likelihood ratio tests</a></li>
</ul></li>
<li class="chapter" data-level="88.3" data-path="surv-check.html"><a href="surv-check.html#針對不同的研究設計不同的分析策略"><i class="fa fa-check"></i><b>88.3</b> 針對不同的研究設計不同的分析策略</a><ul>
<li class="chapter" data-level="88.3.1" data-path="surv-check.html"><a href="surv-check.html#針對隨機對照臨牀試驗-rct"><i class="fa fa-check"></i><b>88.3.1</b> 針對隨機對照臨牀試驗 RCT</a></li>
<li class="chapter" data-level="88.3.2" data-path="surv-check.html"><a href="surv-check.html#針對觀察型研究-observational-studies"><i class="fa fa-check"></i><b>88.3.2</b> 針對觀察型研究 observational studies</a></li>
</ul></li>
<li class="chapter" data-level="88.4" data-path="surv-check.html"><a href="surv-check.html#模型檢查的要點"><i class="fa fa-check"></i><b>88.4</b> 模型檢查的要點</a></li>
<li class="chapter" data-level="88.5" data-path="surv-check.html"><a href="surv-check.html#比例風險假設的檢查-check-the-proportional-hazard-assumtion"><i class="fa fa-check"></i><b>88.5</b> 比例風險假設的檢查 check the proportional hazard assumtion</a><ul>
<li class="chapter" data-level="88.5.1" data-path="surv-check.html"><a href="surv-check.html#比例風險檢查的統計檢驗法"><i class="fa fa-check"></i><b>88.5.1</b> 比例風險檢查的統計檢驗法</a></li>
<li class="chapter" data-level="88.5.2" data-path="surv-check.html"><a href="surv-check.html#用-schoenfeld-殘差繪圖"><i class="fa fa-check"></i><b>88.5.2</b> 用 Schoenfeld 殘差繪圖</a></li>
</ul></li>
<li class="chapter" data-level="88.6" data-path="surv-check.html"><a href="surv-check.html#評價模型擬合的其他有趣方法"><i class="fa fa-check"></i><b>88.6</b> 評價模型擬合的其他有趣方法</a><ul>
<li class="chapter" data-level="88.6.1" data-path="surv-check.html"><a href="surv-check.html#martingale-殘差-assessing-the-functional-form-of-continuous-variables"><i class="fa fa-check"></i><b>88.6.1</b> Martingale 殘差-assessing the functional form of continuous variables</a></li>
<li class="chapter" data-level="88.6.2" data-path="surv-check.html"><a href="surv-check.html#deviance-偏差殘差-identifying-individuals-for-whom-the-model-does-not-provide-a-good-fit"><i class="fa fa-check"></i><b>88.6.2</b> Deviance 偏差殘差 – identifying individuals for whom the model does not provide a good fit</a></li>
</ul></li>
<li class="chapter" data-level="88.7" data-path="surv-check.html"><a href="surv-check.html#practical-survival-05"><i class="fa fa-check"></i><b>88.7</b> Practical Survival 05</a><ul>
<li class="chapter" data-level="88.7.1" data-path="surv-check.html"><a href="surv-check.html#把數據讀入你最喜歡的-r-的環境中先考慮一個二進制變量-cir0-對生存的影響在建立的模型中加入該-cir0-變量和時間的交互作用項在-r-裏需要用到-tt-命令"><i class="fa fa-check"></i><b>88.7.1</b> 把數據讀入你最喜歡的 R 的環境中，先考慮一個二進制變量 <code>cir0</code> 對生存的影響。在建立的模型中加入該 <code>cir0</code> 變量和時間的交互作用項。在 R 裏需要用到 <code>tt()</code> 命令。</a></li>
<li class="chapter" data-level="88.7.2" data-path="surv-check.html"><a href="surv-check.html#繪製模型中只有-cir0-一個變量的情況下調整後的-scaled-schoenfeld-殘差圖"><i class="fa fa-check"></i><b>88.7.2</b> 繪製模型中只有 <code>cir0</code> 一個變量的情況下，調整後的 scaled Schoenfeld 殘差圖。</a></li>
<li class="chapter" data-level="88.7.3" data-path="surv-check.html"><a href="surv-check.html#另外一種探索變量-cir0-的風險度比是否隨時間保持不變的方法是可以把生存數據分割成幾個時間段分別估計每個時間段內該暴露變量的風險度比"><i class="fa fa-check"></i><b>88.7.3</b> 另外一種探索變量 <code>cir0</code> 的風險度比是否隨時間保持不變的方法是可以把生存數據分割成幾個時間段，分別估計每個時間段內該暴露變量的風險度比。</a></li>
<li class="chapter" data-level="88.7.4" data-path="surv-check.html"><a href="surv-check.html#接下來我們來看該數據集中的一個連續型變量-bil0-我們練習使用-martingale-殘差輔助我們判斷該連續型變量應該放入模型中的數學函數形式"><i class="fa fa-check"></i><b>88.7.4</b> 接下來我們來看該數據集中的一個連續型變量， <code>bil0</code> 。我們練習使用 Martingale 殘差輔助我們判斷該連續型變量應該放入模型中的數學函數形式。</a></li>
<li class="chapter" data-level="88.7.5" data-path="surv-check.html"><a href="surv-check.html#選擇你認爲應該對-bil0-進行的數學函數形式使用-scaled-schoenfeld-殘差檢查它是否違反比例風險假設"><i class="fa fa-check"></i><b>88.7.5</b> 選擇你認爲應該對 <code>bil0</code> 進行的數學函數形式，使用 Scaled Schoenfeld 殘差檢查它是否違反比例風險假設。</a></li>
<li class="chapter" data-level="88.7.6" data-path="surv-check.html"><a href="surv-check.html#建立一個含有如下解釋變量的-cox-比例風險回歸模型轉換過後的bil0-cir0cenc0-age"><i class="fa fa-check"></i><b>88.7.6</b> 建立一個含有如下解釋變量的 Cox 比例風險回歸模型：轉換過後的<code>bil0</code>, <code>cir0</code>，<code>cenc0</code>, <code>Age</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="89" data-path="competing-risk.html"><a href="competing-risk.html"><i class="fa fa-check"></i><b>89</b> 競爭風險模型 competing risk</a><ul>
<li class="chapter" data-level="89.1" data-path="competing-risk.html"><a href="competing-risk.html#cause-specific-hazard"><i class="fa fa-check"></i><b>89.1</b> Cause-specific hazard</a><ul>
<li class="chapter" data-level="89.1.1" data-path="competing-risk.html"><a href="competing-risk.html#cause-specific-hazards-models"><i class="fa fa-check"></i><b>89.1.1</b> Cause-specific hazards models</a></li>
</ul></li>
<li class="chapter" data-level="89.2" data-path="competing-risk.html"><a href="competing-risk.html#cumulative-incidence-function"><i class="fa fa-check"></i><b>89.2</b> Cumulative incidence function</a></li>
<li class="chapter" data-level="89.3" data-path="competing-risk.html"><a href="competing-risk.html#subdistribution-hazard---fine-and-gray-model"><i class="fa fa-check"></i><b>89.3</b> Subdistribution hazard - Fine and Gray model</a><ul>
<li class="chapter" data-level="89.3.1" data-path="competing-risk.html"><a href="competing-risk.html#subdistribution-hazard-model"><i class="fa fa-check"></i><b>89.3.1</b> Subdistribution hazard model</a></li>
</ul></li>
<li class="chapter" data-level="89.4" data-path="competing-risk.html"><a href="competing-risk.html#multi-state-models"><i class="fa fa-check"></i><b>89.4</b> Multi-state models</a><ul>
<li class="chapter" data-level="89.4.1" data-path="competing-risk.html"><a href="competing-risk.html#the-markov-model"><i class="fa fa-check"></i><b>89.4.1</b> The Markov model</a></li>
<li class="chapter" data-level="89.4.2" data-path="competing-risk.html"><a href="competing-risk.html#cox-proportional-hazards-model-for-transition-intensities"><i class="fa fa-check"></i><b>89.4.2</b> Cox proportional hazards model for transition intensities</a></li>
</ul></li>
<li class="chapter" data-level="89.5" data-path="competing-risk.html"><a href="competing-risk.html#practical-survival-06"><i class="fa fa-check"></i><b>89.5</b> Practical Survival 06</a></li>
</ul></li>
<li class="chapter" data-level="90" data-path="other-surv.html"><a href="other-surv.html"><i class="fa fa-check"></i><b>90</b> 生存分析的其他手段</a><ul>
<li class="chapter" data-level="90.1" data-path="other-surv.html"><a href="other-surv.html#分層cox生存分析-stratified-cox-proportional-hazards-model"><i class="fa fa-check"></i><b>90.1</b> 分層Cox生存分析 stratified Cox proportional hazards model</a></li>
<li class="chapter" data-level="90.2" data-path="other-surv.html"><a href="other-surv.html#加速失效死亡模型-accelerated-failure-time-aft-model"><i class="fa fa-check"></i><b>90.2</b> 加速失效(死亡)模型 Accelerated failure time (AFT) model</a><ul>
<li class="chapter" data-level="90.2.1" data-path="other-surv.html"><a href="other-surv.html#詳細推導"><i class="fa fa-check"></i><b>90.2.1</b> 詳細推導</a></li>
<li class="chapter" data-level="90.2.2" data-path="other-surv.html"><a href="other-surv.html#再詳細推導"><i class="fa fa-check"></i><b>90.2.2</b> 再詳細推導</a></li>
<li class="chapter" data-level="90.2.3" data-path="other-surv.html"><a href="other-surv.html#風險比例模型ph和加速失效死亡模型aft的比較"><i class="fa fa-check"></i><b>90.2.3</b> 風險比例模型(PH)和加速失效（死亡）模型(AFT)的比較</a></li>
<li class="chapter" data-level="90.2.4" data-path="other-surv.html"><a href="other-surv.html#weibull-模型也是一種-aft-模型"><i class="fa fa-check"></i><b>90.2.4</b> Weibull 模型也是一種 AFT 模型</a></li>
</ul></li>
<li class="chapter" data-level="90.3" data-path="other-surv.html"><a href="other-surv.html#practical-survival-07"><i class="fa fa-check"></i><b>90.3</b> Practical Survival 07</a></li>
</ul></li>
<li class="chapter" data-level="91" data-path="time-dep.html"><a href="time-dep.html"><i class="fa fa-check"></i><b>91</b> 時間依存變量 Time-dependent variables 和脆弱模型 frailty model</a><ul>
<li class="chapter" data-level="91.1" data-path="time-dep.html"><a href="time-dep.html#時間依存變量指的是什麼"><i class="fa fa-check"></i><b>91.1</b> 時間依存變量指的是什麼</a></li>
<li class="chapter" data-level="91.2" data-path="time-dep.html"><a href="time-dep.html#extended-cox-model-把cox模型擴展開去"><i class="fa fa-check"></i><b>91.2</b> Extended Cox model 把Cox模型擴展開去</a></li>
<li class="chapter" data-level="91.3" data-path="time-dep.html"><a href="time-dep.html#時間依存變量數據的結構"><i class="fa fa-check"></i><b>91.3</b> 時間依存變量數據的結構</a><ul>
<li class="chapter" data-level="91.3.1" data-path="time-dep.html"><a href="time-dep.html#值得注意的點"><i class="fa fa-check"></i><b>91.3.1</b> 值得注意的點</a></li>
</ul></li>
<li class="chapter" data-level="91.4" data-path="time-dep.html"><a href="time-dep.html#frailty-models-脆弱模型"><i class="fa fa-check"></i><b>91.4</b> Frailty Models (脆弱模型?)</a><ul>
<li class="chapter" data-level="91.4.1" data-path="time-dep.html"><a href="time-dep.html#individual-frailty-model"><i class="fa fa-check"></i><b>91.4.1</b> Individual frailty model</a></li>
<li class="chapter" data-level="91.4.2" data-path="time-dep.html"><a href="time-dep.html#application-to-a-weibull-model"><i class="fa fa-check"></i><b>91.4.2</b> Application to a Weibull model</a></li>
<li class="chapter" data-level="91.4.3" data-path="time-dep.html"><a href="time-dep.html#shared-frailty-model"><i class="fa fa-check"></i><b>91.4.3</b> Shared frailty model</a></li>
</ul></li>
<li class="chapter" data-level="91.5" data-path="time-dep.html"><a href="time-dep.html#practical-survival-08"><i class="fa fa-check"></i><b>91.5</b> Practical Survival 08</a><ul>
<li class="chapter" data-level="91.5.1" data-path="time-dep.html"><a href="time-dep.html#練習題-exercise-8.1"><i class="fa fa-check"></i><b>91.5.1</b> 練習題 exercise 8.1</a></li>
<li class="chapter" data-level="91.5.2" data-path="time-dep.html"><a href="time-dep.html#解答"><i class="fa fa-check"></i><b>91.5.2</b> 解答</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="92" data-path="surv-advance.html"><a href="surv-advance.html"><i class="fa fa-check"></i><b>92</b> 時間事件數據的高級分析法</a></li>
<li class="chapter" data-level="93" data-path="bayes-surv.html"><a href="bayes-surv.html"><i class="fa fa-check"></i><b>93</b> 貝葉斯生存分析 Bayesian Survival Analysis</a></li>
<li class="part"><span><b>XI 貝葉斯統計學 Bayesian Statistics</b></span></li>
<li class="chapter" data-level="94" data-path="why-bayes.html"><a href="why-bayes.html"><i class="fa fa-check"></i><b>94</b> 爲什麼我們要用貝葉斯統計學方法？</a><ul>
<li class="chapter" data-level="94.1" data-path="why-bayes.html"><a href="why-bayes.html#氨甲喋呤-methotrexate-在系統性硬皮病-systematic-sclerosis-ssc-中的療效"><i class="fa fa-check"></i><b>94.1</b> 氨甲喋呤 (methotrexate) 在系統性硬皮病 (systematic sclerosis, SSc) 中的療效</a><ul>
<li class="chapter" data-level="94.1.1" data-path="why-bayes.html"><a href="why-bayes.html#背景資料-ssc-trial"><i class="fa fa-check"></i><b>94.1.1</b> 背景資料-SSc trial</a></li>
<li class="chapter" data-level="94.1.2" data-path="why-bayes.html"><a href="why-bayes.html#概率論者分析結果"><i class="fa fa-check"></i><b>94.1.2</b> 概率論者分析結果</a></li>
<li class="chapter" data-level="94.1.3" data-path="why-bayes.html"><a href="why-bayes.html#貝葉斯統計分析結果"><i class="fa fa-check"></i><b>94.1.3</b> 貝葉斯統計分析結果</a></li>
</ul></li>
<li class="chapter" data-level="94.2" data-path="why-bayes.html"><a href="why-bayes.html#example-the-great-trial"><i class="fa fa-check"></i><b>94.2</b> Example: The GREAT trial</a><ul>
<li class="chapter" data-level="94.2.1" data-path="why-bayes.html"><a href="why-bayes.html#background-great-trial"><i class="fa fa-check"></i><b>94.2.1</b> Background (GREAT trial)</a></li>
<li class="chapter" data-level="94.2.2" data-path="why-bayes.html"><a href="why-bayes.html#試驗結果"><i class="fa fa-check"></i><b>94.2.2</b> 試驗結果</a></li>
<li class="chapter" data-level="94.2.3" data-path="why-bayes.html"><a href="why-bayes.html#經典統計學分析方法"><i class="fa fa-check"></i><b>94.2.3</b> 經典統計學分析方法</a></li>
<li class="chapter" data-level="94.2.4" data-path="why-bayes.html"><a href="why-bayes.html#貝葉斯統計學分析方法"><i class="fa fa-check"></i><b>94.2.4</b> 貝葉斯統計學分析方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="95" data-path="MC-estimation.html"><a href="MC-estimation.html"><i class="fa fa-check"></i><b>95</b> 蒙特卡羅估計和預測 Mente Carlo estimation and prediction</a><ul>
<li class="chapter" data-level="95.1" data-path="MC-estimation.html"><a href="MC-estimation.html#起源"><i class="fa fa-check"></i><b>95.1</b> 起源</a></li>
<li class="chapter" data-level="95.2" data-path="MC-estimation.html"><a href="MC-estimation.html#百分比的統計學推斷-inference-on-proportions"><i class="fa fa-check"></i><b>95.2</b> 百分比的統計學推斷 inference on proportions</a><ul>
<li class="chapter" data-level="95.2.1" data-path="MC-estimation.html"><a href="MC-estimation.html#example-new-drug"><i class="fa fa-check"></i><b>95.2.1</b> Example: New Drug</a></li>
<li class="chapter" data-level="95.2.2" data-path="MC-estimation.html"><a href="MC-estimation.html#beta-distr"><i class="fa fa-check"></i><b>95.2.2</b> Beta 分布</a></li>
<li class="chapter" data-level="95.2.3" data-path="MC-estimation.html"><a href="MC-estimation.html#作出預測"><i class="fa fa-check"></i><b>95.2.3</b> 作出預測</a></li>
<li class="chapter" data-level="95.2.4" data-path="MC-estimation.html"><a href="MC-estimation.html#example-新藥表現預測"><i class="fa fa-check"></i><b>95.2.4</b> Example: 新藥表現預測</a></li>
</ul></li>
<li class="chapter" data-level="95.3" data-path="MC-estimation.html"><a href="MC-estimation.html#蒙特卡羅估計"><i class="fa fa-check"></i><b>95.3</b> 蒙特卡羅估計</a><ul>
<li class="chapter" data-level="95.3.1" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法估計概率分佈尾側累積概率面積"><i class="fa fa-check"></i><b>95.3.1</b> 用蒙特卡羅法估計概率分佈尾側累積概率(面積)</a></li>
<li class="chapter" data-level="95.3.2" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法計算預測概率分佈"><i class="fa fa-check"></i><b>95.3.2</b> 用蒙特卡羅法計算預測概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="95.4" data-path="MC-estimation.html"><a href="MC-estimation.html#蒙特卡羅法分析軟件-openbugs-jags"><i class="fa fa-check"></i><b>95.4</b> 蒙特卡羅法分析軟件 OpenBUGS / JAGS</a><ul>
<li class="chapter" data-level="95.4.1" data-path="MC-estimation.html"><a href="MC-estimation.html#用-jagsbugs-分析投擲硬幣數據"><i class="fa fa-check"></i><b>95.4.1</b> 用 JAGS/BUGS 分析投擲硬幣數據</a></li>
<li class="chapter" data-level="95.4.2" data-path="MC-estimation.html"><a href="MC-estimation.html#用-jags-對藥物臨牀試驗的結果做預測"><i class="fa fa-check"></i><b>95.4.2</b> 用 JAGS 對藥物臨牀試驗的結果做預測</a></li>
<li class="chapter" data-level="95.4.3" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法計算一個臨牀試驗的統計效能-allow-uncertainty-in-power-calculation"><i class="fa fa-check"></i><b>95.4.3</b> 用蒙特卡羅法計算一個臨牀試驗的統計效能 allow uncertainty in power calculation</a></li>
</ul></li>
<li class="chapter" data-level="95.5" data-path="MC-estimation.html"><a href="MC-estimation.html#practical-bayesian-statistics-02"><i class="fa fa-check"></i><b>95.5</b> Practical Bayesian Statistics 02</a></li>
</ul></li>
<li class="chapter" data-level="96" data-path="conjugate-priors.html"><a href="conjugate-priors.html"><i class="fa fa-check"></i><b>96</b> 共軛先驗概率 Conjugate priors</a><ul>
<li class="chapter" data-level="96.1" data-path="conjugate-priors.html"><a href="conjugate-priors.html#貝葉斯推斷的基礎"><i class="fa fa-check"></i><b>96.1</b> 貝葉斯推斷的基礎</a></li>
<li class="chapter" data-level="96.2" data-path="conjugate-priors.html"><a href="conjugate-priors.html#二項分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>96.2</b> 二項分布(似然)數據的共軛先驗概率</a><ul>
<li class="chapter" data-level="96.2.1" data-path="conjugate-priors.html"><a href="conjugate-priors.html#事後概率分布預測"><i class="fa fa-check"></i><b>96.2.1</b> 事後概率分布預測</a></li>
</ul></li>
<li class="chapter" data-level="96.3" data-path="conjugate-priors.html"><a href="conjugate-priors.html#正態分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>96.3</b> 正態分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="96.4" data-path="conjugate-priors.html"><a href="conjugate-priors.html#泊淞分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>96.4</b> 泊淞分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="96.5" data-path="conjugate-priors.html"><a href="conjugate-priors.html#共軛先驗概率分布的總結"><i class="fa fa-check"></i><b>96.5</b> 共軛先驗概率分布的總結</a></li>
<li class="chapter" data-level="96.6" data-path="conjugate-priors.html"><a href="conjugate-priors.html#BayesPrac03"><i class="fa fa-check"></i><b>96.6</b> Practical Bayesian Statistics 03</a></li>
</ul></li>
<li class="chapter" data-level="97" data-path="MCMC-methods.html"><a href="MCMC-methods.html"><i class="fa fa-check"></i><b>97</b> 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言</a><ul>
<li class="chapter" data-level="97.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#markov-chain-monte-carlo-馬爾可夫鏈蒙特卡羅算法"><i class="fa fa-check"></i><b>97.1</b> Markov Chain Monte Carlo 馬爾可夫鏈蒙特卡羅算法</a><ul>
<li class="chapter" data-level="97.1.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#爲什麼我們需要用計算機模擬算法simulation-methods來進行貝葉斯統計推斷"><i class="fa fa-check"></i><b>97.1.1</b> 爲什麼我們需要用計算機模擬算法(simulation methods)來進行貝葉斯統計推斷？</a></li>
<li class="chapter" data-level="97.1.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#Gibbs-sampling"><i class="fa fa-check"></i><b>97.1.2</b> 吉布斯採樣</a></li>
<li class="chapter" data-level="97.1.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#初始值-initial-values"><i class="fa fa-check"></i><b>97.1.3</b> 初始值 initial values</a></li>
</ul></li>
<li class="chapter" data-level="97.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#使用-mcmc-時需要考慮的一些問題"><i class="fa fa-check"></i><b>97.2</b> 使用 MCMC 時需要考慮的一些問題</a><ul>
<li class="chapter" data-level="97.2.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#收斂時間"><i class="fa fa-check"></i><b>97.2.1</b> 收斂時間</a></li>
<li class="chapter" data-level="97.2.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#模型效率-efficiency-of-mcmc"><i class="fa fa-check"></i><b>97.2.2</b> 模型效率 efficiency of MCMC</a></li>
</ul></li>
<li class="chapter" data-level="97.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#bugs-軟件"><i class="fa fa-check"></i><b>97.3</b> BUGS 軟件</a></li>
<li class="chapter" data-level="97.4" data-path="MCMC-methods.html"><a href="MCMC-methods.html#圖形模型-statistical-graphical-models---directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>97.4</b> 圖形模型 statistical graphical models - Directed Acyclic Graphs (DAGs)</a><ul>
<li class="chapter" data-level="97.4.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#條件獨立的概念-conditional-independence-concept"><i class="fa fa-check"></i><b>97.4.1</b> 條件獨立的概念 conditional independence concept</a></li>
</ul></li>
<li class="chapter" data-level="97.5" data-path="MCMC-methods.html"><a href="MCMC-methods.html#bugs-language"><i class="fa fa-check"></i><b>97.5</b> BUGS language</a><ul>
<li class="chapter" data-level="97.5.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#節點的種類-types-of-nodes"><i class="fa fa-check"></i><b>97.5.1</b> 節點的種類 types of nodes</a></li>
<li class="chapter" data-level="97.5.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#分布的標記法"><i class="fa fa-check"></i><b>97.5.2</b> 分布的標記法</a></li>
<li class="chapter" data-level="97.5.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#arrays-and-loops"><i class="fa fa-check"></i><b>97.5.3</b> Arrays and loops</a></li>
<li class="chapter" data-level="97.5.4" data-path="MCMC-methods.html"><a href="MCMC-methods.html#常用的方程"><i class="fa fa-check"></i><b>97.5.4</b> 常用的方程</a></li>
</ul></li>
<li class="chapter" data-level="97.6" data-path="MCMC-methods.html"><a href="MCMC-methods.html#爲bugs-model模型準備格式正確的數據"><i class="fa fa-check"></i><b>97.6</b> 爲BUGS model模型準備格式正確的數據</a></li>
<li class="chapter" data-level="97.7" data-path="MCMC-methods.html"><a href="MCMC-methods.html#practical-bayesian-statistics-04"><i class="fa fa-check"></i><b>97.7</b> Practical Bayesian Statistics 04</a></li>
</ul></li>
<li class="chapter" data-level="98" data-path="Bayes-check.html"><a href="Bayes-check.html"><i class="fa fa-check"></i><b>98</b> 建模和模型的檢查</a><ul>
<li class="chapter" data-level="98.1" data-path="Bayes-check.html"><a href="Bayes-check.html#BayesianLM"><i class="fa fa-check"></i><b>98.1</b> 簡單線性回歸模型</a></li>
<li class="chapter" data-level="98.2" data-path="Bayes-check.html"><a href="Bayes-check.html#children-in-the-gambia"><i class="fa fa-check"></i><b>98.2</b> Children in the Gambia</a><ul>
<li class="chapter" data-level="98.2.1" data-path="Bayes-check.html"><a href="Bayes-check.html#岡比亞兒童數據模型"><i class="fa fa-check"></i><b>98.2.1</b> 岡比亞兒童數據模型</a></li>
<li class="chapter" data-level="98.2.2" data-path="Bayes-check.html"><a href="Bayes-check.html#bugs-model-for-gambia-example"><i class="fa fa-check"></i><b>98.2.2</b> BUGS model for Gambia example</a></li>
<li class="chapter" data-level="98.2.3" data-path="Bayes-check.html"><a href="Bayes-check.html#data-file-for-the-gambia-example"><i class="fa fa-check"></i><b>98.2.3</b> Data file for the Gambia example</a></li>
<li class="chapter" data-level="98.2.4" data-path="Bayes-check.html"><a href="Bayes-check.html#初始值文件-initial-value-files"><i class="fa fa-check"></i><b>98.2.4</b> 初始值文件 initial value files</a></li>
<li class="chapter" data-level="98.2.5" data-path="Bayes-check.html"><a href="Bayes-check.html#給岡比亞兒童體重數據的貝葉斯模型檢查收斂-mcmc-check-1"><i class="fa fa-check"></i><b>98.2.5</b> 給岡比亞兒童體重數據的貝葉斯模型檢查收斂 (MCMC check 1)</a></li>
<li class="chapter" data-level="98.2.6" data-path="Bayes-check.html"><a href="Bayes-check.html#岡比亞兒童體重數據的貝葉斯統計學推斷結果"><i class="fa fa-check"></i><b>98.2.6</b> 岡比亞兒童體重數據的貝葉斯統計學推斷結果</a></li>
<li class="chapter" data-level="98.2.7" data-path="Bayes-check.html"><a href="Bayes-check.html#檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量-effective-sample-size-mcmc-check-2"><i class="fa fa-check"></i><b>98.2.7</b> 檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量 effective sample size (MCMC check 2)</a></li>
<li class="chapter" data-level="98.2.8" data-path="Bayes-check.html"><a href="Bayes-check.html#檢查模型擬合程度-checking-model-fit-for-the-gambia-example"><i class="fa fa-check"></i><b>98.2.8</b> 檢查模型擬合程度 checking model fit for the Gambia example</a></li>
<li class="chapter" data-level="98.2.9" data-path="Bayes-check.html"><a href="Bayes-check.html#tdreplacegaussian"><i class="fa fa-check"></i><b>98.2.9</b> 其他的替代模型 alternative model with t-errors</a></li>
</ul></li>
<li class="chapter" data-level="98.3" data-path="Bayes-check.html"><a href="Bayes-check.html#貝葉斯統計模型的比較-bayesian-model-comparison"><i class="fa fa-check"></i><b>98.3</b> 貝葉斯統計模型的比較 Bayesian model comparison</a><ul>
<li class="chapter" data-level="98.3.1" data-path="Bayes-check.html"><a href="Bayes-check.html#deviance-information-criterion-dic"><i class="fa fa-check"></i><b>98.3.1</b> Deviance Information Criterion (DIC)</a></li>
<li class="chapter" data-level="98.3.2" data-path="Bayes-check.html"><a href="Bayes-check.html#岡比亞兒童體重數據模型比較"><i class="fa fa-check"></i><b>98.3.2</b> 岡比亞兒童體重數據模型比較</a></li>
</ul></li>
<li class="chapter" data-level="98.4" data-path="Bayes-check.html"><a href="Bayes-check.html#practical-bayesian-statistics-05"><i class="fa fa-check"></i><b>98.4</b> Practical Bayesian Statistics 05</a><ul>
<li class="chapter" data-level="98.4.1" data-path="Bayes-check.html"><a href="Bayes-check.html#增加年齡二次方項-adding-age-squared"><i class="fa fa-check"></i><b>98.4.1</b> 增加年齡二次方項 adding age squared</a></li>
<li class="chapter" data-level="98.4.2" data-path="Bayes-check.html"><a href="Bayes-check.html#增加年齡和性別的交互作用項-adding-an-interaction-term"><i class="fa fa-check"></i><b>98.4.2</b> 增加年齡和性別的交互作用項 adding an interaction term</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="99" data-path="Bayes-design.html"><a href="Bayes-design.html"><i class="fa fa-check"></i><b>99</b> 不同實驗/研究設計時適用的貝葉斯模型</a><ul>
<li class="chapter" data-level="99.1" data-path="Bayes-design.html"><a href="Bayes-design.html#隊列研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>99.1</b> 隊列研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="99.2" data-path="Bayes-design.html"><a href="Bayes-design.html#病例對照研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>99.2</b> 病例對照研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="99.3" data-path="Bayes-design.html"><a href="Bayes-design.html#bayes-crosssectional"><i class="fa fa-check"></i><b>99.3</b> 橫斷面研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="99.4" data-path="Bayes-design.html"><a href="Bayes-design.html#把不同實驗設計的數據用貝葉斯模型連接起來"><i class="fa fa-check"></i><b>99.4</b> 把不同實驗設計的數據用貝葉斯模型連接起來</a><ul>
<li class="chapter" data-level="99.4.1" data-path="Bayes-design.html"><a href="Bayes-design.html#linking-sub-models-throug-common-parameters"><i class="fa fa-check"></i><b>99.4.1</b> Linking sub-models throug common parameters</a></li>
</ul></li>
<li class="chapter" data-level="99.5" data-path="Bayes-design.html"><a href="Bayes-design.html#practical-bayesian-statistics-06"><i class="fa fa-check"></i><b>99.5</b> Practical Bayesian Statistics 06</a><ul>
<li class="chapter" data-level="99.5.1" data-path="Bayes-design.html"><a href="Bayes-design.html#the-great-trial"><i class="fa fa-check"></i><b>99.5.1</b> The GREAT Trial</a></li>
<li class="chapter" data-level="99.5.2" data-path="Bayes-design.html"><a href="Bayes-design.html#吸煙與癌症"><i class="fa fa-check"></i><b>99.5.2</b> 吸煙與癌症</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="100" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html"><i class="fa fa-check"></i><b>100</b> 貝葉斯廣義線性回歸</a><ul>
<li class="chapter" data-level="100.1" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#如何在bugs語言中描述分類型變量"><i class="fa fa-check"></i><b>100.1</b> 如何在BUGS語言中描述分類型變量</a><ul>
<li class="chapter" data-level="100.1.1" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#啞變量的數據矩陣"><i class="fa fa-check"></i><b>100.1.1</b> 啞變量的數據矩陣</a></li>
<li class="chapter" data-level="100.1.2" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#雙重索引bugs語言標記法"><i class="fa fa-check"></i><b>100.1.2</b> 雙重索引BUGS語言標記法</a></li>
</ul></li>
<li class="chapter" data-level="100.2" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#邏輯回歸-bayesian-logistic-regression"><i class="fa fa-check"></i><b>100.2</b> 邏輯回歸 Bayesian Logistic Regression</a><ul>
<li class="chapter" data-level="100.2.1" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#低出生體重數據-1"><i class="fa fa-check"></i><b>100.2.1</b> 低出生體重數據</a></li>
</ul></li>
<li class="chapter" data-level="100.3" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#貝葉斯泊鬆回歸-bayesian-poisson-regression"><i class="fa fa-check"></i><b>100.3</b> 貝葉斯泊鬆回歸 Bayesian Poisson Regression</a></li>
<li class="chapter" data-level="100.4" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#glm-in-a-bayesian-way"><i class="fa fa-check"></i><b>100.4</b> GLM in a Bayesian way</a></li>
<li class="chapter" data-level="100.5" data-path="Bayes-GLM.html"><a href="Bayes-GLM.html#Bayesian-practical07"><i class="fa fa-check"></i><b>100.5</b> Practical Bayesian Statistics 07</a></li>
</ul></li>
<li class="chapter" data-level="101" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html"><i class="fa fa-check"></i><b>101</b> 貝葉斯等級回歸模型</a><ul>
<li class="chapter" data-level="101.1" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#關於等級迴歸模型"><i class="fa fa-check"></i><b>101.1</b> 關於等級迴歸模型</a></li>
<li class="chapter" data-level="101.2" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#多層數據在模型中可能要用到的前提條件"><i class="fa fa-check"></i><b>101.2</b> 多層數據在模型中可能要用到的前提條件</a><ul>
<li class="chapter" data-level="101.2.1" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#參數是相同的-identical-parameters"><i class="fa fa-check"></i><b>101.2.1</b> 參數是相同的 (identical parameters)</a></li>
<li class="chapter" data-level="101.2.2" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#參數是獨立的-independent-parameters"><i class="fa fa-check"></i><b>101.2.2</b> 參數是獨立的 (independent parameters)</a></li>
<li class="chapter" data-level="101.2.3" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#參數是可交換的-exchangeable-parameters"><i class="fa fa-check"></i><b>101.2.3</b> 參數是可交換的 (exchangeable parameters)</a></li>
</ul></li>
<li class="chapter" data-level="101.3" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#抗抑鬱臨牀試驗實例"><i class="fa fa-check"></i><b>101.3</b> 抗抑鬱臨牀試驗實例</a><ul>
<li class="chapter" data-level="101.3.1" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#縱向數據"><i class="fa fa-check"></i><b>101.3.1</b> 縱向數據</a></li>
<li class="chapter" data-level="101.3.2" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#hamd-example"><i class="fa fa-check"></i><b>101.3.2</b> HAMD example</a></li>
<li class="chapter" data-level="101.3.3" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#貝葉斯簡單線性迴歸模型"><i class="fa fa-check"></i><b>101.3.3</b> 貝葉斯簡單線性迴歸模型</a></li>
<li class="chapter" data-level="101.3.4" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#貝葉斯等級線性回歸隨機截距模型"><i class="fa fa-check"></i><b>101.3.4</b> 貝葉斯等級線性回歸–隨機截距模型</a></li>
<li class="chapter" data-level="101.3.5" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#貝葉斯等級線性回歸模型隨機截距和隨機斜率模型"><i class="fa fa-check"></i><b>101.3.5</b> 貝葉斯等級線性回歸模型–隨機截距和隨機斜率模型</a></li>
<li class="chapter" data-level="101.3.6" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#hamd-數據不同模型結果的比較"><i class="fa fa-check"></i><b>101.3.6</b> HAMD 數據不同模型結果的比較</a></li>
<li class="chapter" data-level="101.3.7" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#hamd-數據實例結果的解釋"><i class="fa fa-check"></i><b>101.3.7</b> HAMD 數據實例結果的解釋</a></li>
</ul></li>
<li class="chapter" data-level="101.4" data-path="Bayes-Hier.html"><a href="Bayes-Hier.html#practical-bayesian-statistics-08"><i class="fa fa-check"></i><b>101.4</b> Practical Bayesian Statistics 08</a></li>
</ul></li>
<li class="chapter" data-level="102" data-path="MCMC-revisit.html"><a href="MCMC-revisit.html"><i class="fa fa-check"></i><b>102</b> 再訪 MCMC</a><ul>
<li class="chapter" data-level="102.1" data-path="MCMC-revisit.html"><a href="MCMC-revisit.html#metropolis-hastings-algorithm"><i class="fa fa-check"></i><b>102.1</b> Metropolis-Hastings algorithm</a></li>
<li class="chapter" data-level="102.2" data-path="MCMC-revisit.html"><a href="MCMC-revisit.html#適應階段-adaptive-phase"><i class="fa fa-check"></i><b>102.2</b> 適應階段 adaptive phase</a></li>
</ul></li>
<li class="chapter" data-level="103" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html"><i class="fa fa-check"></i><b>103</b> 貝葉斯和概率論的比較</a><ul>
<li class="chapter" data-level="103.1" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html#兩種方法的不同點總覽"><i class="fa fa-check"></i><b>103.1</b> 兩種方法的不同點總覽</a></li>
<li class="chapter" data-level="103.2" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html#亞組分析-subgroup-analysis"><i class="fa fa-check"></i><b>103.2</b> 亞組分析 subgroup analysis</a></li>
<li class="chapter" data-level="103.3" data-path="compare-Bayes-freq.html"><a href="compare-Bayes-freq.html#多重比較問題-multiple-comparisons"><i class="fa fa-check"></i><b>103.3</b> 多重比較問題 multiple comparisons</a></li>
</ul></li>
<li class="part"><span><b>XII 非參數貝葉斯統計 Bayesian Nonparametric Data Analysis</b></span></li>
<li class="chapter" data-level="104" data-path="nonparaBayes-intro.html"><a href="nonparaBayes-intro.html"><i class="fa fa-check"></i><b>104</b> 非參貝葉斯入門</a></li>
<li class="chapter" data-level="105" data-path="-density-estimation-dp-models.html"><a href="-density-estimation-dp-models.html"><i class="fa fa-check"></i><b>105</b> 密度估計 Density estimation - 狄雷克雷過程模型 DP models</a><ul>
<li class="chapter" data-level="105.1" data-path="-density-estimation-dp-models.html"><a href="-density-estimation-dp-models.html#狄雷克雷過程-dirichlet-process"><i class="fa fa-check"></i><b>105.1</b> 狄雷克雷過程 Dirichlet process</a><ul>
<li class="chapter" data-level="105.1.1" data-path="-density-estimation-dp-models.html"><a href="-density-estimation-dp-models.html#定義-definition"><i class="fa fa-check"></i><b>105.1.1</b> 定義 definition</a></li>
<li class="chapter" data-level="105.1.2" data-path="-density-estimation-dp-models.html"><a href="-density-estimation-dp-models.html#推導"><i class="fa fa-check"></i><b>105.1.2</b> 推導</a></li>
<li class="chapter" data-level="105.1.3" data-path="-density-estimation-dp-models.html"><a href="-density-estimation-dp-models.html#事後概率分佈和邊際分佈"><i class="fa fa-check"></i><b>105.1.3</b> 事後概率分佈和邊際分佈</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>XIII 因果推斷 Causal Inference</b></span></li>
<li class="chapter" data-level="106" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html"><i class="fa fa-check"></i><b>106</b> Causal Languages 因果推斷的語法</a><ul>
<li class="chapter" data-level="106.1" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#當我們在談論因果推斷的時候我們在談論什麼"><i class="fa fa-check"></i><b>106.1</b> 當我們在談論因果推斷的時候，我們在談論什麼？</a></li>
<li class="chapter" data-level="106.2" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#傳統的統計學方法"><i class="fa fa-check"></i><b>106.2</b> 傳統的統計學方法</a><ul>
<li class="chapter" data-level="106.2.1" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#初步分析"><i class="fa fa-check"></i><b>106.2.1</b> 初步分析</a></li>
<li class="chapter" data-level="106.2.2" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#混雜"><i class="fa fa-check"></i><b>106.2.2</b> 混雜</a></li>
<li class="chapter" data-level="106.2.3" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#以共變量爲條件-conditioning-on-covariates"><i class="fa fa-check"></i><b>106.2.3</b> 以共變量爲條件 conditioning on covariates</a></li>
</ul></li>
<li class="chapter" data-level="106.3" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#更加正規的方法"><i class="fa fa-check"></i><b>106.3</b> 更加正規的方法</a><ul>
<li class="chapter" data-level="106.3.1" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#因果推斷使用的語言"><i class="fa fa-check"></i><b>106.3.1</b> 因果推斷使用的語言</a></li>
<li class="chapter" data-level="106.3.2" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#因果推斷的被估計量-causal-estimands"><i class="fa fa-check"></i><b>106.3.2</b> 因果推斷的被估計量 causal estimands</a></li>
<li class="chapter" data-level="106.3.3" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#鑑定因果推斷時的前提假設-assumptions-for-identification"><i class="fa fa-check"></i><b>106.3.3</b> 鑑定因果推斷時的前提假設 assumptions for identification</a></li>
<li class="chapter" data-level="106.3.4" data-path="grama-causal-infer.html"><a href="grama-causal-infer.html#鑑定-identification"><i class="fa fa-check"></i><b>106.3.4</b> 鑑定 identification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="107" data-path="graphical-models.html"><a href="graphical-models.html"><i class="fa fa-check"></i><b>107</b> Graphical Models 因果推斷的圖形模型</a><ul>
<li class="chapter" data-level="107.1" data-path="graphical-models.html"><a href="graphical-models.html#統計學中的有向無環圖"><i class="fa fa-check"></i><b>107.1</b> 統計學中的有向無環圖</a><ul>
<li class="chapter" data-level="107.1.1" data-path="graphical-models.html"><a href="graphical-models.html#dag-和條件獨立性-conditional-independence"><i class="fa fa-check"></i><b>107.1.1</b> DAG 和條件獨立性 conditional independence</a></li>
<li class="chapter" data-level="107.1.2" data-path="graphical-models.html"><a href="graphical-models.html#dag-圖的術語"><i class="fa fa-check"></i><b>107.1.2</b> DAG 圖的術語</a></li>
<li class="chapter" data-level="107.1.3" data-path="graphical-models.html"><a href="graphical-models.html#阻斷通路-blocking-paths"><i class="fa fa-check"></i><b>107.1.3</b> 阻斷通路 blocking paths</a></li>
<li class="chapter" data-level="107.1.4" data-path="graphical-models.html"><a href="graphical-models.html#以對撞因子爲條件-conditioning-on-a-collider"><i class="fa fa-check"></i><b>107.1.4</b> 以對撞因子爲條件 conditioning on a collider</a></li>
</ul></li>
<li class="chapter" data-level="107.2" data-path="graphical-models.html"><a href="graphical-models.html#以非對撞爲條件-conditioning-on-a-non-collider"><i class="fa fa-check"></i><b>107.2</b> 以非對撞爲條件 conditioning on a non-collider</a><ul>
<li class="chapter" data-level="107.2.1" data-path="graphical-models.html"><a href="graphical-models.html#條件的總結"><i class="fa fa-check"></i><b>107.2.1</b> 條件的總結</a></li>
<li class="chapter" data-level="107.2.2" data-path="graphical-models.html"><a href="graphical-models.html#d-分離-d-separation"><i class="fa fa-check"></i><b>107.2.2</b> D 分離 d-separation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="108" data-path="reg-cont.html"><a href="reg-cont.html"><i class="fa fa-check"></i><b>108</b> Regression Methods with continuous outcomes 結果變量爲連續型變量</a><ul>
<li class="chapter" data-level="108.1" data-path="reg-cont.html"><a href="reg-cont.html#用於對連續型結果變量做因果推斷的被估計量"><i class="fa fa-check"></i><b>108.1</b> 用於對連續型結果變量做因果推斷的被估計量</a></li>
<li class="chapter" data-level="108.2" data-path="reg-cont.html"><a href="reg-cont.html#鑑定-identification---revision"><i class="fa fa-check"></i><b>108.2</b> 鑑定 identification - revision</a><ul>
<li class="chapter" data-level="108.2.1" data-path="reg-cont.html"><a href="reg-cont.html#條件因果均差-conditional-causal-mean-difference"><i class="fa fa-check"></i><b>108.2.1</b> 條件因果均差 conditional causal mean difference</a></li>
<li class="chapter" data-level="108.2.2" data-path="reg-cont.html"><a href="reg-cont.html#簡單分類型條件變量-c-的-ace"><i class="fa fa-check"></i><b>108.2.2</b> 簡單分類型條件變量 <span class="math inline">\(C\)</span> 的 ACE</a></li>
<li class="chapter" data-level="108.2.3" data-path="reg-cont.html"><a href="reg-cont.html#簡單連續型條件變量-c-的ace"><i class="fa fa-check"></i><b>108.2.3</b> 簡單連續型條件變量 <span class="math inline">\(C\)</span> 的ACE</a></li>
</ul></li>
<li class="chapter" data-level="108.3" data-path="reg-cont.html"><a href="reg-cont.html#通過線性回歸模型來估計-ace"><i class="fa fa-check"></i><b>108.3</b> 通過線性回歸模型來估計 ACE</a><ul>
<li class="chapter" data-level="108.3.1" data-path="reg-cont.html"><a href="reg-cont.html#條件因果均值差"><i class="fa fa-check"></i><b>108.3.1</b> 條件因果均值差</a></li>
<li class="chapter" data-level="108.3.2" data-path="reg-cont.html"><a href="reg-cont.html#效應修正-effect-modification-和-交互作用-interaction"><i class="fa fa-check"></i><b>108.3.2</b> 效應修正 effect modification 和 交互作用 interaction</a></li>
<li class="chapter" data-level="108.3.3" data-path="reg-cont.html"><a href="reg-cont.html#分類型條件變量的平均因果效應-ace"><i class="fa fa-check"></i><b>108.3.3</b> 分類型條件變量的平均因果效應 (ACE)</a></li>
<li class="chapter" data-level="108.3.4" data-path="reg-cont.html"><a href="reg-cont.html#positivity-非零性"><i class="fa fa-check"></i><b>108.3.4</b> Positivity 非零性</a></li>
<li class="chapter" data-level="108.3.5" data-path="reg-cont.html"><a href="reg-cont.html#連續型變量的平均因果效應"><i class="fa fa-check"></i><b>108.3.5</b> 連續型變量的平均因果效應</a></li>
</ul></li>
<li class="chapter" data-level="108.4" data-path="reg-cont.html"><a href="reg-cont.html#practical03---causal-inference"><i class="fa fa-check"></i><b>108.4</b> Practical03 - causal inference</a></li>
</ul></li>
<li class="chapter" data-level="109" data-path="regre-binary.html"><a href="regre-binary.html"><i class="fa fa-check"></i><b>109</b> Regression Methods with binary outcomes 結果變量爲二進制變量</a><ul>
<li class="chapter" data-level="109.1" data-path="regre-binary.html"><a href="regre-binary.html#二進制結果變量的因果被估計量-causal-estimand"><i class="fa fa-check"></i><b>109.1</b> 二進制結果變量的因果被估計量 (causal estimand):</a><ul>
<li class="chapter" data-level="109.1.1" data-path="regre-binary.html"><a href="regre-binary.html#比值比的不可壓縮性-non-collapsibility-of-the-odds-ratio"><i class="fa fa-check"></i><b>109.1.1</b> 比值比的不可壓縮性 non-collapsibility of the odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="109.2" data-path="regre-binary.html"><a href="regre-binary.html#鑑定-identification---conditional-effects"><i class="fa fa-check"></i><b>109.2</b> 鑑定 identification - conditional effects</a></li>
<li class="chapter" data-level="109.3" data-path="regre-binary.html"><a href="regre-binary.html#鑑定-identification---marginal-effects"><i class="fa fa-check"></i><b>109.3</b> 鑑定 identification - marginal effects</a><ul>
<li class="chapter" data-level="109.3.1" data-path="regre-binary.html"><a href="regre-binary.html#marginal-causal-risk-difference-ace"><i class="fa fa-check"></i><b>109.3.1</b> Marginal causal risk difference (ACE)</a></li>
<li class="chapter" data-level="109.3.2" data-path="regre-binary.html"><a href="regre-binary.html#marginal-causal-log-risk-ratio"><i class="fa fa-check"></i><b>109.3.2</b> Marginal causal log risk ratio</a></li>
</ul></li>
<li class="chapter" data-level="109.4" data-path="regre-binary.html"><a href="regre-binary.html#通過邏輯回歸估計這些被估計量"><i class="fa fa-check"></i><b>109.4</b> 通過邏輯回歸估計這些被估計量</a></li>
<li class="chapter" data-level="109.5" data-path="regre-binary.html"><a href="regre-binary.html#average-causaltreatment-effect-in-the-exposedtreated-atet"><i class="fa fa-check"></i><b>109.5</b> Average causal/treatment effect in the exposed/treated (ATET)</a></li>
<li class="chapter" data-level="109.6" data-path="regre-binary.html"><a href="regre-binary.html#practical04---causal-inference"><i class="fa fa-check"></i><b>109.6</b> Practical04 - causal inference</a><ul>
<li class="chapter" data-level="109.6.1" data-path="regre-binary.html"><a href="regre-binary.html#在stata裡打開數據初步分析和熟悉數據"><i class="fa fa-check"></i><b>109.6.1</b> 在STATA裡打開數據，初步分析和熟悉數據</a></li>
<li class="chapter" data-level="109.6.2" data-path="regre-binary.html"><a href="regre-binary.html#用標準邏輯回歸模型分析-rfa-暴露-和-dodp-結果-之間的關係"><i class="fa fa-check"></i><b>109.6.2</b> 用標準邏輯回歸模型分析 <code>rfa</code> (暴露) 和 <code>dodp</code> (結果) 之間的關係</a></li>
<li class="chapter" data-level="109.6.3" data-path="regre-binary.html"><a href="regre-binary.html#比較上面a和b兩個邏輯回歸模型的結果你認為混雜因素對暴露和結果的關係的影響是怎樣的"><i class="fa fa-check"></i><b>109.6.3</b> 比較上面(a)和(b)兩個邏輯回歸模型的結果，你認為混雜因素對暴露和結果的關係的影響是怎樣的？</a></li>
<li class="chapter" data-level="109.6.4" data-path="regre-binary.html"><a href="regre-binary.html#在怎樣的前提假設條件下上面模型-b-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>109.6.4</b> 在怎樣的前提假設條件下，上面模型 (b) 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="109.6.5" data-path="regre-binary.html"><a href="regre-binary.html#在前面提出的所有前提假設都滿足的情況下請給模型-b-的回歸係數賦予一個因果效應的解釋"><i class="fa fa-check"></i><b>109.6.5</b> 在前面提出的所有前提假設都滿足的情況下，請給模型 (b) 的回歸係數賦予一個因果效應的解釋。</a></li>
<li class="chapter" data-level="109.6.6" data-path="regre-binary.html"><a href="regre-binary.html#用-stata-的-teffects-ra-擬合上面兩個模型"><i class="fa fa-check"></i><b>109.6.6</b> 用 STATA 的 <code>teffects ra</code> 擬合上面兩個模型</a></li>
<li class="chapter" data-level="109.6.7" data-path="regre-binary.html"><a href="regre-binary.html#在怎樣的假設前提條件下前一步擬合的模型-b-結果中的-ate-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>109.6.7</b> 在怎樣的假設前提條件下，前一步擬合的模型 (b) 結果中的 ATE 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="109.6.8" data-path="regre-binary.html"><a href="regre-binary.html#前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答有什麼不同"><i class="fa fa-check"></i><b>109.6.8</b> 前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答，有什麼不同？</a></li>
<li class="chapter" data-level="109.6.9" data-path="regre-binary.html"><a href="regre-binary.html#用因果關係語言解釋-teffects-ra-擬合的模型-b-的結果"><i class="fa fa-check"></i><b>109.6.9</b> 用因果關係語言解釋 <code>teffects ra</code> 擬合的模型 (b) 的結果</a></li>
<li class="chapter" data-level="109.6.10" data-path="regre-binary.html"><a href="regre-binary.html#如果模型中加入-age-gender-smoke-nodules-mets-duration-primary-等和預後相關但是和決定療法並不太有關係的變量結果會有什麼不同呢"><i class="fa fa-check"></i><b>109.6.10</b> 如果模型中加入 <code>age, gender, smoke, nodules, mets, duration, primary</code> 等和預後相關但是和決定療法並不太有關係的變量，結果會有什麼不同呢？</a></li>
<li class="chapter" data-level="109.6.11" data-path="regre-binary.html"><a href="regre-binary.html#如果再向模型中加入和暴露變量相關和預後沒什麼關係的變量-coag結果該怎麼解讀"><i class="fa fa-check"></i><b>109.6.11</b> 如果再向模型中加入和暴露變量相關，和預後沒什麼關係的變量 <code>coag</code>，結果該怎麼解讀？</a></li>
<li class="chapter" data-level="109.6.12" data-path="regre-binary.html"><a href="regre-binary.html#使用-atet-的選項重新擬合上面的因果效應模型解釋結果發生的變化並作出相應的結論"><i class="fa fa-check"></i><b>109.6.12</b> 使用 <code>atet</code> 的選項重新擬合上面的因果效應模型，解釋結果發生的變化，並作出相應的結論。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="110" data-path="prop-score.html"><a href="prop-score.html"><i class="fa fa-check"></i><b>110</b> Prospensity Score 傾向性評分</a><ul>
<li class="chapter" data-level="110.1" data-path="prop-score.html"><a href="prop-score.html#practical05---causal-inference"><i class="fa fa-check"></i><b>110.1</b> Practical05 - causal inference</a><ul>
<li class="chapter" data-level="110.1.1" data-path="prop-score.html"><a href="prop-score.html#初步熟悉數據內容"><i class="fa fa-check"></i><b>110.1.1</b> 初步熟悉數據內容</a></li>
<li class="chapter" data-level="110.1.2" data-path="prop-score.html"><a href="prop-score.html#把連續型變量以分類型數據的形式放入模型中"><i class="fa fa-check"></i><b>110.1.2</b> 把連續型變量以分類型數據的形式放入模型中:</a></li>
<li class="chapter" data-level="110.1.3" data-path="prop-score.html"><a href="prop-score.html#用相同的模型結構估計每個人的傾向性評分"><i class="fa fa-check"></i><b>110.1.3</b> 用相同的模型結構估計每個人的傾向性評分</a></li>
<li class="chapter" data-level="110.1.4" data-path="prop-score.html"><a href="prop-score.html#用-ps-評分來把對象分層-stratification"><i class="fa fa-check"></i><b>110.1.4</b> 用 PS 評分來把對象分層 stratification</a></li>
<li class="chapter" data-level="110.1.5" data-path="prop-score.html"><a href="prop-score.html#用配對法計算-ace"><i class="fa fa-check"></i><b>110.1.5</b> 用配對法計算 ACE</a></li>
<li class="chapter" data-level="110.1.6" data-path="prop-score.html"><a href="prop-score.html#模型校正-ps"><i class="fa fa-check"></i><b>110.1.6</b> 模型校正 PS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="111" data-path="inverse-probability-weighted-estimation-and-doubly-robust-methods.html"><a href="inverse-probability-weighted-estimation-and-doubly-robust-methods.html"><i class="fa fa-check"></i><b>111</b> Inverse probability weighted estimation and doubly robust methods</a></li>
<li class="chapter" data-level="112" data-path="causal-mediation-analysis.html"><a href="causal-mediation-analysis.html"><i class="fa fa-check"></i><b>112</b> Causal mediation analysis</a></li>
<li class="part"><span><b>XIV Statistical Methods in Epidemiology</b></span></li>
<li class="chapter" data-level="113" data-path="-crude-and-stratified-rate-ratios.html"><a href="-crude-and-stratified-rate-ratios.html"><i class="fa fa-check"></i><b>113</b> 粗率比和分層率比 Crude and stratified rate ratios</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本書由 bookdown 強力驅動</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="有向無環圖-dag-可怕的因果-causal-terror" class="section level1">
<h1><span class="header-section-number">第 49 章</span> 有向無環圖 DAG &amp; 可怕的因果 Causal Terror</h1>
<blockquote>
<dl>
<dt>The most newsworthy scientific studies are the least trustworthy. Maybe popular topics attract more and worse researchers, like flies drawn to the smell of honey?</dt>
<dd>Richard McElreath
</dd>
</dl>
</blockquote>
<p>Berkson’s paradox, 又被叫做是選擇性扭曲現象（selection-distortion effect）。</p>
<div class="sourceCode" id="cb667"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb667-1"><a href="-dag-causal-terror.html#cb667-1"></a><span class="kw">set.seed</span>(<span class="dv">1914</span>)</span>
<span id="cb667-2"><a href="-dag-causal-terror.html#cb667-2"></a>N &lt;-<span class="st"> </span><span class="dv">200</span> <span class="co"># num grant proposals</span></span>
<span id="cb667-3"><a href="-dag-causal-terror.html#cb667-3"></a>p &lt;-<span class="st"> </span><span class="fl">0.1</span> <span class="co"># proportion to select</span></span>
<span id="cb667-4"><a href="-dag-causal-terror.html#cb667-4"></a></span>
<span id="cb667-5"><a href="-dag-causal-terror.html#cb667-5"></a><span class="co"># uncorrelated newsworthiness and trustworthiness</span></span>
<span id="cb667-6"><a href="-dag-causal-terror.html#cb667-6"></a>nw &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N)</span>
<span id="cb667-7"><a href="-dag-causal-terror.html#cb667-7"></a>tw &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N)</span>
<span id="cb667-8"><a href="-dag-causal-terror.html#cb667-8"></a></span>
<span id="cb667-9"><a href="-dag-causal-terror.html#cb667-9"></a><span class="co"># select top 10 of combined scores</span></span>
<span id="cb667-10"><a href="-dag-causal-terror.html#cb667-10"></a>s &lt;-<span class="st"> </span>nw <span class="op">+</span><span class="st"> </span>tw <span class="co"># total score</span></span>
<span id="cb667-11"><a href="-dag-causal-terror.html#cb667-11"></a>q &lt;-<span class="st"> </span><span class="kw">quantile</span>( s, <span class="dv">1</span><span class="op">-</span>p ) <span class="co"># top 10% threshold</span></span>
<span id="cb667-12"><a href="-dag-causal-terror.html#cb667-12"></a></span>
<span id="cb667-13"><a href="-dag-causal-terror.html#cb667-13"></a>selected &lt;-<span class="st"> </span><span class="kw">ifelse</span>( s <span class="op">&gt;=</span><span class="st"> </span>q, <span class="ot">TRUE</span>, <span class="ot">FALSE</span>) </span>
<span id="cb667-14"><a href="-dag-causal-terror.html#cb667-14"></a><span class="kw">cor</span>(tw[selected], nw[selected])</span></code></pre></div>
<pre><code>## [1] -0.76800831</code></pre>
<div class="sourceCode" id="cb669"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb669-1"><a href="-dag-causal-terror.html#cb669-1"></a>proposal &lt;-<span class="st"> </span><span class="kw">data.frame</span>(nw, tw, selected)</span>
<span id="cb669-2"><a href="-dag-causal-terror.html#cb669-2"></a><span class="kw">with</span>(proposal, <span class="kw">plot</span>(nw[<span class="op">!</span>selected], tw[<span class="op">!</span>selected], <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>),</span>
<span id="cb669-3"><a href="-dag-causal-terror.html#cb669-3"></a>                    <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>,<span class="fl">3.5</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">3.5</span>,<span class="dv">3</span>), </span>
<span id="cb669-4"><a href="-dag-causal-terror.html#cb669-4"></a>                    <span class="dt">bty=</span><span class="st">&quot;n&quot;</span>, </span>
<span id="cb669-5"><a href="-dag-causal-terror.html#cb669-5"></a>                    <span class="dt">xlab =</span> <span class="st">&quot;newsworthiness&quot;</span>, </span>
<span id="cb669-6"><a href="-dag-causal-terror.html#cb669-6"></a>                    <span class="dt">ylab =</span> <span class="st">&quot;trustworthiness&quot;</span>))</span>
<span id="cb669-7"><a href="-dag-causal-terror.html#cb669-7"></a><span class="kw">points</span>(proposal<span class="op">$</span>nw[proposal<span class="op">$</span>selected], </span>
<span id="cb669-8"><a href="-dag-causal-terror.html#cb669-8"></a>       proposal<span class="op">$</span>tw[proposal<span class="op">$</span>selected], </span>
<span id="cb669-9"><a href="-dag-causal-terror.html#cb669-9"></a>       <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>), </span>
<span id="cb669-10"><a href="-dag-causal-terror.html#cb669-10"></a>       <span class="dt">pch =</span> <span class="dv">16</span>)</span>
<span id="cb669-11"><a href="-dag-causal-terror.html#cb669-11"></a><span class="kw">abline</span>(<span class="kw">lm</span>(proposal<span class="op">$</span>nw[proposal<span class="op">$</span>selected] <span class="op">~</span><span class="st"> </span>proposal<span class="op">$</span>tw[proposal<span class="op">$</span>selected]), </span>
<span id="cb669-12"><a href="-dag-causal-terror.html#cb669-12"></a>       <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>))</span>
<span id="cb669-13"><a href="-dag-causal-terror.html#cb669-13"></a><span class="kw">text</span>(<span class="dv">1</span>, <span class="fl">-2.8</span>, <span class="st">&quot;rejected&quot;</span>)</span>
<span id="cb669-14"><a href="-dag-causal-terror.html#cb669-14"></a><span class="kw">text</span>(<span class="dv">2</span>, <span class="fl">2.5</span>, <span class="st">&quot;selected&quot;</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig01"></span>
<img src="bookdown_files/figure-html/introBayes09-fig01-1.png" alt="Why the most newsworthy studies might be least trustworthy. 200 research proposals are ranked by combined trustworthiness and news worthiness. The top 10% are selected for funding. While there is no correlation before selection, the two criteria are strongly negatively correlated after selection. The correlation here is -0.77." width="576" />
<p class="caption">
圖 49.1: Why the most newsworthy studies might be least trustworthy. 200 research proposals are ranked by combined trustworthiness and news worthiness. The top 10% are selected for funding. While there is no correlation before selection, the two criteria are strongly negatively correlated after selection. The correlation here is -0.77.
</p>
</div>
<div id="multicollinearity" class="section level2">
<h2><span class="header-section-number">49.1</span> 多重共線性問題 multicollinearity</h2>
<p>多重共線性，通常當模型的預測變量之間有較強的相互關係的時候會出現。它造成的結果是你的模型給出的事後概率分佈會表現的似乎和任何一個預測變量之間都沒什麼關係，即便事實上其中的一個甚至幾個都可能和結果變量存在著相互依賴的關係。這樣的模型對於研究目的是使用模型來做預測的情形下沒有什麼本質的影響。</p>
<p>想像一下我們想使用一個人的腿長度來預測他/她的身高。你覺得模型中同時放入左右兩條腿的長度作為預測變量的話，事情會變成怎樣的呢？</p>
<p>下面的代碼是通過計算機模擬生成100個人的身高和腿長度。</p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb670-1"><a href="-dag-causal-terror.html#cb670-1"></a>N &lt;-<span class="st"> </span><span class="dv">100</span>                        <span class="co"># number of individuals </span></span>
<span id="cb670-2"><a href="-dag-causal-terror.html#cb670-2"></a><span class="kw">set.seed</span>(<span class="dv">909</span>)</span>
<span id="cb670-3"><a href="-dag-causal-terror.html#cb670-3"></a>height &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dv">10</span>, <span class="dv">2</span>)       <span class="co"># sim total height for each</span></span>
<span id="cb670-4"><a href="-dag-causal-terror.html#cb670-4"></a>leg_prop &lt;-<span class="st"> </span><span class="kw">runif</span>(N, <span class="fl">0.4</span>, <span class="fl">0.5</span>)  <span class="co"># leg as proportion of height </span></span>
<span id="cb670-5"><a href="-dag-causal-terror.html#cb670-5"></a>leg_left &lt;-<span class="st"> </span>leg_prop <span class="op">*</span><span class="st"> </span>height <span class="op">+</span><span class="st"> </span><span class="co"># sim left leg as proportion + error</span></span>
<span id="cb670-6"><a href="-dag-causal-terror.html#cb670-6"></a><span class="st">  </span><span class="kw">rnorm</span>( N, <span class="dv">0</span>, <span class="fl">0.02</span> ) </span>
<span id="cb670-7"><a href="-dag-causal-terror.html#cb670-7"></a>leg_right &lt;-<span class="st"> </span>leg_prop <span class="op">*</span><span class="st"> </span>height <span class="op">+</span><span class="st"> </span><span class="co"># sim right leg as proportion + error</span></span>
<span id="cb670-8"><a href="-dag-causal-terror.html#cb670-8"></a><span class="st">  </span><span class="kw">rnorm</span>( N, <span class="dv">0</span>, <span class="fl">0.02</span> )</span>
<span id="cb670-9"><a href="-dag-causal-terror.html#cb670-9"></a>                                  <span class="co"># combine into data frame</span></span>
<span id="cb670-10"><a href="-dag-causal-terror.html#cb670-10"></a>d &lt;-<span class="st"> </span><span class="kw">data.frame</span>(height, leg_left, leg_right)</span>
<span id="cb670-11"><a href="-dag-causal-terror.html#cb670-11"></a><span class="kw">head</span>(d)</span></code></pre></div>
<pre><code>##       height  leg_left leg_right
## 1  5.9314170 2.6794115 2.7092861
## 2  6.5129833 2.6764277 2.6800068
## 3  9.3466279 3.9271549 3.9849467
## 4  9.2330335 3.9641911 3.9933889
## 5 10.3571282 4.4275932 4.4187658
## 6 10.0889226 4.9566406 4.9718779</code></pre>
<p>如果我們同時使用兩腿的長度作為預測身高的變量建立簡單線性回歸模型的話，我們會期待獲得怎樣的結果？從生成數據的過程我們已知平均地，腿長度佔身高的比例是45%。所以我們其實會期待腿長度的回歸係數應該在 <span class="math inline">\(10/4.5 \approx 2.2\)</span> 左右。但事實是怎樣呢？</p>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb672-1"><a href="-dag-causal-terror.html#cb672-1"></a>m6<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb672-2"><a href="-dag-causal-terror.html#cb672-2"></a>  <span class="kw">alist</span>(</span>
<span id="cb672-3"><a href="-dag-causal-terror.html#cb672-3"></a>    height <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( mu, sigma ), </span>
<span id="cb672-4"><a href="-dag-causal-terror.html#cb672-4"></a>    mu &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>bl <span class="op">*</span><span class="st"> </span>leg_left <span class="op">+</span><span class="st"> </span>br <span class="op">*</span><span class="st"> </span>leg_right, </span>
<span id="cb672-5"><a href="-dag-causal-terror.html#cb672-5"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( <span class="dv">10</span>, <span class="dv">100</span> ),</span>
<span id="cb672-6"><a href="-dag-causal-terror.html#cb672-6"></a>    bl <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">2</span>, <span class="dv">10</span>), </span>
<span id="cb672-7"><a href="-dag-causal-terror.html#cb672-7"></a>    br <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">2</span>, <span class="dv">10</span>), </span>
<span id="cb672-8"><a href="-dag-causal-terror.html#cb672-8"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>( <span class="dv">1</span> )</span>
<span id="cb672-9"><a href="-dag-causal-terror.html#cb672-9"></a>  ), <span class="dt">data =</span> d</span>
<span id="cb672-10"><a href="-dag-causal-terror.html#cb672-10"></a>)</span>
<span id="cb672-11"><a href="-dag-causal-terror.html#cb672-11"></a><span class="kw">precis</span>(m6<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>##             mean          sd        5.5%      94.5%
## a     0.98127908 0.283955398  0.52746352 1.43509465
## bl    0.21185848 2.527037063 -3.82683482 4.25055177
## br    1.78367737 2.531250606 -2.26174999 5.82910472
## sigma 0.61710260 0.043434269  0.54768625 0.68651895</code></pre>
<p>左右腿的數據同時放到一個模型裡給出的結果似乎是令人困惑的。</p>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb674-1"><a href="-dag-causal-terror.html#cb674-1"></a><span class="kw">plot</span>(<span class="kw">precis</span>(m6<span class="fl">.1</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig02"></span>
<img src="bookdown_files/figure-html/introBayes09-fig02-1.png" alt="If both legs have almost identical lengths, and height is so strongly associated with leg length, then why is this posterior distribution so weird?" width="576" />
<p class="caption">
圖 49.2: If both legs have almost identical lengths, and height is so strongly associated with leg length, then why is this posterior distribution so weird?
</p>
</div>
<p>我們看模型 <code>m6.1</code> 給出的 <code>bl, br</code> 的事後聯合分佈 (joint posterior distribution)：</p>
<div class="sourceCode" id="cb675"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb675-1"><a href="-dag-causal-terror.html#cb675-1"></a>post &lt;-<span class="st"> </span><span class="kw">extract.samples</span>(m6<span class="fl">.1</span>)</span>
<span id="cb675-2"><a href="-dag-causal-terror.html#cb675-2"></a><span class="kw">plot</span>(bl <span class="op">~</span><span class="st"> </span>br, post, <span class="dt">col =</span> <span class="kw">col.alpha</span>(rangi2, <span class="fl">0.1</span>),</span>
<span id="cb675-3"><a href="-dag-causal-terror.html#cb675-3"></a>     <span class="dt">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig03"></span>
<img src="bookdown_files/figure-html/introBayes09-fig03-1.png" alt="Posterior distribution of the association of each leg with hegiht, from model m6.1. Since both variables contain almost identical information, the posterior is a narrow ridge of negatively correlated values." width="576" />
<p class="caption">
圖 49.3: Posterior distribution of the association of each leg with hegiht, from model m6.1. Since both variables contain almost identical information, the posterior is a narrow ridge of negatively correlated values.
</p>
</div>
<p>如圖 <a href="-dag-causal-terror.html#fig:introBayes09-fig03">49.3</a> 顯示的那樣，當 <code>bl</code> 很大時，<code>br</code> 就很小，反之亦然。</p>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb676-1"><a href="-dag-causal-terror.html#cb676-1"></a>sumblbr &lt;-<span class="st"> </span>post<span class="op">$</span>bl <span class="op">+</span><span class="st"> </span>post<span class="op">$</span>br</span>
<span id="cb676-2"><a href="-dag-causal-terror.html#cb676-2"></a><span class="kw">dens</span>(sumblbr, <span class="dt">col =</span> rangi2, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">xlab =</span> <span class="st">&quot;sum of bl and br&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig04"></span>
<img src="bookdown_files/figure-html/introBayes09-fig04-1.png" alt="The posterior distribution of the sum of the two parameters is cnetered on the proper association of eight leg with height." width="576" />
<p class="caption">
圖 49.4: The posterior distribution of the sum of the two parameters is cnetered on the proper association of eight leg with height.
</p>
</div>
<p>於是我們知道我們應該從模型中去掉其中一個腿的信息，從而獲得正確的模型和計算結果：</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb677-1"><a href="-dag-causal-terror.html#cb677-1"></a>m6<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb677-2"><a href="-dag-causal-terror.html#cb677-2"></a>  <span class="kw">alist</span>(</span>
<span id="cb677-3"><a href="-dag-causal-terror.html#cb677-3"></a>    height <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( mu, sigma ), </span>
<span id="cb677-4"><a href="-dag-causal-terror.html#cb677-4"></a>    mu &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>bl <span class="op">*</span><span class="st"> </span>leg_left, </span>
<span id="cb677-5"><a href="-dag-causal-terror.html#cb677-5"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( <span class="dv">10</span>, <span class="dv">100</span> ), </span>
<span id="cb677-6"><a href="-dag-causal-terror.html#cb677-6"></a>    bl <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">2</span>, <span class="dv">10</span>), </span>
<span id="cb677-7"><a href="-dag-causal-terror.html#cb677-7"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>( <span class="dv">1</span> )</span>
<span id="cb677-8"><a href="-dag-causal-terror.html#cb677-8"></a>  ), <span class="dt">data =</span> d</span>
<span id="cb677-9"><a href="-dag-causal-terror.html#cb677-9"></a>)</span>
<span id="cb677-10"><a href="-dag-causal-terror.html#cb677-10"></a></span>
<span id="cb677-11"><a href="-dag-causal-terror.html#cb677-11"></a><span class="kw">precis</span>(m6<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>##             mean          sd       5.5%      94.5%
## a     0.99793262 0.283646205 0.54461121 1.45125404
## bl    1.99206762 0.061157037 1.89432686 2.08980838
## sigma 0.61860375 0.043539981 0.54901845 0.68818905</code></pre>
<div id="哺乳動物奶質量數據中的共線性" class="section level3">
<h3><span class="header-section-number">49.1.1</span> 哺乳動物奶質量數據中的共線性</h3>
<p>重新打開哺乳動物奶質量數據。我們看其中的含脂肪百分比和含乳糖百分比這兩個變量。把他們標準化：</p>
<div class="sourceCode" id="cb679"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb679-1"><a href="-dag-causal-terror.html#cb679-1"></a><span class="kw">data</span>(milk)</span>
<span id="cb679-2"><a href="-dag-causal-terror.html#cb679-2"></a>d &lt;-<span class="st"> </span>milk</span>
<span id="cb679-3"><a href="-dag-causal-terror.html#cb679-3"></a>d<span class="op">$</span>K &lt;-<span class="st"> </span><span class="kw">standardize</span>( d<span class="op">$</span>kcal.per.g )</span>
<span id="cb679-4"><a href="-dag-causal-terror.html#cb679-4"></a>d<span class="op">$</span>F &lt;-<span class="st"> </span><span class="kw">standardize</span>( d<span class="op">$</span>perc.fat )</span>
<span id="cb679-5"><a href="-dag-causal-terror.html#cb679-5"></a>d<span class="op">$</span>L &lt;-<span class="st"> </span><span class="kw">standardize</span>( d<span class="op">$</span>perc.lactose )</span></code></pre></div>
<p>下面的模型使用標準化的脂肪百分比和乳糖百分比兩個變量作為預測變量來預測奶的能量密度：</p>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb680-1"><a href="-dag-causal-terror.html#cb680-1"></a><span class="co"># kcal.per.g regressed on perc.fat</span></span>
<span id="cb680-2"><a href="-dag-causal-terror.html#cb680-2"></a>m6<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb680-3"><a href="-dag-causal-terror.html#cb680-3"></a>  <span class="kw">alist</span>(</span>
<span id="cb680-4"><a href="-dag-causal-terror.html#cb680-4"></a>    K <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( mu, sigma ),</span>
<span id="cb680-5"><a href="-dag-causal-terror.html#cb680-5"></a>    mu &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>bF <span class="op">*</span><span class="st"> </span>F, </span>
<span id="cb680-6"><a href="-dag-causal-terror.html#cb680-6"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.2</span> ), </span>
<span id="cb680-7"><a href="-dag-causal-terror.html#cb680-7"></a>    bF <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> ), </span>
<span id="cb680-8"><a href="-dag-causal-terror.html#cb680-8"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb680-9"><a href="-dag-causal-terror.html#cb680-9"></a>  ), <span class="dt">data =</span> d</span>
<span id="cb680-10"><a href="-dag-causal-terror.html#cb680-10"></a>)</span>
<span id="cb680-11"><a href="-dag-causal-terror.html#cb680-11"></a></span>
<span id="cb680-12"><a href="-dag-causal-terror.html#cb680-12"></a><span class="co"># kcal.per.g regressed on perc.lactose</span></span>
<span id="cb680-13"><a href="-dag-causal-terror.html#cb680-13"></a>m6<span class="fl">.4</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb680-14"><a href="-dag-causal-terror.html#cb680-14"></a>  <span class="kw">alist</span>(</span>
<span id="cb680-15"><a href="-dag-causal-terror.html#cb680-15"></a>    K <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( mu, sigma ), </span>
<span id="cb680-16"><a href="-dag-causal-terror.html#cb680-16"></a>    mu &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>bL <span class="op">*</span><span class="st"> </span>L, </span>
<span id="cb680-17"><a href="-dag-causal-terror.html#cb680-17"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.2</span> ), </span>
<span id="cb680-18"><a href="-dag-causal-terror.html#cb680-18"></a>    bL <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> ), </span>
<span id="cb680-19"><a href="-dag-causal-terror.html#cb680-19"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb680-20"><a href="-dag-causal-terror.html#cb680-20"></a>  ), <span class="dt">data =</span>  d</span>
<span id="cb680-21"><a href="-dag-causal-terror.html#cb680-21"></a>)</span>
<span id="cb680-22"><a href="-dag-causal-terror.html#cb680-22"></a></span>
<span id="cb680-23"><a href="-dag-causal-terror.html#cb680-23"></a></span>
<span id="cb680-24"><a href="-dag-causal-terror.html#cb680-24"></a><span class="kw">precis</span>( m6<span class="fl">.3</span> )</span></code></pre></div>
<pre><code>##                mean          sd        5.5%      94.5%
## a     1.5355260e-07 0.077251946 -0.12346338 0.12346368
## bF    8.6189697e-01 0.084260876  0.72723181 0.99656212
## sigma 4.5101794e-01 0.058707561  0.35719192 0.54484396</code></pre>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="-dag-causal-terror.html#cb682-1"></a><span class="kw">precis</span>( m6<span class="fl">.4</span> )</span></code></pre></div>
<pre><code>##                 mean          sd        5.5%       94.5%
## a      7.4388949e-07 0.066616333 -0.10646502  0.10646651
## bL    -9.0245498e-01 0.071328484 -1.01645167 -0.78845828
## sigma  3.8046526e-01 0.049582594  0.30122270  0.45970783</code></pre>
<p>當單獨使用其中之一作為能量密度的預測變量時，我們發現他們各自的回歸係數似乎互相成鏡像數據，一個是正的，另一個是負的。而且二者的回歸係屬的事後概率分佈都很精確，我們認為這兩個單獨變量都是可以用來預測奶能量密度的極佳預測變量。因為脂肪百分比越高，能量密度越高，反之，乳糖含量比例越高，那麼能量密度則越低。我們來看把他們兩個同時加入模型中會發生什麼現象：</p>
<div class="sourceCode" id="cb684"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb684-1"><a href="-dag-causal-terror.html#cb684-1"></a>m6<span class="fl">.5</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb684-2"><a href="-dag-causal-terror.html#cb684-2"></a>  <span class="kw">alist</span>(</span>
<span id="cb684-3"><a href="-dag-causal-terror.html#cb684-3"></a>    K <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( mu, sigma ), </span>
<span id="cb684-4"><a href="-dag-causal-terror.html#cb684-4"></a>    mu &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>bF <span class="op">*</span><span class="st"> </span>F <span class="op">+</span><span class="st"> </span>bL <span class="op">*</span><span class="st"> </span>L, </span>
<span id="cb684-5"><a href="-dag-causal-terror.html#cb684-5"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.2</span> ), </span>
<span id="cb684-6"><a href="-dag-causal-terror.html#cb684-6"></a>    bF <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> ), </span>
<span id="cb684-7"><a href="-dag-causal-terror.html#cb684-7"></a>    bL <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( <span class="dv">0</span>, <span class="fl">0.5</span> ), </span>
<span id="cb684-8"><a href="-dag-causal-terror.html#cb684-8"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>( <span class="dv">1</span> )</span>
<span id="cb684-9"><a href="-dag-causal-terror.html#cb684-9"></a>  ), <span class="dt">data =</span> d</span>
<span id="cb684-10"><a href="-dag-causal-terror.html#cb684-10"></a>)</span>
<span id="cb684-11"><a href="-dag-causal-terror.html#cb684-11"></a><span class="kw">precis</span>( m6<span class="fl">.5</span> )</span></code></pre></div>
<pre><code>##                 mean          sd        5.5%       94.5%
## a     -3.1721359e-07 0.066035771 -0.10553823  0.10553760
## bF     2.4349835e-01 0.183578648 -0.04989579  0.53689248
## bL    -6.7808254e-01 0.183776698 -0.97179320 -0.38437188
## sigma  3.7674180e-01 0.049183935  0.29813637  0.45534722</code></pre>
<p>你看現在 <code>m6.5</code> 模型中同時加入了脂肪百分比，和乳糖百分比的兩個變量。都比單獨使用時給出的回歸係屬更接近 0。而且各自的事後概率分佈的標準差都比單獨使用時大了許多（幾乎兩倍）。這並非是來自計算機模擬的數據，而是真正現實中存在的奶製品測量之後的數據。脂肪百分比和乳糖百分比二者之間存在的很強的互相預測的關係。我們從他們的三點圖可以看出其中的奧妙：</p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb686-1"><a href="-dag-causal-terror.html#cb686-1"></a><span class="kw">pairs</span>( <span class="op">~</span><span class="st"> </span>kcal.per.g <span class="op">+</span><span class="st"> </span>perc.fat <span class="op">+</span><span class="st"> </span>perc.lactose, <span class="dt">data =</span> d, </span>
<span id="cb686-2"><a href="-dag-causal-terror.html#cb686-2"></a>       <span class="dt">col =</span> rangi2)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig05"></span>
<img src="bookdown_files/figure-html/introBayes09-fig05-1.png" alt="A pairs plot of the total energy, percent fat, and percent lactose variables from the primate milk data. Percent fat and percent lactose are strongly negatively correlated with one another, providing mostly the same information. " width="576" />
<p class="caption">
圖 49.5: A pairs plot of the total energy, percent fat, and percent lactose variables from the primate milk data. Percent fat and percent lactose are strongly negatively correlated with one another, providing mostly the same information.
</p>
</div>
</div>
</div>
<div id="posttreatbias" class="section level2">
<h2><span class="header-section-number">49.2</span> 治療後偏倚 post-treatment bias</h2>
<div class="sourceCode" id="cb687"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb687-1"><a href="-dag-causal-terror.html#cb687-1"></a><span class="kw">set.seed</span>(<span class="dv">71</span>)</span>
<span id="cb687-2"><a href="-dag-causal-terror.html#cb687-2"></a> <span class="co"># number of plants </span></span>
<span id="cb687-3"><a href="-dag-causal-terror.html#cb687-3"></a>N &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb687-4"><a href="-dag-causal-terror.html#cb687-4"></a></span>
<span id="cb687-5"><a href="-dag-causal-terror.html#cb687-5"></a><span class="co"># simulate initial heights </span></span>
<span id="cb687-6"><a href="-dag-causal-terror.html#cb687-6"></a>h0 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dv">10</span>, <span class="dv">2</span>)</span>
<span id="cb687-7"><a href="-dag-causal-terror.html#cb687-7"></a></span>
<span id="cb687-8"><a href="-dag-causal-terror.html#cb687-8"></a><span class="co"># assign treatments and simulate fungus and growth</span></span>
<span id="cb687-9"><a href="-dag-causal-terror.html#cb687-9"></a>treatment &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>, <span class="dt">each =</span> N<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb687-10"><a href="-dag-causal-terror.html#cb687-10"></a>fungus &lt;-<span class="st"> </span><span class="kw">rbinom</span>( N, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">prob =</span> <span class="fl">0.5</span> <span class="op">-</span><span class="st"> </span>treatment <span class="op">*</span><span class="st"> </span><span class="fl">0.4</span>)</span>
<span id="cb687-11"><a href="-dag-causal-terror.html#cb687-11"></a>h1 &lt;-<span class="st"> </span>h0 <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>( N, <span class="dv">5</span> <span class="op">-</span><span class="st"> </span><span class="dv">3</span><span class="op">*</span>fungus )</span>
<span id="cb687-12"><a href="-dag-causal-terror.html#cb687-12"></a></span>
<span id="cb687-13"><a href="-dag-causal-terror.html#cb687-13"></a><span class="co"># compose a clean data frame</span></span>
<span id="cb687-14"><a href="-dag-causal-terror.html#cb687-14"></a>d &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">h0 =</span> h0, <span class="dt">h1 =</span> h1, <span class="dt">treatment =</span> treatment, <span class="dt">fungus =</span> fungus)</span>
<span id="cb687-15"><a href="-dag-causal-terror.html#cb687-15"></a><span class="kw">head</span>(d)</span></code></pre></div>
<pre><code>##           h0        h1 treatment fungus
## 1  9.1363156 14.345788         0      0
## 2  9.1056256 15.623924         0      0
## 3  9.0428548 14.386665         0      0
## 4 10.8342908 15.837422         0      0
## 5  9.1641987 11.469124         0      1
## 6  7.6256722 11.107757         0      0</code></pre>
<div class="sourceCode" id="cb689"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb689-1"><a href="-dag-causal-terror.html#cb689-1"></a><span class="kw">precis</span>(d)</span></code></pre></div>
<pre><code>##                mean         sd       5.5%     94.5%    histogram
## h0         9.959780 2.10116231  6.5703278 13.078737 ▁▂▂▂▇▃▂▃▁▁▁▁
## h1        14.399204 2.68808705 10.6180024 17.933694     ▁▁▃▇▇▇▁▁
## treatment  0.500000 0.50251891  0.0000000  1.000000   ▇▁▁▁▁▁▁▁▁▇
## fungus     0.230000 0.42295258  0.0000000  1.000000   ▇▁▁▁▁▁▁▁▁▂</code></pre>
<div id="設定模型" class="section level3">
<h3><span class="header-section-number">49.2.1</span> 設定模型</h3>
<p><span class="math display">\[
\begin{aligned}
h_{1,i} &amp; \sim \text{Normal}(\mu_i, \sigma) \\
\mu_i &amp; = h_{0,i} \times p
\end{aligned}
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(h_{0,i}\)</span> 是在時間 <span class="math inline">\(t = 0\)</span> 時的植物高度；</li>
<li><span class="math inline">\(h_{1,i}\)</span> 是在時間 <span class="math inline">\(t = 1\)</span> 時植物的高度；</li>
<li><span class="math inline">\(p\)</span> 是比例係數，也就是 <span class="math inline">\(h_{1,i}\)</span> 和 <span class="math inline">\(h_{0,i}\)</span> 之間的比值，<span class="math inline">\(p = \frac{h_{1,i}}{h_{0,i}}\)</span>。如果 <span class="math inline">\(p = 1\)</span> 說明在時間 <span class="math inline">\(t = 1\)</span> 時植物並沒有比在時間 <span class="math inline">\(t = 0\)</span> 時有長高。</li>
</ul>
<p>這裡我們對 <span class="math inline">\(p\)</span> 使用的先驗概率分佈，應該會集中在 1 的附近，因為無信息表示我們認為植物的高度不會隨時間發生變化。但是這個比例 <span class="math inline">\(p\)</span> 不能為負數。因為它是一個值和另一個值的比值。我們之前使用過相似特質的先驗概率分佈，也就是對數正（常）態分佈（Log-Normal distribution）：</p>
<p><span class="math display">\[
\beta \sim \text{Log-Normal}(0, 0.25)
\]</span></p>
<p>看看這個先驗概率分佈的密度曲線是什麼樣子：</p>
<div class="sourceCode" id="cb691"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb691-1"><a href="-dag-causal-terror.html#cb691-1"></a>sim_p &lt;-<span class="st"> </span><span class="kw">rlnorm</span>(<span class="dv">10000</span>, <span class="dv">0</span>, <span class="fl">0.25</span>)</span>
<span id="cb691-2"><a href="-dag-causal-terror.html#cb691-2"></a><span class="kw">precis</span>(sim_p)</span></code></pre></div>
<pre><code>##          mean         sd       5.5%     94.5%    histogram
## sim_p 1.03699 0.26298937 0.67068301 1.4963969 ▁▁▃▇▇▃▁▁▁▁▁▁</code></pre>
<div class="sourceCode" id="cb693"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb693-1"><a href="-dag-causal-terror.html#cb693-1"></a><span class="kw">dens</span>( sim_p, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">3</span>), <span class="dt">adj =</span> <span class="fl">0.1</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig06"></span>
<img src="bookdown_files/figure-html/introBayes09-fig06-1.png" alt="Distribution density funciton of Log-Normal(0,0.25)" width="576" />
<p class="caption">
圖 49.6: Distribution density funciton of Log-Normal(0,0.25)
</p>
</div>
<p>也就是說，我們給出的這個先驗概率分佈認為，植物在不同時間點之間的生長比例範圍在 0.67 和 1.49 之間，也就是要麼縮水33%，或者最多長高50%。</p>
<p>建立該模型：</p>
<div class="sourceCode" id="cb694"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb694-1"><a href="-dag-causal-terror.html#cb694-1"></a>m6<span class="fl">.6</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb694-2"><a href="-dag-causal-terror.html#cb694-2"></a>  <span class="kw">alist</span>(</span>
<span id="cb694-3"><a href="-dag-causal-terror.html#cb694-3"></a>    h1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma), </span>
<span id="cb694-4"><a href="-dag-causal-terror.html#cb694-4"></a>    mu &lt;-<span class="st"> </span>h0 <span class="op">*</span><span class="st"> </span>p ,</span>
<span id="cb694-5"><a href="-dag-causal-terror.html#cb694-5"></a>    p <span class="op">~</span><span class="st"> </span><span class="kw">dlnorm</span>( <span class="dv">0</span>, <span class="fl">0.25</span> ),</span>
<span id="cb694-6"><a href="-dag-causal-terror.html#cb694-6"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb694-7"><a href="-dag-causal-terror.html#cb694-7"></a>  ), <span class="dt">data  =</span> d</span>
<span id="cb694-8"><a href="-dag-causal-terror.html#cb694-8"></a>)</span>
<span id="cb694-9"><a href="-dag-causal-terror.html#cb694-9"></a><span class="kw">precis</span>(m6<span class="fl">.6</span>)</span></code></pre></div>
<pre><code>##            mean          sd      5.5%     94.5%
## p     1.4266259 0.017609916 1.3984818 1.4547699
## sigma 1.7932857 0.125172622 1.5932357 1.9933357</code></pre>
<p><span class="math inline">\(p\)</span> 的事後概率分佈均值是 1.43，也就是預估平均每單位時間植物會長高大約 40%。接下來如果加入另外兩個變量，治療組，和是否出現菌落。我們會把這兩個變量對植物施加的影響使用線性回歸模型的方式加到 <span class="math inline">\(p\)</span> 上去：</p>
<p><span class="math display">\[
\begin{aligned}
h_{1, i} &amp; \sim \text{Normal}(\mu_i, \sigma) \\
\mu_i  &amp; = h_{0,i} \times p \\ 
p     &amp; = \alpha + \beta_T T_i + \beta_F F_i \\
\alpha  &amp; \sim \text{Log-Normal}(0, 0.25) \\
\beta_T &amp; \sim \text{Normal}(0, 0.5) \\ 
\beta_F &amp; \sim \text{Normal}(0, 0.5) \\ 
\sigma  &amp; \sim \text{Exponential}(1)
\end{aligned}
\]</span></p>
<p>上述模型的R代碼如下：</p>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb696-1"><a href="-dag-causal-terror.html#cb696-1"></a>m6<span class="fl">.7</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb696-2"><a href="-dag-causal-terror.html#cb696-2"></a>  <span class="kw">alist</span>(</span>
<span id="cb696-3"><a href="-dag-causal-terror.html#cb696-3"></a>    h1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma), </span>
<span id="cb696-4"><a href="-dag-causal-terror.html#cb696-4"></a>    mu &lt;-<span class="st"> </span>h0 <span class="op">*</span><span class="st"> </span>p , </span>
<span id="cb696-5"><a href="-dag-causal-terror.html#cb696-5"></a>    p &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>bt <span class="op">*</span><span class="st"> </span>treatment <span class="op">+</span><span class="st"> </span>bf <span class="op">*</span><span class="st"> </span>fungus, </span>
<span id="cb696-6"><a href="-dag-causal-terror.html#cb696-6"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dlnorm</span>( <span class="dv">0</span>, <span class="fl">0.2</span> ),</span>
<span id="cb696-7"><a href="-dag-causal-terror.html#cb696-7"></a>    bt  <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), </span>
<span id="cb696-8"><a href="-dag-causal-terror.html#cb696-8"></a>    bf  <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="fl">0.5</span>),</span>
<span id="cb696-9"><a href="-dag-causal-terror.html#cb696-9"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb696-10"><a href="-dag-causal-terror.html#cb696-10"></a>  ), <span class="dt">data =</span> d</span>
<span id="cb696-11"><a href="-dag-causal-terror.html#cb696-11"></a>)</span>
<span id="cb696-12"><a href="-dag-causal-terror.html#cb696-12"></a><span class="kw">precis</span>(m6<span class="fl">.7</span>)</span></code></pre></div>
<pre><code>##                mean          sd         5.5%        94.5%
## a      1.4813914677 0.024510693  1.442218647  1.520564289
## bt     0.0024122219 0.029869649 -0.045325247  0.050149691
## bf    -0.2667189147 0.036547721 -0.325129231 -0.208308598
## sigma  1.4087974415 0.098620704  1.251182509  1.566412374</code></pre>
<p>這裡似乎在說，治療本身對植物生長速度並無效果，但是有菌落卻對生長比例造成了負影響。可是我們明明知道菌落是否存在，是取決於治療本身的，也就是菌落是治療對土壤造成的結果之一。上述模型似乎在告訴我們，當我們知道了治療造成的結果之一 – 是否有菌落，那麼治療本身對植物生長比例的影響就消失了。正確的模型是，我們應該把菌落這個變量從模型中拿掉，從而尋找治療對植物生長率的效果：</p>
<div class="sourceCode" id="cb698"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb698-1"><a href="-dag-causal-terror.html#cb698-1"></a>m6<span class="fl">.8</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb698-2"><a href="-dag-causal-terror.html#cb698-2"></a>  <span class="kw">alist</span>(</span>
<span id="cb698-3"><a href="-dag-causal-terror.html#cb698-3"></a>    h1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma), </span>
<span id="cb698-4"><a href="-dag-causal-terror.html#cb698-4"></a>    mu &lt;-<span class="st"> </span>h0 <span class="op">*</span><span class="st"> </span>p, </span>
<span id="cb698-5"><a href="-dag-causal-terror.html#cb698-5"></a>    p &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>bt <span class="op">*</span><span class="st"> </span>treatment, </span>
<span id="cb698-6"><a href="-dag-causal-terror.html#cb698-6"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dlnorm</span>(<span class="dv">0</span>, <span class="fl">0.25</span>),</span>
<span id="cb698-7"><a href="-dag-causal-terror.html#cb698-7"></a>    bt <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="fl">0.5</span>),</span>
<span id="cb698-8"><a href="-dag-causal-terror.html#cb698-8"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb698-9"><a href="-dag-causal-terror.html#cb698-9"></a>  ), <span class="dt">data =</span> d</span>
<span id="cb698-10"><a href="-dag-causal-terror.html#cb698-10"></a>)</span>
<span id="cb698-11"><a href="-dag-causal-terror.html#cb698-11"></a><span class="kw">precis</span>(m6<span class="fl">.8</span>)</span></code></pre></div>
<pre><code>##              mean          sd        5.5%     94.5%
## a     1.381693513 0.025197600 1.341422882 1.4219641
## bt    0.083654229 0.034313231 0.028815059 0.1384934
## sigma 1.746295968 0.121908002 1.551463435 1.9411285</code></pre>
<p>上述的分析過程和結果告訴我們，如果我們把由於治療本身造成的結果之一也錯誤地放進預測變量中的話，治療本身的效果會消失。</p>
<p>這些變量之間的關係還可以用下面的DAG圖來輔助理解：</p>
<div class="sourceCode" id="cb700"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb700-1"><a href="-dag-causal-terror.html#cb700-1"></a>plant_dag &lt;-<span class="st"> </span><span class="kw">dagitty</span>(<span class="st">&quot;dag{</span></span>
<span id="cb700-2"><a href="-dag-causal-terror.html#cb700-2"></a><span class="st">      H_0 -&gt; H_1 </span></span>
<span id="cb700-3"><a href="-dag-causal-terror.html#cb700-3"></a><span class="st">      F -&gt; H_1 </span></span>
<span id="cb700-4"><a href="-dag-causal-terror.html#cb700-4"></a><span class="st">      T -&gt; F</span></span>
<span id="cb700-5"><a href="-dag-causal-terror.html#cb700-5"></a><span class="st">}&quot;</span>)</span>
<span id="cb700-6"><a href="-dag-causal-terror.html#cb700-6"></a><span class="kw">coordinates</span>( plant_dag ) &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dt">H_0 =</span> <span class="dv">0</span> , <span class="dt">T =</span> <span class="dv">2</span>, <span class="dt">F =</span> <span class="fl">1.5</span>, <span class="dt">H_1 =</span> <span class="dv">1</span>), </span>
<span id="cb700-7"><a href="-dag-causal-terror.html#cb700-7"></a>                                 <span class="dt">y =</span> <span class="kw">c</span>(<span class="dt">H_0 =</span> <span class="dv">0</span> , <span class="dt">T =</span> <span class="dv">0</span>, <span class="dt">F =</span> <span class="dv">0</span>, <span class="dt">H_1 =</span> <span class="dv">0</span>))</span>
<span id="cb700-8"><a href="-dag-causal-terror.html#cb700-8"></a><span class="kw">drawdag</span>(plant_dag)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig07"></span>
<img src="bookdown_files/figure-html/introBayes09-fig07-1.png" alt="The DAG of the fungus and treatment effect on the grow of plant." width="768" />
<p class="caption">
圖 49.7: The DAG of the fungus and treatment effect on the grow of plant.
</p>
</div>
<p>如果我們錯誤地把 <span class="math inline">\(F\)</span> 也放入預測變量中去的話，就把實際治療變量的效果這條通路給堵住了。這在因果推斷中被叫做，由於控制了 F 變量，我們錯誤地在模型中引入了 D - separation。這裡的 D，指的是 directional（方向）。D-separation 在因果推斷中指的是，某個變量在DAG圖中和其他所有變量都獨立。在本例中， 由於控制了 <span class="math inline">\(F\)</span> 而導致從治療變量 <span class="math inline">\(T\)</span> 通往結果變量 <span class="math inline">\(H_1\)</span> 之間的的通路被阻斷了 (<span class="math inline">\(T \rightarrow F \rightarrow H_1\)</span>)，使得 <span class="math inline">\(H_1\)</span> 和 <span class="math inline">\(T\)</span> 之間變得失去了依賴關係（相互獨立）。</p>
<p>事實上，錯誤地在預測變量中放入治療結果造成的結果不只是可能使我麼誤認為治療無效，也可能使我們誤認為原本無效的治療是有效的。看如下圖 <a href="-dag-causal-terror.html#fig:introBayes09-fig08">49.8</a> 所提示的因果關係。它的涵義是，該治療土壤的方法確實導致了某些奇怪的菌落的生長，但是，我們種的那個植物並不會被菌落的生長所影響。但是假設有一個未知未測量的變量 “M”，它會同時影響植物和菌落的生長（例如空氣濕度）。這時如果我們建立一個簡單線型回歸模型來尋找治療 <span class="math inline">\(T\)</span> 和植物生長 <span class="math inline">\(H_1\)</span> 之間的關係的話，不小心加入了菌落這一變量會導致本來沒有關係的二者突然出現了治療效果一樣的聯繫。我們來試著模擬一下這個現象。</p>
<div class="sourceCode" id="cb701"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb701-1"><a href="-dag-causal-terror.html#cb701-1"></a><span class="co"># define our coordinates</span></span>
<span id="cb701-2"><a href="-dag-causal-terror.html#cb701-2"></a>dag_coords &lt;-</span>
<span id="cb701-3"><a href="-dag-causal-terror.html#cb701-3"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">name =</span> <span class="kw">c</span>(<span class="st">&quot;H0&quot;</span>, <span class="st">&quot;H1&quot;</span>, <span class="st">&quot;M&quot;</span>, <span class="st">&quot;F&quot;</span>, <span class="st">&quot;T&quot;</span>),</span>
<span id="cb701-4"><a href="-dag-causal-terror.html#cb701-4"></a>         <span class="dt">x    =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="fl">2.5</span>, <span class="dv">3</span>, <span class="dv">4</span>),</span>
<span id="cb701-5"><a href="-dag-causal-terror.html#cb701-5"></a>         <span class="dt">y    =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb701-6"><a href="-dag-causal-terror.html#cb701-6"></a></span>
<span id="cb701-7"><a href="-dag-causal-terror.html#cb701-7"></a><span class="co"># save our DAG</span></span>
<span id="cb701-8"><a href="-dag-causal-terror.html#cb701-8"></a>dag &lt;-</span>
<span id="cb701-9"><a href="-dag-causal-terror.html#cb701-9"></a><span class="st">  </span><span class="kw">dagify</span>(F <span class="op">~</span><span class="st"> </span>M <span class="op">+</span><span class="st"> </span>T,</span>
<span id="cb701-10"><a href="-dag-causal-terror.html#cb701-10"></a>         H1 <span class="op">~</span><span class="st"> </span>H0 <span class="op">+</span><span class="st"> </span>M,</span>
<span id="cb701-11"><a href="-dag-causal-terror.html#cb701-11"></a>         <span class="dt">coords =</span> dag_coords)</span>
<span id="cb701-12"><a href="-dag-causal-terror.html#cb701-12"></a></span>
<span id="cb701-13"><a href="-dag-causal-terror.html#cb701-13"></a><span class="co"># plot </span></span>
<span id="cb701-14"><a href="-dag-causal-terror.html#cb701-14"></a>dag <span class="op">%&gt;%</span></span>
<span id="cb701-15"><a href="-dag-causal-terror.html#cb701-15"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">xend =</span> xend, <span class="dt">yend =</span> yend)) <span class="op">+</span></span>
<span id="cb701-16"><a href="-dag-causal-terror.html#cb701-16"></a><span class="st">  </span><span class="kw">geom_dag_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> name <span class="op">==</span><span class="st"> &quot;M&quot;</span>),</span>
<span id="cb701-17"><a href="-dag-causal-terror.html#cb701-17"></a>                 <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">size =</span> <span class="fl">6.5</span>, <span class="dt">show.legend =</span> F) <span class="op">+</span></span>
<span id="cb701-18"><a href="-dag-causal-terror.html#cb701-18"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">x =</span> <span class="fl">2.5</span>, <span class="dt">y =</span> <span class="dv">1</span>, </span>
<span id="cb701-19"><a href="-dag-causal-terror.html#cb701-19"></a>             <span class="dt">size =</span> <span class="fl">6.5</span>, <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">stroke =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;orange&quot;</span>) <span class="op">+</span></span>
<span id="cb701-20"><a href="-dag-causal-terror.html#cb701-20"></a><span class="st">  </span><span class="kw">geom_dag_text</span>(<span class="dt">color =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span></span>
<span id="cb701-21"><a href="-dag-causal-terror.html#cb701-21"></a><span class="st">  </span><span class="kw">geom_dag_edges</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb701-22"><a href="-dag-causal-terror.html#cb701-22"></a><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="st">&quot;orange&quot;</span>)) <span class="op">+</span></span>
<span id="cb701-23"><a href="-dag-causal-terror.html#cb701-23"></a><span class="st">  </span><span class="kw">theme_dag</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig08"></span>
<img src="bookdown_files/figure-html/introBayes09-fig08-1.png" alt="The other DAG of the fungus and treatment effect on the grow of plant." width="768" />
<p class="caption">
圖 49.8: The other DAG of the fungus and treatment effect on the grow of plant.
</p>
</div>
<div class="sourceCode" id="cb702"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb702-1"><a href="-dag-causal-terror.html#cb702-1"></a><span class="kw">set.seed</span>(<span class="dv">71</span>)</span>
<span id="cb702-2"><a href="-dag-causal-terror.html#cb702-2"></a>N &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb702-3"><a href="-dag-causal-terror.html#cb702-3"></a>h0 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dv">10</span>, <span class="dv">2</span>)</span>
<span id="cb702-4"><a href="-dag-causal-terror.html#cb702-4"></a>treatment &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>, <span class="dt">each =</span> N<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb702-5"><a href="-dag-causal-terror.html#cb702-5"></a>M &lt;-<span class="st"> </span><span class="kw">rbern</span>(N)</span>
<span id="cb702-6"><a href="-dag-causal-terror.html#cb702-6"></a>fungus &lt;-<span class="st"> </span><span class="kw">rbinom</span>( N, <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">prob =</span> <span class="fl">0.5</span> <span class="op">-</span><span class="st"> </span>treatment <span class="op">*</span><span class="st"> </span><span class="fl">0.5</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.4</span> <span class="op">*</span><span class="st"> </span>M)</span>
<span id="cb702-7"><a href="-dag-causal-terror.html#cb702-7"></a>h1 &lt;-<span class="st"> </span>h0 <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>( N, <span class="dv">5</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span> <span class="op">*</span><span class="st"> </span>M)</span>
<span id="cb702-8"><a href="-dag-causal-terror.html#cb702-8"></a>d2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">h0 =</span> h0, <span class="dt">h1 =</span> h1, <span class="dt">treatment =</span> treatment, <span class="dt">fungus =</span> fungus)</span>
<span id="cb702-9"><a href="-dag-causal-terror.html#cb702-9"></a><span class="kw">precis</span>(d2)</span></code></pre></div>
<pre><code>##                mean         sd       5.5%     94.5%      histogram
## h0        10.123143 1.99233421  6.9383408 13.428682 ▁▁▂▂▅▇▇▅▃▂▁▁▁▁
## h1        16.627464 2.64352784 12.3803465 20.692560      ▁▁▃▇▇▇▂▁▁
## treatment  0.500000 0.50025019  0.0000000  1.000000     ▇▁▁▁▁▁▁▁▁▇
## fungus     0.461000 0.49872610  0.0000000  1.000000     ▇▁▁▁▁▁▁▁▁▇</code></pre>
<div class="sourceCode" id="cb704"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb704-1"><a href="-dag-causal-terror.html#cb704-1"></a><span class="co"># incorrectly included fugus </span></span>
<span id="cb704-2"><a href="-dag-causal-terror.html#cb704-2"></a>m6<span class="fl">.7</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb704-3"><a href="-dag-causal-terror.html#cb704-3"></a>  <span class="kw">alist</span>(</span>
<span id="cb704-4"><a href="-dag-causal-terror.html#cb704-4"></a>    h1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma), </span>
<span id="cb704-5"><a href="-dag-causal-terror.html#cb704-5"></a>    mu &lt;-<span class="st"> </span>h0 <span class="op">*</span><span class="st"> </span>p , </span>
<span id="cb704-6"><a href="-dag-causal-terror.html#cb704-6"></a>    p &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>bt <span class="op">*</span><span class="st"> </span>treatment <span class="op">+</span><span class="st"> </span>bf <span class="op">*</span><span class="st"> </span>fungus, </span>
<span id="cb704-7"><a href="-dag-causal-terror.html#cb704-7"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dlnorm</span>( <span class="dv">0</span>, <span class="fl">0.2</span> ),</span>
<span id="cb704-8"><a href="-dag-causal-terror.html#cb704-8"></a>    bt  <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), </span>
<span id="cb704-9"><a href="-dag-causal-terror.html#cb704-9"></a>    bf  <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="fl">0.5</span>),</span>
<span id="cb704-10"><a href="-dag-causal-terror.html#cb704-10"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb704-11"><a href="-dag-causal-terror.html#cb704-11"></a>  ), <span class="dt">data =</span> d2</span>
<span id="cb704-12"><a href="-dag-causal-terror.html#cb704-12"></a>)</span>
<span id="cb704-13"><a href="-dag-causal-terror.html#cb704-13"></a><span class="kw">precis</span>(m6<span class="fl">.7</span>)</span></code></pre></div>
<pre><code>##              mean          sd        5.5%       94.5%
## a     1.510467777 0.014175426 1.487812708 1.533122846
## bt    0.066779619 0.015124914 0.042607085 0.090952152
## bf    0.160976680 0.015183931 0.136709826 0.185243533
## sigma 2.109488889 0.047098698 2.034216072 2.184761705</code></pre>
<div class="sourceCode" id="cb706"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb706-1"><a href="-dag-causal-terror.html#cb706-1"></a><span class="co"># the correct model to see the treatment effect </span></span>
<span id="cb706-2"><a href="-dag-causal-terror.html#cb706-2"></a>m6<span class="fl">.8</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb706-3"><a href="-dag-causal-terror.html#cb706-3"></a>  <span class="kw">alist</span>(</span>
<span id="cb706-4"><a href="-dag-causal-terror.html#cb706-4"></a>    h1 <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma), </span>
<span id="cb706-5"><a href="-dag-causal-terror.html#cb706-5"></a>    mu &lt;-<span class="st"> </span>h0 <span class="op">*</span><span class="st"> </span>p, </span>
<span id="cb706-6"><a href="-dag-causal-terror.html#cb706-6"></a>    p &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>bt <span class="op">*</span><span class="st"> </span>treatment, </span>
<span id="cb706-7"><a href="-dag-causal-terror.html#cb706-7"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dlnorm</span>(<span class="dv">0</span>, <span class="fl">0.25</span>),</span>
<span id="cb706-8"><a href="-dag-causal-terror.html#cb706-8"></a>    bt <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="fl">0.5</span>),</span>
<span id="cb706-9"><a href="-dag-causal-terror.html#cb706-9"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb706-10"><a href="-dag-causal-terror.html#cb706-10"></a>  ), <span class="dt">data =</span> d2</span>
<span id="cb706-11"><a href="-dag-causal-terror.html#cb706-11"></a>)</span>
<span id="cb706-12"><a href="-dag-causal-terror.html#cb706-12"></a><span class="kw">precis</span>(m6<span class="fl">.8</span>)</span></code></pre></div>
<pre><code>##               mean           sd         5.5%        94.5%
## a      1.625584764 0.0096235572  1.610204461 1.6409650674
## bt    -0.016667992 0.0136202768 -0.038435825 0.0050998411
## sigma  2.222812199 0.0496210313  2.143508207 2.3021161910</code></pre>
<p>此時你發現加入 <code>fungus</code> 變量依然對正確的對斷造成了干擾。使得本來不應該出現的治療效果似乎突然成了有效的促進植物生長的治療。</p>
</div>
</div>
<div id="對撞因子偏倚-collider-bias" class="section level2">
<h2><span class="header-section-number">49.3</span> 對撞因子偏倚 collider bias</h2>
<p>使用本章節開頭的申請研究經費的例子，我們認為研究的可靠性 (Trustworthiness, T)，和新穎程度 (Newsworthiness, N) 之間是無關聯性的（圖 <a href="-dag-causal-terror.html#fig:introBayes09-fig01">49.1</a>）。但是，他們二者都會對是否該科研項目被選中 (Selected, S) 造成影響。這樣的關係可以使用下面的 DAG 來表達：</p>
<div class="sourceCode" id="cb708"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb708-1"><a href="-dag-causal-terror.html#cb708-1"></a>grant_dag &lt;-<span class="st"> </span><span class="kw">dagitty</span>(<span class="st">&quot;dag{</span></span>
<span id="cb708-2"><a href="-dag-causal-terror.html#cb708-2"></a><span class="st">      T -&gt; S</span></span>
<span id="cb708-3"><a href="-dag-causal-terror.html#cb708-3"></a><span class="st">      N -&gt; S</span></span>
<span id="cb708-4"><a href="-dag-causal-terror.html#cb708-4"></a><span class="st">}&quot;</span>)</span>
<span id="cb708-5"><a href="-dag-causal-terror.html#cb708-5"></a><span class="kw">coordinates</span>( grant_dag ) &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dt">T =</span> <span class="fl">0.5</span>, <span class="dt">S =</span> <span class="dv">1</span>, <span class="dt">N =</span> <span class="fl">1.5</span>), </span>
<span id="cb708-6"><a href="-dag-causal-terror.html#cb708-6"></a>                                 <span class="dt">y =</span> <span class="kw">c</span>(<span class="dt">T =</span> <span class="dv">0</span>, <span class="dt">S =</span> <span class="dv">0</span>, <span class="dt">N =</span> <span class="dv">0</span>))</span>
<span id="cb708-7"><a href="-dag-causal-terror.html#cb708-7"></a><span class="kw">drawdag</span>(grant_dag)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig09"></span>
<img src="bookdown_files/figure-html/introBayes09-fig09-1.png" alt="The DAG of the grant selection problem: two unrelated variables (T and N) influence S, a collider example." width="768" />
<p class="caption">
圖 49.9: The DAG of the grant selection problem: two unrelated variables (T and N) influence S, a collider example.
</p>
</div>
<p>對撞因子偏倚的現象很有趣，當上述模型中加入對撞因子 S，就會在統計學上給出影響該對撞因子的變量之間的錯誤的關聯性，這裡就是本不該有關聯的 N 和 T 之間會出現統計學上的關聯性。因為，從邏輯上來說，當你知道了某個項目被選中了，也就是圖 <a href="-dag-causal-terror.html#fig:introBayes09-fig01">49.1</a> 中藍色的部分，那麼本來不相關的兩個變量之間就存在了互相可以預測的掛係，即，如果此時你又對該科研項目的可信度或者是新穎度之一有所了解的話，你就可以大致猜測它的新穎度或者是可信度。也就是說，在這些被選中接受科研經費贊助的藍色項目中，如果你知道某項目的新穎程度很高很高，那麼你大概可以認為它給出的科研成果的可信度會比較低。同樣的，如果你知道某個科研項目並不是特別新穎的內容，但是它既然被選中了，這就說明該項目本身將會給出的科研成果會是十分令人信服的。</p>
<div id="虛假的傷心對撞因子-collider-of-false-sorrow" class="section level3">
<h3><span class="header-section-number">49.3.1</span> 虛假的傷心對撞因子 collider of false sorrow</h3>
<p>思考年齡和信服感之間的關係。年齡是否會和幸福感有關係呢？如果有關係，他們之間的關係能算作是因果關係嗎？這裡我們大膽假定每個人出生時幸福感就已被定格，不會隨著年齡而變化。我們已知幸福感會影響一個人是否結婚的概率，大概天天比較樂觀開心表現的有幸福感的人，結婚的概率也相對高一些。另一個可能影響結婚與否的變量一般認為是年齡。很顯然，存活的時間越長，越有機會結婚。這三者之間的關係類似地也可以表達成為 DAG 因果關係圖：</p>
<div class="sourceCode" id="cb709"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb709-1"><a href="-dag-causal-terror.html#cb709-1"></a>marriage_dag &lt;-<span class="st"> </span><span class="kw">dagitty</span>(<span class="st">&quot;dag{</span></span>
<span id="cb709-2"><a href="-dag-causal-terror.html#cb709-2"></a><span class="st">      H -&gt; M</span></span>
<span id="cb709-3"><a href="-dag-causal-terror.html#cb709-3"></a><span class="st">      A -&gt; M</span></span>
<span id="cb709-4"><a href="-dag-causal-terror.html#cb709-4"></a><span class="st">}&quot;</span>)</span>
<span id="cb709-5"><a href="-dag-causal-terror.html#cb709-5"></a><span class="kw">coordinates</span>( marriage_dag ) &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dt">H =</span> <span class="fl">0.5</span>, <span class="dt">M =</span> <span class="dv">1</span>, <span class="dt">A =</span> <span class="fl">1.5</span>), </span>
<span id="cb709-6"><a href="-dag-causal-terror.html#cb709-6"></a>                                 <span class="dt">y =</span> <span class="kw">c</span>(<span class="dt">H =</span> <span class="dv">0</span>, <span class="dt">M =</span> <span class="dv">0</span>, <span class="dt">A =</span> <span class="dv">0</span>))</span>
<span id="cb709-7"><a href="-dag-causal-terror.html#cb709-7"></a><span class="kw">drawdag</span>(marriage_dag)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig10"></span>
<img src="bookdown_files/figure-html/introBayes09-fig10-1.png" alt="The DAG of the happiniess problem: two unrelated variables (H and A) influence marriage." width="768" />
<p class="caption">
圖 49.10: The DAG of the happiniess problem: two unrelated variables (H and A) influence marriage.
</p>
</div>
<p>根據我們理解的理論，年齡和幸福感各自都會影響結婚與否。結婚這個變量就是一個對撞因子 (collider)。即使我們知道年齡和幸福感之間不應該存在直接的關係，但是假如我們有一個模型，結果變量是幸福感，預測變量是年齡（或者反過來）的話，在預測變量裡增加結婚這個變量會導致本來沒有關係的二者變得有“統計學關係”。這就顯然會誤導我們認為年齡增加和幸福感的增加或者減少是有關聯的（而事實上應該是無關的）。</p>
<p>我們用一個較為極端的例子來做一次計算機模擬：</p>
<ol style="list-style-type: decimal">
<li>每年有20名實驗對象出生，且他們擁有符合均一分佈特徵的幸福感。</li>
<li>每年，實驗對象年齡自然會增加一歲。然而幸福感並不會因年齡的增加而增加或減少。</li>
<li>當實驗對象18歲時，有些人會結婚。結婚本身的比值 (odds) 則於該實驗對象的幸福感成一定的比例關係 (proportional)。</li>
<li>當一名實驗對象結婚了以後，她/他保持結婚的狀態，不會離婚。</li>
<li>年齡到65歲之後，該實驗對象離開本次研究。</li>
</ol>
<div class="sourceCode" id="cb710"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb710-1"><a href="-dag-causal-terror.html#cb710-1"></a>d &lt;-<span class="st"> </span><span class="kw">sim_happiness</span>( <span class="dt">seed =</span> <span class="dv">1977</span>, <span class="dt">N_years =</span> <span class="dv">1000</span>)</span>
<span id="cb710-2"><a href="-dag-causal-terror.html#cb710-2"></a><span class="kw">precis</span>(d)</span></code></pre></div>
<pre><code>##                     mean         sd       5.5%      94.5%     histogram
## age        3.3000000e+01 18.7688832  4.0000000 62.0000000 ▇▇▇▇▇▇▇▇▇▇▇▇▇
## married    3.0076923e-01  0.4587690  0.0000000  1.0000000    ▇▁▁▁▁▁▁▁▁▃
## happiness -1.0000698e-16  1.2144211 -1.7894737  1.7894737      ▇▅▇▅▅▇▅▇</code></pre>
<p>這個實驗性的計算機模擬數據本身包含了0-65歲的1300名實驗對象的幸福感和結婚與否的數據。</p>
<div class="sourceCode" id="cb712"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb712-1"><a href="-dag-causal-terror.html#cb712-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb712-2"><a href="-dag-causal-terror.html#cb712-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">married =</span> <span class="kw">factor</span>(married,</span>
<span id="cb712-3"><a href="-dag-causal-terror.html#cb712-3"></a>                          <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;unmarried&quot;</span>, <span class="st">&quot;married&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb712-4"><a href="-dag-causal-terror.html#cb712-4"></a><span class="st">  </span></span>
<span id="cb712-5"><a href="-dag-causal-terror.html#cb712-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> happiness)) <span class="op">+</span></span>
<span id="cb712-6"><a href="-dag-causal-terror.html#cb712-6"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> married), <span class="dt">size =</span> <span class="fl">1.75</span>) <span class="op">+</span></span>
<span id="cb712-7"><a href="-dag-causal-terror.html#cb712-7"></a><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="ot">NULL</span>, <span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;grey85&quot;</span>, <span class="st">&quot;forestgreen&quot;</span>)) <span class="op">+</span></span>
<span id="cb712-8"><a href="-dag-causal-terror.html#cb712-8"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">expand =</span> <span class="kw">c</span>(.<span class="dv">015</span>, <span class="fl">.015</span>)) <span class="op">+</span></span>
<span id="cb712-9"><a href="-dag-causal-terror.html#cb712-9"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig11"></span>
<img src="bookdown_files/figure-html/introBayes09-fig11-1.png" alt="Simulated data, assuming that happiness is uniformly distributed and never changes. Each point is a person. Married individuals are shown with filled blue points. At each age after 18, the happiest individuals are more likely to be married. At later ages, more individuals tend to be married. Marriage status is a collider of age and happiness: A -&gt; M &lt;- H. If we condition on marriage in a regression, it will mislead us to believe that happiness declines with age." width="768" />
<p class="caption">
圖 49.11: Simulated data, assuming that happiness is uniformly distributed and never changes. Each point is a person. Married individuals are shown with filled blue points. At each age after 18, the happiest individuals are more likely to be married. At later ages, more individuals tend to be married. Marriage status is a collider of age and happiness: A -&gt; M &lt;- H. If we condition on marriage in a regression, it will mislead us to believe that happiness declines with age.
</p>
</div>
<p>這時，我們希望用這個數據來回答：“年齡是否和幸福感有關係？”這樣的問題。假設你不知道我們在生成這組數據時遵循的上述 1 - 5 條原則。所以你在建立模型的時候很可能自然而然的認為婚姻本身是年齡和幸福感之間關係的混雜因子。也就是你大概會認為結婚的人莫名其妙地就應該比相對更加（不）幸福。這樣的模型應該是這樣子的；</p>
<p><span class="math display">\[
\mu_i = \alpha_{\text{MID}[i]} + \beta_A A_i
\]</span></p>
<p>其中，</p>
<ul>
<li><span class="math inline">\(\text{MID}[i]\)</span> 是實驗對象 <span class="math inline">\(i\)</span> 是否已經結婚的索引變量 (index variable)，當它等於1時表示單身，等於2時表示已婚。</li>
<li>這其實是我們人為地給已婚者和單身者的幸福感和年齡之間關係的直線設定了各自的截距。</li>
</ul>
<p>這時，由於18歲以後才可以結婚，我們把該數據的人口年齡限定在18歲及以上者。另外我們再把年齡的尺度縮放一下使得 18-65 歲之間的比例是1：</p>
<div class="sourceCode" id="cb713"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb713-1"><a href="-dag-causal-terror.html#cb713-1"></a>d2 &lt;-<span class="st"> </span>d[ d<span class="op">$</span>age <span class="op">&gt;</span><span class="st"> </span><span class="dv">17</span>, ] <span class="co"># adults only</span></span>
<span id="cb713-2"><a href="-dag-causal-terror.html#cb713-2"></a>d2<span class="op">$</span>A &lt;-<span class="st"> </span>(d2<span class="op">$</span>age <span class="op">-</span><span class="st"> </span><span class="dv">18</span>) <span class="op">/</span><span class="st"> </span>(<span class="dv">65</span> <span class="op">-</span><span class="st"> </span><span class="dv">18</span> )</span></code></pre></div>
<p>經過上述的數據處理，我們使得年齡變量 A 的範圍控制在 0-1 之間，其中 0 代表 18 歲，1 代表 65 歲。幸福感則是一個範圍在 -2, 2 之間的數值。這樣的話，假定年齡和幸福感之間呈現的是極其強烈的正關係，那麼這最極端的斜率也就是 <span class="math inline">\((2 - (-2)) / 1 = 4\)</span>。所以，一個較為合理的斜率的先驗概率分佈，可以是95%的斜率取值分佈在小於極端斜率之內的範圍。其次是為截距 <span class="math inline">\(\alpha\)</span> 設定合理的先驗概率分佈。因為 <span class="math inline">\(\alpha\)</span> 本身是年齡等於零，也就是18歲時的幸福感，我們需要這個數據能夠覆蓋所有可能的幸福感取值，-2，2 之間。那麼，標準正（常）態分佈是一個不錯的選擇。</p>
<div class="sourceCode" id="cb714"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb714-1"><a href="-dag-causal-terror.html#cb714-1"></a>d2<span class="op">$</span>mid &lt;-<span class="st"> </span>d2<span class="op">$</span>married <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="co"># construct the marriage status index variable</span></span>
<span id="cb714-2"><a href="-dag-causal-terror.html#cb714-2"></a>m6<span class="fl">.9</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb714-3"><a href="-dag-causal-terror.html#cb714-3"></a>  <span class="kw">alist</span>(</span>
<span id="cb714-4"><a href="-dag-causal-terror.html#cb714-4"></a>    happiness <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma), </span>
<span id="cb714-5"><a href="-dag-causal-terror.html#cb714-5"></a>    mu &lt;-<span class="st"> </span>a[mid] <span class="op">+</span><span class="st"> </span>bA <span class="op">*</span><span class="st"> </span>A, </span>
<span id="cb714-6"><a href="-dag-causal-terror.html#cb714-6"></a>    a[mid] <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>), </span>
<span id="cb714-7"><a href="-dag-causal-terror.html#cb714-7"></a>    bA <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">2</span>), </span>
<span id="cb714-8"><a href="-dag-causal-terror.html#cb714-8"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb714-9"><a href="-dag-causal-terror.html#cb714-9"></a>  ), <span class="dt">data =</span> d2</span>
<span id="cb714-10"><a href="-dag-causal-terror.html#cb714-10"></a>)</span>
<span id="cb714-11"><a href="-dag-causal-terror.html#cb714-11"></a><span class="kw">precis</span>(m6<span class="fl">.9</span>, <span class="dt">depth =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##              mean          sd        5.5%       94.5%
## a[1]  -0.23508769 0.063489864 -0.33655675 -0.13361862
## a[2]   1.25855173 0.084959885  1.12276943  1.39433404
## bA    -0.74902744 0.113201124 -0.92994470 -0.56811018
## sigma  0.98970796 0.022557999  0.95365592  1.02576000</code></pre>
<p>看，這個模型似乎很確定，年齡和幸福感是呈現負關係的。對比一下沒有假如婚姻狀態的變量的模型給出的估計結果：</p>
<div class="sourceCode" id="cb716"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb716-1"><a href="-dag-causal-terror.html#cb716-1"></a>m6<span class="fl">.10</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb716-2"><a href="-dag-causal-terror.html#cb716-2"></a>  <span class="kw">alist</span>(</span>
<span id="cb716-3"><a href="-dag-causal-terror.html#cb716-3"></a>    happiness <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(mu, sigma), </span>
<span id="cb716-4"><a href="-dag-causal-terror.html#cb716-4"></a>    mu &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>bA <span class="op">*</span><span class="st"> </span>A, </span>
<span id="cb716-5"><a href="-dag-causal-terror.html#cb716-5"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( <span class="dv">0</span>, <span class="dv">1</span> ), </span>
<span id="cb716-6"><a href="-dag-causal-terror.html#cb716-6"></a>    bA <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">2</span>),</span>
<span id="cb716-7"><a href="-dag-causal-terror.html#cb716-7"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb716-8"><a href="-dag-causal-terror.html#cb716-8"></a>  ), <span class="dt">data =</span> d2</span>
<span id="cb716-9"><a href="-dag-causal-terror.html#cb716-9"></a>)</span>
<span id="cb716-10"><a href="-dag-causal-terror.html#cb716-10"></a><span class="kw">precis</span>(m6<span class="fl">.10</span>)</span></code></pre></div>
<pre><code>##                 mean          sd        5.5%      94.5%
## a      1.6492480e-07 0.076750151 -0.12266140 0.12266173
## bA    -2.7286203e-07 0.132259761 -0.21137692 0.21137637
## sigma  1.2131876e+00 0.027660803  1.16898030 1.25739491</code></pre>
<p><code>m6.10</code> 才是正確的模型。它正確的給出了年齡和幸福感之間並無關係的結果。模型 <code>m6.9</code> 錯誤地把對撞因子 – 婚姻狀況作為預測變量之一加入了模型中，而婚姻狀況在這個數據背景下，同時是年齡和幸福感的結果（common consequence of age and happiness）。結果就會像 <code>m6.9</code> 那樣，出現年齡和幸福感之間虛假的負關係 (false negative association between the two causes)。<code>m6.9</code> 告訴我們看起來似乎年齡的增長和幸福感呈現負關係，這種僅僅在模型中給出的變量之間的關係應該嚴格來說只能算是一種“統計學的關係 (statistical association)”，不能算是真實的因果關係 (causal association)。正如圖 <a href="-dag-causal-terror.html#fig:introBayes09-fig11">49.11</a> 所顯示的。當已知實驗對象是已婚或者未婚，實驗對象的年齡似乎能告訴我們他/她的幸福度。看綠色點的部分，這些人都是已婚者，年齡越大，越多人結婚，那麼這個已婚人群的幸福度數值就會平均被拉低。相似的，看空白點的部分，這些人都是未婚者，年齡越大，其中幸福感較強的人都結婚而加入了已婚人群陣營，那麼剩下的人就會感覺幸福度越來越低。所以，當把人群分成未婚和已婚兩個部分的話，這兩個人群中的幸福度都隨著年齡增加而呈現下降趨勢。但是，我們知道，這並不是真實的因果關係。</p>
<p>碰撞因子偏倚本身會出現在當模型中的預測變量加入了某個同時是結果和某一個預測變量的結果的變量（common consequence）。</p>
</div>
<div id="對撞因子偏倚另一實例未測量變量造成的碰撞偏倚" class="section level3">
<h3><span class="header-section-number">49.3.2</span> 對撞因子偏倚另一實例（未測量變量造成的碰撞偏倚）</h3>
<p>當我們知道並了解了這樣的對撞因子偏倚現象之後，DAG圖非常有助於幫助我們避免陷入這樣的困境。但是，最可怕的其實是未知（未測量）變量可能造成的對撞偏倚。</p>
<p>假設我們想通過數據了解父母親的受教育程度 (P)，祖父母的受教育程度 (G)，和子女的學習成績 (C)，之間的關係，特別是 P, G 對 C 可能的貢獻或者影響。我們很容易就能理解圖 <a href="-dag-causal-terror.html#fig:introBayes09-fig12">49.12</a> 中所表示的這三個變量之間應該存在的相互因果關係。祖父母的受教育程度很顯然也會對子女的學習成績造成影響 (<span class="math inline">\(G \rightarrow C\)</span>)。</p>
<div class="sourceCode" id="cb718"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb718-1"><a href="-dag-causal-terror.html#cb718-1"></a>dag6.<span class="fl">3.2</span> &lt;-<span class="st"> </span><span class="kw">dagitty</span>( <span class="st">&quot;dag{ G -&gt; P; P -&gt; C; G -&gt; C }&quot;</span> )</span>
<span id="cb718-2"><a href="-dag-causal-terror.html#cb718-2"></a><span class="kw">coordinates</span>(dag6.<span class="fl">3.2</span>) &lt;-<span class="st"> </span><span class="kw">list</span>( <span class="dt">x=</span><span class="kw">c</span>(<span class="dt">G=</span><span class="dv">0</span>,<span class="dt">P=</span><span class="dv">1</span>,<span class="dt">C=</span><span class="dv">1</span>) , <span class="dt">y=</span><span class="kw">c</span>(<span class="dt">G=</span><span class="dv">0</span>,<span class="dt">P=</span><span class="dv">0</span>,<span class="dt">C=</span><span class="dv">1</span>) )</span>
<span id="cb718-3"><a href="-dag-causal-terror.html#cb718-3"></a><span class="kw">drawdag</span>( dag6.<span class="fl">3.2</span> )</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig12"></span>
<img src="bookdown_files/figure-html/introBayes09-fig12-1.png" alt="Educational achievements between parents (P), grandparents (G), and children (C)." width="288" />
<p class="caption">
圖 49.12: Educational achievements between parents (P), grandparents (G), and children (C).
</p>
</div>
<p>如果此時我們發現，可能有一個未被測量的變量可能同時影響父母 (P)，和子女 (C)，但是對祖父母的教育程度並無直接影響，例如父母和子女生活的社區的環境 (U)，通常祖父母不一定和子女和孫輩生活在一個社區。那麼這個未觀察的社區變量就很可能會造成一個碰撞偏倚：</p>
<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb719-1"><a href="-dag-causal-terror.html#cb719-1"></a>dag6.<span class="fl">3.2</span>_u &lt;-<span class="st"> </span><span class="kw">dagitty</span>( <span class="st">&quot;dag{ G -&gt; P; P -&gt; C; G -&gt; C ; U -&gt; P ; U -&gt; C U [unobserved]}&quot;</span> )</span>
<span id="cb719-2"><a href="-dag-causal-terror.html#cb719-2"></a><span class="kw">coordinates</span>(dag6.<span class="fl">3.2</span>_u) &lt;-<span class="st"> </span><span class="kw">list</span>( <span class="dt">x=</span><span class="kw">c</span>(<span class="dt">G=</span><span class="dv">0</span>,<span class="dt">P=</span><span class="dv">1</span>,<span class="dt">C=</span><span class="dv">1</span>,<span class="dt">U=</span><span class="fl">1.3</span>) , <span class="dt">y=</span><span class="kw">c</span>(<span class="dt">G=</span><span class="dv">0</span>,<span class="dt">P=</span><span class="dv">0</span>,<span class="dt">C=</span><span class="dv">1</span>,<span class="dt">U=</span><span class="fl">0.5</span>) )</span>
<span id="cb719-3"><a href="-dag-causal-terror.html#cb719-3"></a><span class="kw">drawdag</span>( dag6.<span class="fl">3.2</span>_u )</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig13"></span>
<img src="bookdown_files/figure-html/introBayes09-fig13-1.png" alt="Educational achievements between parents (P), grandparents (G), and children (C), with an unobserved neighborhood variable (U)." width="316.8" />
<p class="caption">
圖 49.13: Educational achievements between parents (P), grandparents (G), and children (C), with an unobserved neighborhood variable (U).
</p>
</div>
<p>如果因果關係 <a href="-dag-causal-terror.html#fig:introBayes09-fig13">49.13</a> 成立的話，那麼 P 就是 G 和 U 之間的對撞因子。如果此時我們建立 <span class="math inline">\(G \rightarrow C\)</span> 模型時把 <span class="math inline">\(P\)</span> 加入預測變量中，即便我們並沒有測量這個 U 變量，對撞因子偏倚也變得不可避免。</p>
<p>我們實際使用計算機模擬來理解這一過程。數據模擬符合下列條件</p>
<ol style="list-style-type: decimal">
<li>P 是 G, U 共同影響的結果 (common consequence)。</li>
<li>C 則是 G, U, P 三者共同預測的結果。</li>
<li>G 和 U 不受任一變量的影響（完全獨立）。</li>
</ol>
<div class="sourceCode" id="cb720"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb720-1"><a href="-dag-causal-terror.html#cb720-1"></a>N &lt;-<span class="st"> </span><span class="dv">200</span>  <span class="co"># number of grandparent-parent-child traids</span></span>
<span id="cb720-2"><a href="-dag-causal-terror.html#cb720-2"></a>b_GP &lt;-<span class="st"> </span><span class="dv">1</span> <span class="co"># direct effect of G on P</span></span>
<span id="cb720-3"><a href="-dag-causal-terror.html#cb720-3"></a>b_GC &lt;-<span class="st"> </span><span class="dv">0</span> <span class="co"># direct effect of G on C</span></span>
<span id="cb720-4"><a href="-dag-causal-terror.html#cb720-4"></a>b_PC &lt;-<span class="st"> </span><span class="dv">1</span> <span class="co"># direct effect of P on C</span></span>
<span id="cb720-5"><a href="-dag-causal-terror.html#cb720-5"></a>b_U &lt;-<span class="st"> </span><span class="dv">2</span>  <span class="co"># direct effect of U on P and C</span></span></code></pre></div>
<p>上面的模擬參數其實類似於回歸模型中的回歸係數。注意到我們假設祖父母對孫輩學習成績的影響是 0。接下來我們用這些回歸係數來採集一些符合上述設定的隨機樣本數據：</p>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="-dag-causal-terror.html#cb721-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb721-2"><a href="-dag-causal-terror.html#cb721-2"></a>U &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">rbern</span>( N, <span class="fl">0.5</span> ) <span class="op">-</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb721-3"><a href="-dag-causal-terror.html#cb721-3"></a>G &lt;-<span class="st"> </span><span class="kw">rnorm</span>( N )</span>
<span id="cb721-4"><a href="-dag-causal-terror.html#cb721-4"></a>P &lt;-<span class="st"> </span><span class="kw">rnorm</span>( N, b_GP <span class="op">*</span><span class="st"> </span>G <span class="op">+</span><span class="st"> </span>b_U <span class="op">*</span><span class="st"> </span>U)</span>
<span id="cb721-5"><a href="-dag-causal-terror.html#cb721-5"></a>C &lt;-<span class="st"> </span><span class="kw">rnorm</span>( N, b_PC <span class="op">*</span><span class="st"> </span>P <span class="op">+</span><span class="st"> </span>b_GC <span class="op">*</span><span class="st"> </span>G <span class="op">+</span><span class="st"> </span>b_U <span class="op">*</span><span class="st"> </span>U )</span>
<span id="cb721-6"><a href="-dag-causal-terror.html#cb721-6"></a>d &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">C =</span> C, <span class="dt">P =</span> P, <span class="dt">G =</span> G, <span class="dt">U =</span> U)</span></code></pre></div>
<p>那麼，該怎樣設定一個模型來分析祖父母對孫輩學習成績的影響呢？我們認為祖父母的教育程度會通過父母親這條通路，影響到子女的學習成績，所以模型中應該要控制 P。那麼下面的代碼建立的是一個簡單的線性回歸模型，結果變量是 C，預測變量是 P 和 G，注意這裡我們假裝沒有測量到，也不知道 U 變量的存在：</p>
<div class="sourceCode" id="cb722"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb722-1"><a href="-dag-causal-terror.html#cb722-1"></a>m6<span class="fl">.11</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb722-2"><a href="-dag-causal-terror.html#cb722-2"></a>  <span class="kw">alist</span>(</span>
<span id="cb722-3"><a href="-dag-causal-terror.html#cb722-3"></a>    C <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( mu, sigma ), </span>
<span id="cb722-4"><a href="-dag-causal-terror.html#cb722-4"></a>    mu &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>b_PC <span class="op">*</span><span class="st"> </span>P <span class="op">+</span><span class="st"> </span>b_GC <span class="op">*</span><span class="st"> </span>G,</span>
<span id="cb722-5"><a href="-dag-causal-terror.html#cb722-5"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb722-6"><a href="-dag-causal-terror.html#cb722-6"></a>    <span class="kw">c</span>(b_PC, b_GC) <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>), </span>
<span id="cb722-7"><a href="-dag-causal-terror.html#cb722-7"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb722-8"><a href="-dag-causal-terror.html#cb722-8"></a>  ), <span class="dt">data =</span> d</span>
<span id="cb722-9"><a href="-dag-causal-terror.html#cb722-9"></a>)</span>
<span id="cb722-10"><a href="-dag-causal-terror.html#cb722-10"></a></span>
<span id="cb722-11"><a href="-dag-causal-terror.html#cb722-11"></a><span class="kw">precis</span>(m6<span class="fl">.11</span>)</span></code></pre></div>
<pre><code>##              mean          sd        5.5%        94.5%
## a     -0.11747518 0.099195743 -0.27600914  0.041058772
## b_PC   1.78689146 0.044553553  1.71568628  1.858096644
## b_GC  -0.83895371 0.106140454 -1.00858666 -0.669320767
## sigma  1.40948908 0.070111393  1.29743753  1.521540626</code></pre>
<p>看模型 <code>m6.11</code> 給出的父母子女的學習成績的影響是多麼的顯著。甚至比我們設定的關係還要大兩倍。這並不奇怪，因為這裡給出的一部分 <span class="math inline">\(P \rightarrow C\)</span> 的關係應該歸功於 <span class="math inline">\(U\)</span>，但是該模型本身不知道 <span class="math inline">\(U\)</span> 的存在。但是更令人感到驚訝的是，本來設定的祖父母不影響子女學習成績的關係在這個模型中變得顯著呈現負相關，這是有悖常識的。再怎麼說祖父母的受教育程度越高也不能給子女的學習成績帶來負面的影響才是。這個數學模型本身並沒有錯，但是它不能被賦予一個因果關係的解釋。這裏的對撞因子偏倚是如何形成的呢？</p>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb724-1"><a href="-dag-causal-terror.html#cb724-1"></a>d<span class="op">$</span>G_st &lt;-<span class="st"> </span><span class="kw">standardize</span>(d<span class="op">$</span>G)</span>
<span id="cb724-2"><a href="-dag-causal-terror.html#cb724-2"></a>d<span class="op">$</span>C_st &lt;-<span class="st"> </span><span class="kw">standardize</span>(d<span class="op">$</span>C)</span>
<span id="cb724-3"><a href="-dag-causal-terror.html#cb724-3"></a>d<span class="op">$</span>P_st &lt;-<span class="st"> </span><span class="kw">standardize</span>(d<span class="op">$</span>P)</span>
<span id="cb724-4"><a href="-dag-causal-terror.html#cb724-4"></a>P_<span class="dv">45</span> &lt;-<span class="st"> </span><span class="kw">quantile</span>(d<span class="op">$</span>P_st, <span class="dt">prob =</span> <span class="fl">.45</span>)</span>
<span id="cb724-5"><a href="-dag-causal-terror.html#cb724-5"></a>P_<span class="dv">60</span> &lt;-<span class="st"> </span><span class="kw">quantile</span>(d<span class="op">$</span>P_st, <span class="dt">prob =</span> <span class="fl">.60</span>)</span>
<span id="cb724-6"><a href="-dag-causal-terror.html#cb724-6"></a></span>
<span id="cb724-7"><a href="-dag-causal-terror.html#cb724-7"></a><span class="kw">with</span>(d, <span class="kw">plot</span>(G_st[(P_st <span class="op">&lt;</span><span class="st"> </span>P_<span class="dv">45</span> <span class="op">|</span><span class="st"> </span>P_st <span class="op">&gt;</span><span class="st"> </span>P_<span class="dv">60</span>) <span class="op">&amp;</span><span class="st"> </span>U <span class="op">==</span><span class="st"> </span><span class="dv">-1</span>], </span>
<span id="cb724-8"><a href="-dag-causal-terror.html#cb724-8"></a>             C_st[(P_st <span class="op">&lt;</span><span class="st"> </span>P_<span class="dv">45</span> <span class="op">|</span><span class="st"> </span>P_st <span class="op">&gt;</span><span class="st"> </span>P_<span class="dv">60</span>) <span class="op">&amp;</span><span class="st"> </span>U <span class="op">==</span><span class="st"> </span><span class="dv">-1</span>], </span>
<span id="cb724-9"><a href="-dag-causal-terror.html#cb724-9"></a>             <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>), </span>
<span id="cb724-10"><a href="-dag-causal-terror.html#cb724-10"></a>             <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">2.3</span>),</span>
<span id="cb724-11"><a href="-dag-causal-terror.html#cb724-11"></a>             <span class="dt">bty=</span><span class="st">&quot;n&quot;</span>, </span>
<span id="cb724-12"><a href="-dag-causal-terror.html#cb724-12"></a>             <span class="dt">main =</span> <span class="st">&quot;Parents in 45th to 60th centiles&quot;</span>,</span>
<span id="cb724-13"><a href="-dag-causal-terror.html#cb724-13"></a>             <span class="dt">xlab =</span> <span class="st">&quot;grandparent education (G)&quot;</span>, </span>
<span id="cb724-14"><a href="-dag-causal-terror.html#cb724-14"></a>             <span class="dt">ylab =</span> <span class="st">&quot;grandchild education (C)&quot;</span>))</span>
<span id="cb724-15"><a href="-dag-causal-terror.html#cb724-15"></a><span class="kw">with</span>(d, <span class="kw">points</span>(G_st[(P_st <span class="op">&gt;=</span><span class="st"> </span>P_<span class="dv">45</span> <span class="op">&amp;</span><span class="st"> </span>P_st <span class="op">&lt;=</span><span class="st"> </span>P_<span class="dv">60</span>) <span class="op">&amp;</span><span class="st"> </span>U <span class="op">==</span><span class="st"> </span><span class="dv">-1</span>], </span>
<span id="cb724-16"><a href="-dag-causal-terror.html#cb724-16"></a>               C_st[(P_st <span class="op">&gt;=</span><span class="st"> </span>P_<span class="dv">45</span> <span class="op">&amp;</span><span class="st"> </span>P_st <span class="op">&lt;=</span><span class="st"> </span>P_<span class="dv">60</span>) <span class="op">&amp;</span><span class="st"> </span>U <span class="op">==</span><span class="st"> </span><span class="dv">-1</span>], </span>
<span id="cb724-17"><a href="-dag-causal-terror.html#cb724-17"></a>               <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>), </span>
<span id="cb724-18"><a href="-dag-causal-terror.html#cb724-18"></a>               <span class="dt">pch =</span> <span class="dv">16</span>))</span>
<span id="cb724-19"><a href="-dag-causal-terror.html#cb724-19"></a><span class="kw">with</span>(d, <span class="kw">points</span>(G_st[(P_st <span class="op">&lt;</span><span class="st"> </span>P_<span class="dv">45</span> <span class="op">|</span><span class="st"> </span>P_st <span class="op">&gt;</span><span class="st"> </span>P_<span class="dv">60</span>) <span class="op">&amp;</span><span class="st"> </span>U <span class="op">==</span><span class="st"> </span><span class="dv">1</span>], </span>
<span id="cb724-20"><a href="-dag-causal-terror.html#cb724-20"></a>               C_st[(P_st <span class="op">&lt;</span><span class="st"> </span>P_<span class="dv">45</span> <span class="op">|</span><span class="st"> </span>P_st <span class="op">&gt;</span><span class="st"> </span>P_<span class="dv">60</span>) <span class="op">&amp;</span><span class="st"> </span>U <span class="op">==</span><span class="st"> </span><span class="dv">1</span>], </span>
<span id="cb724-21"><a href="-dag-causal-terror.html#cb724-21"></a>               <span class="dt">col =</span> rangi2))</span>
<span id="cb724-22"><a href="-dag-causal-terror.html#cb724-22"></a><span class="kw">with</span>(d, <span class="kw">points</span>(G_st[(P_st <span class="op">&gt;=</span><span class="st"> </span>P_<span class="dv">45</span> <span class="op">&amp;</span><span class="st"> </span>P_st <span class="op">&lt;=</span><span class="st"> </span>P_<span class="dv">60</span>) <span class="op">&amp;</span><span class="st"> </span>U <span class="op">==</span><span class="st"> </span><span class="dv">1</span>], </span>
<span id="cb724-23"><a href="-dag-causal-terror.html#cb724-23"></a>               C_st[(P_st <span class="op">&gt;=</span><span class="st"> </span>P_<span class="dv">45</span> <span class="op">&amp;</span><span class="st"> </span>P_st <span class="op">&lt;=</span><span class="st"> </span>P_<span class="dv">60</span>) <span class="op">&amp;</span><span class="st"> </span>U <span class="op">==</span><span class="st"> </span><span class="dv">1</span>], </span>
<span id="cb724-24"><a href="-dag-causal-terror.html#cb724-24"></a>               <span class="dt">col =</span> rangi2, </span>
<span id="cb724-25"><a href="-dag-causal-terror.html#cb724-25"></a>               <span class="dt">pch =</span> <span class="dv">16</span>))</span>
<span id="cb724-26"><a href="-dag-causal-terror.html#cb724-26"></a><span class="kw">with</span>(d, <span class="kw">abline</span>(<span class="kw">lm</span>(C_st[(P_st <span class="op">&gt;=</span><span class="st"> </span>P_<span class="dv">45</span> <span class="op">&amp;</span><span class="st"> </span>P_st <span class="op">&lt;=</span><span class="st"> </span>P_<span class="dv">60</span>)] <span class="op">~</span><span class="st"> </span></span>
<span id="cb724-27"><a href="-dag-causal-terror.html#cb724-27"></a><span class="st">                    </span>G_st[(P_st <span class="op">&gt;=</span><span class="st"> </span>P_<span class="dv">45</span> <span class="op">&amp;</span><span class="st"> </span>P_st <span class="op">&lt;=</span><span class="st"> </span>P_<span class="dv">60</span>)]), </span>
<span id="cb724-28"><a href="-dag-causal-terror.html#cb724-28"></a>       <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">lwd =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>)))</span>
<span id="cb724-29"><a href="-dag-causal-terror.html#cb724-29"></a><span class="kw">text</span>(<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">2.1</span>, <span class="st">&quot;Good neighborhoods&quot;</span>, <span class="dt">col =</span> rangi2)</span>
<span id="cb724-30"><a href="-dag-causal-terror.html#cb724-30"></a><span class="kw">text</span>(<span class="fl">0.5</span>, <span class="fl">-2.1</span>, <span class="st">&quot;Bad neighborhoods&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig14"></span>
<img src="bookdown_files/figure-html/introBayes09-fig14-1.png" alt="Unobserved confounds and collider bias. In this example, grandparents influence grandkids only indirectly, through parents. However, unobserved neighborhood effects on parents and their children create the illusion that grand parents harm their grandkids education. Parental education is a collider: once we condition on it, grandparental education becomes negatively associated with grand child education." width="576" />
<p class="caption">
圖 49.14: Unobserved confounds and collider bias. In this example, grandparents influence grandkids only indirectly, through parents. However, unobserved neighborhood effects on parents and their children create the illusion that grand parents harm their grandkids education. Parental education is a collider: once we condition on it, grandparental education becomes negatively associated with grand child education.
</p>
</div>
<p>繪製祖父母教育水平和子女學習成績之間的散點圖如圖 <a href="-dag-causal-terror.html#fig:introBayes09-fig14">49.14</a> 所示，橫軸是祖父母的受教育水平，縱軸是子女的學習成績。其中根據未知的變量 U ，也就是子女和父母生活的社區環境的優越與否分成了藍色和黑色兩個部分的散點雲。可以看見不論是在優越街區 (U = 1) 還是在較差的街區 (U = 2)，祖父母的教育水平應該都和子女的學習成績成正相關才對。但是這一關係在我們模擬的數據中是100%通過父母親的受教育水平來體現的，因為我們一開始強制 <code>b_GC &lt;- 0 # direct effect of G on C</code>，也就是 G 直接對 C 的影響的理論值是零。當模型中的預測變量加入了對撞因子，父母親的受教育水平 P 這一變量之後，我們相當於是在強制比較父母受相似教育水平的孩子之間的學習成績。如圖 <a href="-dag-causal-terror.html#fig:introBayes09-fig14">49.14</a> 中藍色和黑色實心點的部分兒童。當僅使用這些點來做回歸直線時，給出的回歸係數就是負的。這就是模型 <code>m6.11</code> 給出的 <code>b_GC = -0.84</code> 這樣的負數的回歸係屬估計的原因。之所以會出現這樣有趣的對撞因子偏倚，我們可以這樣認為：當我們已知父母親的受教育水平 P 之後，如果再了解了祖父母的受教育水平 G，等於是間接知道了子女和父母生活的街區 (U) 的一部分信息。這裡反覆需要強調的是，街區這一變量是未知未測的變量。所以，假如我們選出兩個小孩，他們的父母親有相似的受教育程度，其中一個的祖父母受教育程度低，在圖<a href="-dag-causal-terror.html#fig:introBayes09-fig14">49.14</a>的藍色區域，另一個小孩的祖父母受教育程度較高，在圖<a href="-dag-causal-terror.html#fig:introBayes09-fig14">49.14</a>的黑色區域。那麼之所以這兩個小孩的父母親受教育水平相似，只能是被不同的生活街區所影響（但是這個變量其實是未觀測變量）。所以這時候孩子之間的成績差異其實並非是由祖父母造成的，而是間接地被未知的變量 - 生活街區的優越與否給影響了的。所以我們會看見這樣神奇的現象，也就是父母親相似的教育水平時，如果祖父母受教育水平高，則他們大多生活在不怎麼樣的街區，從而間接導致了小孩學習成績不佳。看起來似乎是祖父母的受教育水平反而對子女學習成績造成了負影響一樣。</p>
<p>這裡，未測量的街區這一變量使得父母親受教育程度這一變量變成了對撞因子，解決對撞因子偏倚的方法其實是，認識到有未測量變量的存在，然後去獲取該變量，加入到你的模型中去：</p>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="-dag-causal-terror.html#cb725-1"></a>m6<span class="fl">.12</span> &lt;-<span class="st"> </span><span class="kw">quap</span>(</span>
<span id="cb725-2"><a href="-dag-causal-terror.html#cb725-2"></a>  <span class="kw">alist</span>(</span>
<span id="cb725-3"><a href="-dag-causal-terror.html#cb725-3"></a>    C <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>( mu, sigma ), </span>
<span id="cb725-4"><a href="-dag-causal-terror.html#cb725-4"></a>    mu &lt;-<span class="st"> </span>a <span class="op">+</span><span class="st"> </span>b_PC <span class="op">*</span><span class="st"> </span>P <span class="op">+</span><span class="st"> </span>b_GC <span class="op">*</span><span class="st"> </span>G <span class="op">+</span><span class="st"> </span>b_U <span class="op">*</span><span class="st"> </span>U,</span>
<span id="cb725-5"><a href="-dag-causal-terror.html#cb725-5"></a>    a <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb725-6"><a href="-dag-causal-terror.html#cb725-6"></a>    <span class="kw">c</span>(b_PC, b_GC, b_U) <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>), </span>
<span id="cb725-7"><a href="-dag-causal-terror.html#cb725-7"></a>    sigma <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span>)</span>
<span id="cb725-8"><a href="-dag-causal-terror.html#cb725-8"></a>  ), <span class="dt">data =</span> d</span>
<span id="cb725-9"><a href="-dag-causal-terror.html#cb725-9"></a>)</span>
<span id="cb725-10"><a href="-dag-causal-terror.html#cb725-10"></a></span>
<span id="cb725-11"><a href="-dag-causal-terror.html#cb725-11"></a><span class="kw">precis</span>(m6<span class="fl">.12</span>)</span></code></pre></div>
<pre><code>##               mean          sd        5.5%         94.5%
## a     -0.121975097 0.071925877 -0.23692654 -0.0070236546
## b_PC   1.011611028 0.065972577  0.90617411  1.1170479480
## b_GC  -0.040813729 0.097287159 -0.19629740  0.1146699415
## b_U    1.996489923 0.147704623  1.76042941  2.2325504390
## sigma  1.019599112 0.050801756  0.93840809  1.1007901302</code></pre>
<p>這樣子模型 <code>m6.12</code> 就能準確地給出我們模擬他們的關係的回歸係數。</p>
</div>
</div>
<div id="直面混雜效應" class="section level2">
<h2><span class="header-section-number">49.4</span> 直面混雜效應</h2>
<div id="兩條通路" class="section level3">
<h3><span class="header-section-number">49.4.1</span> 兩條通路</h3>
<div class="sourceCode" id="cb727"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb727-1"><a href="-dag-causal-terror.html#cb727-1"></a>dag_<span class="fl">6.1</span> &lt;-<span class="st"> </span><span class="kw">dagitty</span>(<span class="st">&quot;dag{</span></span>
<span id="cb727-2"><a href="-dag-causal-terror.html#cb727-2"></a><span class="st">                   U [unobserved]</span></span>
<span id="cb727-3"><a href="-dag-causal-terror.html#cb727-3"></a><span class="st">                   X -&gt; Y</span></span>
<span id="cb727-4"><a href="-dag-causal-terror.html#cb727-4"></a><span class="st">                   X &lt;- U &lt;- A -&gt; C -&gt; Y</span></span>
<span id="cb727-5"><a href="-dag-causal-terror.html#cb727-5"></a><span class="st">                   U -&gt; B &lt;- C</span></span>
<span id="cb727-6"><a href="-dag-causal-terror.html#cb727-6"></a><span class="st">}&quot;</span>)</span>
<span id="cb727-7"><a href="-dag-causal-terror.html#cb727-7"></a><span class="kw">coordinates</span>(dag_<span class="fl">6.1</span>) &lt;-<span class="st"> </span><span class="kw">list</span>( <span class="dt">x=</span><span class="kw">c</span>(<span class="dt">X =</span> <span class="dv">0</span>, <span class="dt">Y =</span> <span class="dv">1</span>, <span class="dt">U =</span> <span class="dv">0</span>, </span>
<span id="cb727-8"><a href="-dag-causal-terror.html#cb727-8"></a>                                  <span class="dt">A =</span> <span class="fl">0.5</span>, <span class="dt">B =</span> <span class="fl">0.5</span>, <span class="dt">C =</span> <span class="dv">1</span>), </span>
<span id="cb727-9"><a href="-dag-causal-terror.html#cb727-9"></a>                              <span class="dt">y=</span><span class="kw">c</span>(<span class="dt">X =</span> <span class="dv">0</span>, <span class="dt">Y =</span> <span class="dv">0</span>, <span class="dt">U =</span> <span class="dv">-1</span>, </span>
<span id="cb727-10"><a href="-dag-causal-terror.html#cb727-10"></a>                                  <span class="dt">A =</span> <span class="fl">-1.3</span>, <span class="dt">B =</span> <span class="fl">-0.7</span>, <span class="dt">C =</span> <span class="dv">-1</span>) )</span>
<span id="cb727-11"><a href="-dag-causal-terror.html#cb727-11"></a><span class="kw">drawdag</span>(dag_<span class="fl">6.1</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig15"></span>
<img src="bookdown_files/figure-html/introBayes09-fig15-1.png" alt="Two roads DAG. Exposure of interest X, outcome of interest Y, an unbserved variable U, and three observed covariates (A, B, and C)" width="316.8" />
<p class="caption">
圖 49.15: Two roads DAG. Exposure of interest X, outcome of interest Y, an unbserved variable U, and three observed covariates (A, B, and C)
</p>
</div>
<p>我們主要關心的是 <span class="math inline">\(X \rightarrow Y\)</span> 之間的通路，也就是暴露和結果之間的直接因果關係。那在圖 <a href="-dag-causal-terror.html#fig:introBayes09-fig15">49.15</a> 這一DAG因果關係中的各種變量之間，你應該怎樣選擇加入模型中作為協變量（調整變量）呢？我們尋找一下從起點（暴露變量）到終點（結果變量）之間的所有可行通路：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X \leftarrow U \leftarrow A \rightarrow C \rightarrow Y\)</span></li>
<li><span class="math inline">\(X \leftarrow U \rightarrow B \leftarrow C \rightarrow Y\)</span></li>
<li><span class="math inline">\(X \rightarrow Y\)</span></li>
</ol>
<p>其中 1. 2. 都含有後門通路 (backdoor paths)，這兩條通路都可能導致我們的推斷受混雜的影響。我們需要通過數學模型把可能存在的後門通路關閉。如果說某個後門通路已經被關閉了，我們則需要小心不要不經意把不該加入模型中的變量給加入然後導致其被偷偷打開。</p>
<p>我們看通路 1.，這條通路通過 <span class="math inline">\(A\)</span>，且沒有任何對撞因子，所以這條通路需要通過調整其變量關閉之，但是 <span class="math inline">\(U\)</span> 是未知未測量變量，無法控制，那我們只好退而求其次，調整 <span class="math inline">\(A\)</span> 或者 <span class="math inline">\(C\)</span>：</p>
<div class="sourceCode" id="cb728"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb728-1"><a href="-dag-causal-terror.html#cb728-1"></a><span class="kw">adjustmentSets</span>( dag_<span class="fl">6.1</span>, <span class="dt">exposure =</span> <span class="st">&quot;X&quot;</span>, <span class="dt">outcome =</span> <span class="st">&quot;Y&quot;</span>)</span></code></pre></div>
<pre><code>## { C }
## { A }</code></pre>
<p>如果能調整 <span class="math inline">\(U\)</span> 當然最好，但是它是未測量的變量。<span class="math inline">\(A\)</span> 或者 <span class="math inline">\(C\)</span> 二選一的話，選擇 <span class="math inline">\(C\)</span> 會是更加理想的選擇， 因為它應該同時還能提高對 <span class="math inline">\(X\rightarrow Y\)</span> 因果關係測量的精確度（increase precision）。</p>
<p>再思考通路 2.，這條通路經過 <span class="math inline">\(B\)</span>，且這個 <span class="math inline">\(B\)</span> 很顯然是一個對撞因子。也就是說這裡的通路已經被這個對撞因子關閉掉了。所以你看計算機也並未建議調整這條通路上的變量。如果有誰不小心把這裡的 <span class="math inline">\(B\)</span> 控制進去的話，反而會打開這條通路，造成對撞因子偏倚。於是我們應該記住這樣一個經驗教訓，在你的模型中假如增加了一個變量導致 <span class="math inline">\(X\rightarrow Y\)</span>的關係發生了較為顯著的變化，甚至反轉關係，並不一定意味著這個增加的變量提升了你模型的準確度或者是改善了模型的預測能力，而要時時刻刻當心對撞因子偏倚存在的可能性。</p>
</div>
<div id="華夫餅的後門" class="section level3">
<h3><span class="header-section-number">49.4.2</span> 華夫餅的後門</h3>
<p>回到華夫餅店鋪數量這個數據 (Chapter <a href="-many-more-variables.html#waffle">48.1</a>) 上來。我們來為這個數據繪製一個 DAG 因果關係圖。我們關心的暴露變量是每個州的瓦夫餅餐廳數量，和結果變量 – 離婚率之間的總體因果關係：</p>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb730-1"><a href="-dag-causal-terror.html#cb730-1"></a>dag_<span class="fl">6.2</span> &lt;-<span class="st"> </span><span class="kw">dagitty</span>(<span class="st">&quot;dag{</span></span>
<span id="cb730-2"><a href="-dag-causal-terror.html#cb730-2"></a><span class="st">                   A -&gt; D</span></span>
<span id="cb730-3"><a href="-dag-causal-terror.html#cb730-3"></a><span class="st">                   A -&gt; M -&gt; D</span></span>
<span id="cb730-4"><a href="-dag-causal-terror.html#cb730-4"></a><span class="st">                   A &lt;- S -&gt; M</span></span>
<span id="cb730-5"><a href="-dag-causal-terror.html#cb730-5"></a><span class="st">                   S -&gt; W -&gt; D</span></span>
<span id="cb730-6"><a href="-dag-causal-terror.html#cb730-6"></a><span class="st">}&quot;</span>)</span>
<span id="cb730-7"><a href="-dag-causal-terror.html#cb730-7"></a><span class="kw">coordinates</span>(dag_<span class="fl">6.2</span>) &lt;-<span class="st"> </span><span class="kw">list</span>( <span class="dt">x=</span><span class="kw">c</span>(<span class="dt">A =</span> <span class="dv">0</span>, <span class="dt">D =</span> <span class="dv">1</span>, <span class="dt">M =</span> <span class="fl">0.5</span>, </span>
<span id="cb730-8"><a href="-dag-causal-terror.html#cb730-8"></a>                                  <span class="dt">S =</span> <span class="dv">0</span>, <span class="dt">W =</span> <span class="dv">1</span>), </span>
<span id="cb730-9"><a href="-dag-causal-terror.html#cb730-9"></a>                              <span class="dt">y=</span><span class="kw">c</span>(<span class="dt">A =</span> <span class="dv">0</span>, <span class="dt">D =</span> <span class="dv">0</span>, <span class="dt">M =</span> <span class="fl">-0.5</span>, </span>
<span id="cb730-10"><a href="-dag-causal-terror.html#cb730-10"></a>                                  <span class="dt">S =</span> <span class="dv">-1</span>, <span class="dt">W =</span> <span class="dv">-1</span>))</span>
<span id="cb730-11"><a href="-dag-causal-terror.html#cb730-11"></a><span class="kw">drawdag</span>(dag_<span class="fl">6.2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:introBayes09-fig16"></span>
<img src="bookdown_files/figure-html/introBayes09-fig16-1.png" alt="The waffle backdoor DAG." width="316.8" />
<p class="caption">
圖 49.16: The waffle backdoor DAG.
</p>
</div>
<p>圖 <a href="-dag-causal-terror.html#fig:introBayes09-fig16">49.16</a> 中，</p>
<ul>
<li>S 是所在州是否屬於南方州；</li>
<li>A 是所在州的結婚年齡中位數；</li>
<li>M 是所在州的結婚率；</li>
<li>W 是所在州的瓦夫餅餐廳數量；</li>
<li>D 是所在州的離婚率。</li>
</ul>
<p>上述DAG的涵義在於：</p>
<ul>
<li>南方州的話，結婚年齡中位數較低 <span class="math inline">\(S \rightarrow A\)</span>；</li>
<li>南方州的話，結婚率較高 <span class="math inline">\(S \rightarrow M\)</span>；</li>
<li>上述 <span class="math inline">\(S \rightarrow M\)</span> 的關係同時還經過 <span class="math inline">\(A\)</span>，也就是 <span class="math inline">\(S \rightarrow A \rightarrow M\)</span>；</li>
<li>南方州的華夫餅餐廳數量較多 <span class="math inline">\(S \rightarrow W\)</span>；</li>
<li>年齡中位數 <span class="math inline">\(A\)</span>，結婚率 <span class="math inline">\(M\)</span>，還有華夫餅餐廳數量 <span class="math inline">\(W\)</span> 都直接影響離婚率，<span class="math inline">\(A\rightarrow D; M\rightarrow D; W \rightarrow D\)</span>。</li>
</ul>
<p>如果把暴露變量 <span class="math inline">\(W\)</span> 作為通路起點，離婚率 <span class="math inline">\(D\)</span> 作為通路通路終點的話，有三條有後門的通路：</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(W \leftarrow S \rightarrow A \rightarrow D\)</span></li>
<li><span class="math inline">\(W \leftarrow S \rightarrow M \rightarrow D\)</span></li>
<li><span class="math inline">\(W \leftarrow S \rightarrow A \rightarrow M \rightarrow D\)</span></li>
</ol>
<p>你會發現他們的共同點是都經過 <span class="math inline">\(S\)</span>。所以很簡單地，只要控制了 <span class="math inline">\(S\)</span>，那麼全部三條後門通路就都會被關閉。</p>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="-dag-causal-terror.html#cb731-1"></a><span class="kw">adjustmentSets</span>( dag_<span class="fl">6.2</span>, <span class="dt">exposure =</span> <span class="st">&quot;W&quot;</span>, <span class="dt">outcome =</span> <span class="st">&quot;D&quot;</span>)</span></code></pre></div>
<pre><code>## { A, M }
## { S }</code></pre>
<p>計算機也告訴我們一致的答案，但是除了單獨控制 <span class="math inline">\(S\)</span>，我們還可以選擇同時控制 <span class="math inline">\(A, M\)</span>，來關閉這些後門通路。上述DAG因果關係圖中，所蘊含的條件獨立性關係為：</p>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="-dag-causal-terror.html#cb733-1"></a><span class="kw">impliedConditionalIndependencies</span>( dag_<span class="fl">6.2</span> )</span></code></pre></div>
<pre><code>## A _||_ W | S
## D _||_ S | A, M, W
## M _||_ W | S</code></pre>
<p>分別表示，</p>
<ol style="list-style-type: decimal">
<li>當控制了是否是南方州(<span class="math inline">\(S\)</span>)之後，華夫餅餐廳<span class="math inline">\(W\)</span> 和結婚年齡中位數 <span class="math inline">\(A\)</span> 之間相互獨立。</li>
<li>當同時控制了<span class="math inline">\(A\)</span>，<span class="math inline">\(M\)</span>，<span class="math inline">\(W\)</span>之後，<span class="math inline">\(S\)</span> 和離婚率之間相互獨立。</li>
<li>當控制了 <span class="math inline">\(S\)</span> 之後，<span class="math inline">\(W\)</span> 和 結婚率 <span class="math inline">\(M\)</span> 之間相互獨立。</li>
</ol>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="-many-more-variables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="-model-selection.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/08-Intro-to-Bayes.Rmd",
"text": "編輯"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
