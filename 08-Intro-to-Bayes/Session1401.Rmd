## Beta 二項分佈模型 beta-binomial model 

Beta 二項分佈模型其實是一系列的二項分佈模型的混合體 (a mixture of binomial distributions)。它假定的是每個二進制觀測值，都有自己的實際成功概率。該模型的目的是估計這些成功概率所構成的概率分佈 (estimate the distribution of probabilities of success)，而不是某一個特定的試驗的成功概率。

下面我們使用大學錄取率這個數據來解釋這個模型。這個數據本身假如我們不知道每個學院之間的錄取率相差很大，也就是當數據本身如果不含有學院 (`dept`) 信息時，我們可能會誤認爲整所大學的錄取率都是一樣的。我們之前是通過在邏輯回歸模型種增加學院 `dept` 這一個變量來獲得正確的男女申請人錄取率之差的比較的。這裏我們轉換一個思路，使用beta二項分佈模型，並且不把學院當作已知變量，看這個模型的神奇之處。它的靈活性在於，該模型會初始默認每一行觀測值，都其實有自己的錄取（成功）概率，而不是統一的錄取概率。這些不同的錄取概率本身構成了一個分佈，它可以用 beta 分佈來描述。beta分佈有兩個參數，一個是平均成功概率 (average probability) $\bar{p}$，還有一個是描述概率分佈密度形狀的形狀參數 (shape parameter) $\theta$。$\theta$ 負責描述這些概率在 $[0, 1]$ 的範圍內的分佈有多寬泛 (how spread out the distribution is)。當 $\theta = 2$ 時，是一個平坦分佈，也就是從 0 到 1 之間的所有概率的概率是相同的 (every probability from 0 to 1 is equally likely)。當 $\theta > 2$，分佈變得越來越向中間的平均概率處集中 (more concentrated)，當 $\theta <  2$，分佈本身則越來越向兩邊的極端概率處靠攏 (dispersed that extreme probabilities near 0 and 1 are more likely than the mean)。它的概率密度分佈圖可以用下面的代碼來獲得：


```{r introBayes14-fig01, cache=TRUE, fig.width=6, fig.height=5,  fig.cap="Beta distributions with different means and dispersion.", fig.align='center'}
curve( dbeta2(x, 0.5, 5), from = 0, to = 1, 
       xlab = "probability", ylab = "Density", 
       bty = "n", ylim = c(0, 4),
       main = "beta distributions with different parameters")
curve( dbeta2(x, 0.5, 1), from = 0, to = 1, 
       add =  TRUE, col = rangi2, lwd = 2)
curve( dbeta2(x, 0.5, 2), from = 0, to = 1, 
       add =  TRUE, col = "red")
text(0.5, 2, "beta(p = 0.5, theta = 5)")
text(0.5, 0.3, "beta(p = 0.5, theta = 1)", col = rangi2)
text(0.5, 1.2, "beta(p = 0.5, theta = 2)", col = "red")
```


接下來我們思考如何把線性模型和 $\bar{p}$ 聯繫起來，需要達到的效果是當預測變量發生變化時，我們應該觀察到錄取率的平均值會隨之發生變化。如果用數學表達式來描述就是：


$$
\begin{aligned}
 A_i & \sim \text{BetaBinomial}(N_i, \bar{p}_i, \theta) \\ 
 \text{logit}(\bar{p}_i) & = \alpha_{\text{GID}[i]}　\\
 \alpha_j & = \text{Normal}(0, 1.5) \\ 
 \theta  & = \phi + 2\\ 
 \phi & \sim \text{Exponential}(1) 
\end{aligned}
$$

其中，

- $A_i$ 是結果變量，表示被錄取（成功）與否。
- $N_i$ 是申請人總數。
- $\text{GID}[i]$ 是表示性別的索引變量（男性 = 1，女性 = 2）。
- 我們希望把 Beta 分佈的概率分散程度 (dispersion) 控制在大於2。這是因爲我們不忍爲錄取概率在任何一個學院會是趨向於兩極化的（要麼不錄取，要麼錄取）而應該是集中在某個平均值附近的，那麼這樣的Beta分佈需要的分散程度 $\theta$ 必須大於等於2。當它等於2時，我們看見概率是一個均一分佈，也就是所有的學院錄取率保持不變。爲了滿足這個分散程度取值大於等於2，我們使用的是一個簡單的技巧，用 $\phi + 2$ 表示 $\theta$ 並且使 $\phi$ 服從指數分佈，因爲服從指數分佈的值是大於等於零的。

下面的代碼運行的是上述的模型：


```{r introBayes14-01, cache=TRUE,  results="hide", message=FALSE}
data("UCBadmit")
d <- UCBadmit
d$gid <- ifelse( d$applicant.gender == "male", 1L, 2L )
dat <- list(
        A = d$admit,
        N = d$applications,
        gid = d$gid
)
m12.1 <- ulam(
        alist(
                A ~ dbetabinom( N, pbar, theta), 
                logit(pbar) <- a[gid], 
                a[gid] ~ dnorm( 0, 1.5 ), 
                transpars> theta <<- phi + 2.0, 
                phi ~ dexp(1)
        ), data = dat, chains = 4, cmdstan = TRUE
)
# if you also failed compliation please see https://github.com/rmcelreath/rethinking/issues/267
```


注意到，我們爲 `theta` 特別標註了它是被轉換過後的參數，`transpars>`，這樣 Stan 就會把 `theta` 作爲結果之一保存下來。我們可以使用採樣過後的 `m12.1` 計算其事後的男女錄取率之差:
 

```{r introBayes14-02, cache=TRUE}
post <- extract.samples(m12.1)
post$da <- post$a[, 1] - post$a[, 2]
precis(post, depth = 2)
```

上面對 `m12.1` 的時候樣本進行的計算和比較可以看見，`a[1]` 是男性申請人被錄取的對數比值 log-odds，它的均值似乎略微比 `a[2]` 女性申請人被錄取的對數比值稍微低一些。但是，它們二者的差的事後均值 `da` 沒有顯著偏離 0，其事後概率分佈的可信區間也包括0。所以並沒有太多的證據表明男女申請人之間在這所大學的錄取率上有任何性別的歧視或者偏差。但是記得我們在前一個章節裏，使用簡單的邏輯回歸模型時，除非把學院這一變量加入預測變量中加以考慮才能獲得相似的正確答案。之前當沒有加入學院這一變量的時候，我們其實被告知男女之間有較大的錄取率的性別差，特別是女生的錄取率在表面上看起來似乎比較低。但是當我們把簡單邏輯回歸模型棄用之後，選擇使用beta二項分佈回歸模型在 `m12.1` 中之後，即使沒有把學院變量放進模型中去，依然獲得了準確的男女之間錄取率的比較結果。這是爲什麼呢？

其實當選用 beta 二項分佈的時候，我們允許了每一行的數據，也就是每一個學院的男性申請人數據，和每一個學院的女性申請人數據分別擁有自己的截距。這些截距其實是從一個均值是 $\bar{p}_i$，分散程度是 $\theta$ 的 beta 分佈中採集而來的。我們可以直觀地繪製這個 beta 分佈的形狀來加深對 `m12.1` 模型的理解：


```{r introBayes14-fig02, cache=TRUE, fig.width=6, fig.height=5,  fig.cap="Posterior distributions for m12.1. The thick curves are the posterior mean beta distribution for male and female applicants. The ligher curves represents 100 combinations of bar(p) and theta sampled from the posterior.", fig.align='center'}
gid <- 2
# draw posterior mean beta distribution

curve( dbeta2(x, mean(logistic(post$a[, gid])), mean(post$theta)), 
       from = 0, to = 1, ylab = "Density", xlab = "probability admit", 
       ylim = c(0, 3), lwd = 2, bty = "n")
curve( dbeta2(x, mean(logistic(post$a[, gid - 1])), mean(post$theta)), 
       from = 0, to = 1, ylab = "Density", xlab = "probability admit", 
       ylim = c(0, 3), lwd = 2, add =  TRUE, col = rangi2)
# Draw 50 beta distributions sampled from posterior

for( i in 1:50 ) {
  p <- logistic( post$a[i, gid] )
  theta <- post$theta[i]
  curve( dbeta2(x, p, theta), add = TRUE, col = col.alpha("black", 0.2))
}
for( i in 1:50 ) {
  p <- logistic( post$a[i, gid-1] )
  theta <- post$theta[i]
  curve( dbeta2(x, p, theta), add = TRUE, col = col.alpha(rangi2, 0.2))
}

mtext("distribution of female admission rates (black); male admission rates (blue)")
```


如圖 \@ref(fig:introBayes14-fig02) 所示的，我們允許了不同的錄取率，這樣一來不論男女，在不同的學院之間錄取率的差異被考慮了進來，男女之間的差異也就不那麼明顯了。同時也避免了模型錯誤地認爲女性受到了錄取上的歧視。雖然模型 `m12.1` 並不知道有學院這個變量（我們並沒有在模型中的任何地方加入學院這個變量），它依然靈活準確地給出了允許不同錄取率這一重要的方案，它使用 beta 分佈來估計該錄取概率在不同的人羣中可能的變化，我們可以再看看該模型的事後證實檢驗 (posterior validation check):

```{r introBayes14-fig03, cache=TRUE, fig.width=6, fig.height=5,  fig.cap="Posterior validation check for m12.1. As a result of widely dispersed beta distributions on the figure above, the raw data (blue) is contained within the prediction intervals.", fig.align='center'}

postcheck(m12.1)
```


## 負二項分佈模型，伽馬泊松回歸模型 Negative-binomial/gamma-Poisson

類似beta二項分佈模型和邏輯回歸模型之間的關係，負二項分佈模型 (negative-binomial)，或者更準確的名字叫做伽馬泊松回歸模型，和泊松回歸模型之間的關係。伽馬泊松回歸模型其實是允許了每一個泊松計數 Poisson count 擁有各自不同的事件發生率。它估計的是一個叫做伽馬分佈的形狀，用來描述該泊松事件的發生率本身的分佈。預測變量估計的是一個伽馬分佈的形狀，而不是簡單的事件發生率的期望值 $\lambda$。這樣做有什麼好處呢？一是使得模型變得更加靈活，不用被泊松回歸模型的均值方差必須相等的條件給限制住。伽馬泊松回歸模型擁有兩個重要參數需要估計，一個是發生率的均值 (mean of rate) $\lambda_i$，另一個是表示該伽馬分佈的分散程度 dispersion 的參數 $\phi$。

$$
y_i \sim \text{Gamma-Poisson}(\lambda_i, \phi)
$$

其中，$\lambda_i$ 可以被視爲和普通的泊松分佈的發生率參數相似，但是分散程度 dispersion 參數 $\phi$ 是必須大於零的，它控制着方差的大小。伽馬泊松分佈的方差是 $\lambda + \lambda^2/\phi$。所以，當 $\phi$ 越大，該方差約接近 $\lambda$，也就是越接近一般的泊松回歸模型。

我們用之前用過的太平洋島國生產工具數據來演示該模型的使用和分析過程。之前使用簡單泊松回歸模型時，我們發現夏威夷島的工具種類數據是一個非常有影響力的觀測值。當我們把模型改成伽馬泊松回歸分佈時，夏威夷數據對模型結果的影響應該會小很多。因爲伽馬泊松回歸模型本身就預計數據本身的均值有較大的差異。

該模型


```{r introBayes14-03, cache=TRUE, results="hide"}
data(Kline)
d <- Kline
d$P <- standardize( log(d$population) )
d$cid <- ifelse( d$contact == "high", 2L, 1L )

dat2 <- list(
  T = d$total_tools, 
  P = d$population, 
  cid = d$cid
)

m12.2 <- ulam(
  alist(
    T ~ dgampois( lambda, phi ), 
    lambda <- exp(a[cid]) * P^b[cid] / g,
    a[cid] ~ dnorm(1, 1), 
    b[cid] ~ dexp(1), 
    g ~ dexp(1), 
    phi ~ dexp(1)
  ), data =  dat2, chains = 4, log_lik = TRUE
)

```


```{r introBayes14-04, cache=TRUE}
precis(m12.2, depth = 2)
```




```{r  introBayes14-fig04, cache=TRUE, fig.width=6, fig.height=5,  fig.cap="The gamma-Poisson model is much less influenced by Hawaii, because the model expects more variation. The increased variation in the size of the shaded regions are much larger than in the pure Poisson model. (Figure 53.16)", fig.align='center'}
k <- PSIS( m12.2, pointwise = TRUE)$k

plot( d$population, d$total_tools, 
            bty = "n", 
      xlab = "population", 
      ylab = "total tools", 
      col = rangi2, pch = ifelse( d$cid == 1, 1, 16), lwd = 2, 
      ylim = c(0, 75), cex = 1 + normalize(k))


ns <- 100

P_seq <- seq( from = -5, to = 3, length.out = ns )
# 1.53 is sd of log(population)
# 9 is mean of log(population)

pop_seq <- exp( P_seq*1.53 + 9 )


lambda <- link( m12.2, data = data.frame( P = pop_seq, cid = 1))
lmu <- apply( lambda, 2, mean)
lci <- apply( lambda, 2, PI)
text(150000, 57, "low contact")

lines( pop_seq, lmu, lty = 2, lwd = 1.5 )
shade( lci, pop_seq, xpd = FALSE )

lambda <- link( m12.2, data =  data.frame( P = pop_seq, cid = 2))
lmu <- apply( lambda, 2, mean )
lci <- apply( lambda, 2, PI )
lines( pop_seq, lmu, lty = 1, lwd = 1.5 )
shade( lci, pop_seq, xpd = FALSE )
text(110000, 69, "high contact")

```



## 零膨脹模型 zero-inflated models

很多時候，觀察事件發生的數量種，含有很多零的數值。產生這些零觀察值的原因可能不只一個。可能是因爲多種不同的原因導致的這樣的數據的產生。假設你去森林裏打算數一種知更鳥。那你觀察不到知更鳥的原因很可能是，森林裏真的沒有知更鳥；另一種可能的原因是，你的腳步聲嚇跑了這些本來生活在樹林裏的知更鳥。所以當產生零的機制有多種時，我們可能可以通過一種叫做零膨脹模型 (zero-inflated models) 的方法來建立回歸模型，分析數據。

### 零膨脹泊松回歸模型 zero-inflated Poisson


